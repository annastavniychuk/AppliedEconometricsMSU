---
title: "Семинар 2. Эксперименты -- часть 2."
author: "Анна Ставнийчук"
date: "19/09/2021"
output:
  html_document:
    toc: true
    toc_depth: 3 
    toc_float: 
        collapsed: true 
    theme: united
    df_print: paged 
---

[annastavnychuk\@gmail.com](mailto:annastavnychuk@gmail.com){.email}

С первой частью материалов по теме можно ознакомиться [тут](https://rpubs.com/AnnaStavniychuk/applied_econometrics_seminar1).

# 4. Продолжение симуляции с прошлого раза

Можно ли было бы сделать все то же самое за меньшее число строчек кода и время? Конечно, можно. Более того, если бы похожую процедуру вам пришлось бы по каким-то причинам проводить несколько раз, например, когда у вас несколько экспериментов, функция для вас просто была бы незаменимым помощником. Еще раз генерим данные о нашем умозрительном эксперименте, но на этот раз для общего развития попробуем переписать все то же самое с помощью функций (не пугайтесь, на семинарах мы отдельно еще раз обсудим техническую сторону вопроса про функции):

1.  Функция для генерации данных

```{r Функция для генерации данных}
generate_data <- function(N){
  N=N
  X <- runif(N, 18, 25)
  Z <- rnorm(N, 60, 20)
  e0 <- rnorm(N/2, 0, 1)
  e1 <- rnorm(N/2, 0, 1)
  number <- 1:N
  Y0 <- 240 - 3*X - Z + 15*0 + e0 
  Y1 <- 240 - 3*X - Z + 15*1 + e1 
  data <- data.frame(number = number, X=X, Z=Z, Y0=Y0, Y1=Y1)
}
```

2.  Функция для рандомизации

```{r Функция для рандомизации}
randomization <- function(data, type){
  N <- nrow(data)
  if (type=='in order'){
    T <- c(rep(1,N/2), rep(0,N/2))
    data$T <- T
  } else if (type=='by turns'){
    T <- rep(0:1, N/2)
    data$T <- T
  } else if (type=='unif'){
    V <- runif(N)
    T <- as.numeric(V1 < median(V1))
    data$T <- T
  } else if (type=='norm'){
    V <- rnorm(N) 
    T <- as.numeric(V2>0)
    data$T <- T
  } else if (type=='binom'){
    T <- rbinom(N, 1, 0.5)
  }
  return(data)
}
```

3.  Функция для расчета наблюдаемого исхода

```{r Функция для расчета наблюдаемого исхода}
outcome <- function(data){
  observed_data <- data
  observed_data$Y <- data$T*observed_data$Y1 + (1 - data$T)*observed_data$Y0
  return(observed_data)
}
```

А теперь посмотрим, сколько строчек займет наша симуляция с использованием функций:

```{r Генерим данные с помощью функций}
set.seed(123)
data <- generate_data(1000)
set.seed(123)
data <- randomization(data=data, type='in order')
data <- outcome(data=data)
tail(data,10)
```

## 4.4. Считаем эффект

Когда данные подготовлены, мы забываем, что что-то о них знали :)

С данного момента мы действуем согласно предпосылке, что мы знаем только $Y$, $X$ и $T$.

Поскольку мы знаем, что тритмент распределялся среди наблюдений случайно, мы можем сделать вывод, что предпосылка о независимости воздействия выполнена. Также мы знаем, что данные устроены так, что SUTVA тоже выполнена. Следовательно, можем использовать обычную разницу в средних, чтобы оценить эффнект воздействия:

$\widehat{ATE} = \overline{Y_1} - \overline{Y_0}$

```{r}
ATE_hat <- mean(data[which(data$T == 1),]$Y) - mean(data[which(data$T == 0),]$Y)
ATE_hat
```


Из курса ЭКМ-2 помним, что то же самое можно было бы получить, с помощью обычного парного МНК:

```{r Считаем эффект с помощью регрессии}
model1 <- lm(Y ~ T, data=data)
summary(model1)
```

Если обе предпосылки выполнены, то оценка должна быть несмещенной даже без контрольных переменных (ковариат). Попробуем их добавить и сравним оценки эффекта:

```{r Считаем эффект с помощью регрессии с контрольными переменными}
model2 <- lm(Y ~ T + X + Z, data=data)
summary(model2)
```

Видим, что результаты устойчивы, величина эффекта практически не изменилась, но существенно уменьшилась его стандартная ошибка. Вывод: контрольные переменные хорошо включать для снижения дисперсии оценок.

Далее в качестве упраженения посчитаем средние эффекты на разных группах:

```{r Average treatment effect for the treatment group}
ATT <- mean(data[which(data$T == 1),]$Y1) - mean(data[which(data$T == 1),]$Y0)
ATT
```

```{r Average treatment on the non-treated}
ATnT <- mean(data[which(data$T == 0),]$Y1) - mean(data[which(data$T == 0),]$Y0)
ATnT
```

Получили, то что и должны были получить $ATT = ATnT$. Если мы вернемся в раздел, где мы подготовливали данные, то увидим, что в двух потенциальных исходах мы "зашифровали" одинаковый эффект:

-   $Y_0 = 120 - 3 \cdot X - Z + 15 \cdot \underbrace{T}_{= 0} + \varepsilon = 120 - 3 \cdot X - Z + \varepsilon$
-   $Y_1 = 120 - 3 \cdot X - Z + 15 \cdot \underbrace{T}_{= 1} + \varepsilon = 120 - 3 \cdot X - Z + 15 + \varepsilon$

Содержательно это иллюстрирует то, что эффект воздействия гомогенен, то есть $\text{Heterogeneous treatment effect bias} = (1-\pi)(ATT - ATnT) = 0$.

## 4.4. Баланс ковариатов

Теперь проверим насколько наша рандомизация оказалась хорошей, то есть проверим контрольную и тритмент группу на "похожесть". Сравним средние значения ковариат в двух группах.

### 4.4.1. Сравнение средних

```{r Баланс ковариатов с помощью mean}
mean(data[which(data$T == 1),]$X) - mean(data[which(data$T == 0),]$X)
mean(data[which(data$T == 1),]$Z) - mean(data[which(data$T == 0),]$Z)
```

Это не очень информативный и субъективный способ, но если мы вспомним, что порядок значений ковариат измерялся десятками, то можно сделать вывод, что группы в среднем похожи.

### 4.4.2. Тест Стьюдента

А теперь проведем тест на разницу в средних с помощью формального t-теста Стьюдента:

-   $H_0:$ среднее значение параметра в группах одинаковое, группы не различаются
-   $H_1:$ среднее значение параметра в группах разное, группы различаются

```{r Баланс ковариатов с помощью t.test}
t.test(data[which(data$T == 1),]$X, data[which(data$T == 0),]$X)
t.test(data[which(data$T == 1),]$Z, data[which(data$T == 0),]$Z)
```

Согласно значению p-value мы принимаем $H_0$ и делаем вывод, что группы одинаковые.

### 4.4.2. Использование готовых пакетов

```{r Баланс ковариатов с помощью пакета tableone}
library("tableone")
table <- CreateTableOne(vars=c("X", "Z"), strata="T", data=data, test=TRUE)
print(table)
```

# 5. Про важность предпосылок Гаусса-Маркова

## 5.1 Предпосылки Гаусса-Маркова

- Линейная модель: $Y_i=\tau T_i+\beta X_i+\varepsilon_i$
- $T_i$ не выражается линейно через $X_i$
- $\mathbb{E}\left(\varepsilon_i\right)=0$
- Гомоскедастичность, некоррелированность ошибок $\mathbb{V}\left(\varepsilon_i\right)=\sigma I$
- Экзогенность $\operatorname{Cov}\left(X_i, \varepsilon_i\right)=0$
- Оцениваем методом наименьших квадратов:
$$
\left(Y_i-\hat{\tau} T_i-\hat{\beta} X_i\right)^2 \rightarrow \min _{\hat{\tau}, \hat{\beta}}
$$
- Свойства оценки (теорема Гаусса-Маркова): несмещенность, эффективность, состоятельность

## 5.2 Пример

Мы располагаем данными из 1000 наблюдений, про которые известно:

- $X_i \sim U[0,1]$ - контрольная переменная: успехи команды в прошлом году
- $T_i \mid X_i \sim \operatorname{Bernoulli}\left(0.1+0.8 X_i\right)$ - бинарная переменная переменная интереса: решение тренера взять команду
- $Y_i=f\left(X_i, T_i\right)+\varepsilon_i$ - переменная исхода: успехи команды в этом году
- В соответствии с предпосылками оценим $Y_i \sim T_i+X_i$
- То же ли самое получится, если $T_i \sim \operatorname{Bernoulli}(0.5)$ и оценим $Y_i \sim T_i$?

### 5.2.1 Генерация данных

Сгенерим данные согласно условию:

```{r, message=FALSE}
library(stargazer)

set.seed(123)

X <- runif(1000, 0, 1)

Y0 <- rnorm(1000)
Y1 <- 10 * X + rnorm(1000)
```

### 5.2.2 Генерация тритмента

Случай 1: эндогенный тритмент
```{r}
T_one = rbinom(1000, 1, 0.1 + 0.8*X)
Y_one = Y1 * T_one + Y0 * (1 - T_one)

data_one = data.frame(X=X, Y=Y_one, T=T_one)
```

Случай 2: экзогенный тритмент
```{r}
T_two = rbinom(1000, 1, 0.5)
Y_two = Y1 * T_two + Y0 * (1 - T_two)

data_two = data.frame(X=X, Y=Y_two, T=T_two)
```

### 5.2.3 Оценка эффекта

Сравним оценки:
```{r, message=FALSE}
model_one_1 <- lm(Y ~ T, data=data_one)
model_one_2 <- lm(Y ~ T + X, data=data_one)
model_two_1 <- lm(Y ~ T, data=data_two)
model_two_2 <- lm(Y ~ T + X, data=data_two)

#stargazer(model_one_1, model_one_2, model_two_1, model_two_2, type = 'text') 

# В обычной жизни вы просто можете пользоваться старгейзером, как в комментраии выше
# Чтобы конкретно на этой странице влезло 4 регрессии, я воспользуюсь другой функцией msummary
m_list <- list(endogenous_without_control = model_one_1, 
               endogenous_with_control = model_one_2,
               exogenous_without_control = model_two_1, 
               exogenous_with_control = model_two_2)
library('modelsummary')
msummary(m_list, output = 'markdown', stars = TRUE, title = 'Сравнение моделей')
```

**Выводы:**

- По теореме Гаусса-Маркова мы должны были получить 2 состоятельные (значит одинаковые) оценки
- Они отличаются, потому что модель нелинейная: тренер решает тренировать только те команды, которые будут успешны, поэтому и эффект высокий
- Если бы эффект тренера всегда был одинаковым, теорема Гаусса-Маркова выполнялась бы и оценки действительно оказались бы одинаковыми.

### 5.2.4 Баланс ковариатов

-   $H_0:$ среднее значение параметра в группах одинаковое, группы не различаются
-   $H_1:$ среднее значение параметра в группах разное, группы различаются

```{r}
table1 <- CreateTableOne(vars=c("X", "Z"), strata="T", data=data_one, test=TRUE)
print(table1)

table2 <- CreateTableOne(vars=c("X", "Z"), strata="T", data=data_two, test=TRUE)
print(table2)
```

Согласно значению p-value мы принимаем $H_0$ для второго случая, где тритмент экзогенный, и делаем вывод, что группы одинаковые; для первого случая с эндогенным тритментом баланс ковариатов не выполняется.

*Если у вас возникли какие-то вопросы, или вы нашли неточности в тексте, напишите мне об этом на почту [annastavnychuk\@gmail.com](mailto:annastavnychuk@gmail.com){.email}*
