[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Прикладная эконометрика",
    "section": "",
    "text": "Предисловие\nЭта книга является сборником материалов к семинарским занятиям по эконометрике причинно-следственных связей, проводимых в бакалавриате экономического факультета МГУ имени М.В. Ломоносова.\nКнижка находится в разработке, поэтому часть материалов по некоторым темам пока отсутствует или являются неполными.\nАвтор благодарит своих коллег, Ольгу Сучкову, Георгия Калашнова и Алексея Замниуса, за совместное создание части материалов и плодотворную совместную работу, а также студентов, слушающих курс, благодаря вопросам и комментариям которых книга становится лучше."
  },
  {
    "objectID": "experiments.html#короткое-напоминание-теории",
    "href": "experiments.html#короткое-напоминание-теории",
    "title": "1  Эксперименты",
    "section": "1.1 Короткое напоминание теории",
    "text": "1.1 Короткое напоминание теории\n\n1.1.1 Потенциальные исходы\nОбозначения:\n\n\\(X_i\\) – независимые переменные (covariates)\n\\(T_i\\) – бинарная переменная воздействия (treatment variable): \\[\\begin{equation*}\nT_i =\n\\begin{cases}\n1, &\\text{воздействие на объект i оказано}\\\\\n0, &\\text{воздействие на объект i не оказано}\n\\end{cases}\n\\end{equation*}\\]\n\\(Y_{i1}\\), \\(Y_{i0}\\) – потенциальные исходы (potential outcomes)\n\nНаблюдаемые исходы \\(Y_i\\) отличаются от потенциальных исходов. Потенциальные исходы являются гипотетическими случайными величинами, когда наблюдаемые исходы являются фактическими случайными величинами. Наблюдаемые исходы являются функцией от потенциальных исходов:\n\\(Y_i = T_i \\cdot Y_{i1} + (1-T_i) \\cdot Y_{i0}\\)\nДействительно при \\(T=1\\) мы получим \\(Y_i = Y_{i1}\\), а при \\(T=0\\) получим \\(Y_i = Y_{i0}\\).\n\n\n\n\n\nТогда наш эффект воздействия для конкретного наблюдения равен разнице между двумя состояниями мира для этого наблюдения (потенциальными исходами):\n\\(\\tau_i = Y_{i1} - Y_{i0}\\)\nФундаментальная проблема причинного вывода (Fundamental problem of causal inference):\nЧтобы оценить эффект воздействия для конкретного индивида, мы должны знать потенциальные исходы сразу для двух его состояний мира, но реально мы наблюдаем только одно из них – либо \\(Y_{i1}\\), если индивид подвергся воздействию, либо \\(Y_{i0}\\), если он ему не подвергался. Оценка индивидуального эффекта требует доступа к данным, которых у нас физически не может быть.\n\n\n1.1.2 Средние эффекты\nЕсли с распределением индивидуального эффекта воздействия (treatment effect) работать не получается, будем довольствоваться средними величинами. Например, попробуем рассчитать средний эффект воздействия (average treatment effect):\n\\(ATE = \\mathbb{E}[\\tau_i] = \\mathbb{E}[Y_{i1} - Y_{i0}] = \\mathbb{E}[Y_{i1}] - \\mathbb{E}[Y_{i0}] = \\frac{1}{N_1}\\sum \\limits_{i=1}^{N_1}Y_{i1} - \\frac{1}{N_0}\\sum \\limits_{i=1}^{N_0}Y_{i0}\\)\nСледующий шаг, который мы предпримем, попробуем рассчиать величину эффекта только для тритмент группы – средний эффект воздействия на задействованных (average treatment effect for the treatment group):\n\\(ATT = \\mathbb{E}[\\tau_i|T_i=1] = \\mathbb{E}[Y_{i1} - Y_{i0}|T_i=1] = \\mathbb{E}[Y_{i1}|T_i=1] - \\mathbb{E}[Y_{i0}|T_i=1]\\)\nА теперь то же самое, но для контрольной группы – средний эффект воздействия на незадействованных (average treatment on the non-treated):\n\\(ATnT = \\mathbb{E}[\\tau_i|T_i=0] = \\mathbb{E}[Y_{i1} - Y_{i0}|T_i=0] = \\mathbb{E}[Y_{i1}|T_i=0] - \\mathbb{E}[Y_{i0}|T_i=0]\\)\nОбратите внимание, как и в случае с определением эффекта воздействия на индивидуальном уровне, различные модификации средних эффектов воздействия снова требуют от нас знания обоих потенциальных исходов для каждого наблюдения. Таким образом, и средние, и индивидуальный эффект воздействия нельзя напрямую рассчиать, но мы будем пробовать их оценить.\nСамая простая идея для оценки ATE, которая всем придет в голову, взять простую разницу в средних: \\(\\mathbb{E}[Y_1|T=1] - \\mathbb{E}[Y_0|T=0]\\).\nНо тут всё не так просто, после небольших преобразований, с которыми можно ознакомиться в части 4.1.3 учебника мы получим следующее:\n\\(\\mathbb{E}[Y_1|T=1] - \\mathbb{E}[Y_0|T=0] = \\underbrace{\\mathbb{E}[Y_1] - \\mathbb{E}[Y_0]}_{\\text{ATE}} + \\underbrace{\\mathbb{E}[Y_0|T=1] - \\mathbb{E}[Y_0|T=0]}_{\\text{Selection Bias}} + \\underbrace{(1-\\pi)(ATT - ATnT)}_{\\text{Heterogeneous treatment effect bias}}\\)\n\nATE – интересующий нас эффект\nSelection Bias – смещение, возникающее из-за того, что контрольная группа и группа воздействия различались, даже если бы на них не было оказано воздействие, то есть имеет место некоторый дисбаланс\nHeterogeneous treatment effect bias – различие в интенсивности эффекта для тритмент и контрольной группы, взвешенное на долю выборки \\((1-\\pi)\\), которая попала в контрольную группу\n\nДалее мы рассмотрим предпосылки, которые позволяют нивелировать влияние этих двух смещений и получить оценку ATE.\n\n\n1.1.3 Предпосылки\n\nЭкзогенность воздействия (Independence assumption)\n\nЭкзогенность воздействия (Independence assumption) означает, что распределение объекта в тритмент или контрольную группы осуществляется случайно и независимо от его изначальных характеристик. Данная предпосылка обычно обозначается следующим образом \\((Y_1, Y_0, X)_i \\perp T_i\\)\nТехнически для нас это значит следующее:\n\n\\(\\mathbb{E}[Y_0|T=1] - \\mathbb{E}[Y_0|T=0] = 0 \\Rightarrow \\text{Selection Bias}=0\\)\n\\(\\mathbb{E}[Y_1|T=1] - \\mathbb{E}[Y_1|T=0] = 0\\)\n\n\\((1-\\pi)(ATT - ATnT) = (1-\\pi)\\left[(\\mathbb{E}[Y_1|T=1]-\\mathbb{E}[Y_0|T=1])-(\\mathbb{E}[Y_1|T=0]-\\mathbb{E}[Y_0|T=0])\\right] = 0 \\Rightarrow \\text{Heterogeneous treatment effect bias}=0\\)\n\n\nТо есть хорошая рандомизация, а следовательно, и выполнение предпосылок, позволяет нам очистить эффект воздействия от двух типов смещения, в этом случае:\n\\(ATE = \\mathbb{E}[Y_1] - \\mathbb{E}[Y_0] = \\mathbb{E}[Y_1|T=1] - \\mathbb{E}[Y_0|T=0] \\xrightarrow{p} \\frac{1}{N_1}\\sum \\limits_{i=1}^{N_1}Y_{i1} - \\frac{1}{N_0}\\sum \\limits_{i=1}^{N_0}Y_{i0}\\)\n\nОтсутствие “внешних эффектов” воздействия (SUTVA – Stable unit treatment value assumption)\n\nЭта предпосылка подразумевает выполнение двух вещей. Во-первых, воздействие оказывается только на один объект и внешние эффекты у него отсутствуют. Во-вторых, воздействие гомогенно – существует только один тип тритмента."
  },
  {
    "objectID": "experiments.html#работа-со-случайными-числами-в-r",
    "href": "experiments.html#работа-со-случайными-числами-в-r",
    "title": "1  Эксперименты",
    "section": "1.2 Работа со случайными числами в R",
    "text": "1.2 Работа со случайными числами в R\nВ рамках курса нам неоднократно придется прибегнуть к генерации случайных чисел из какого-нибудь закона распределения, как правило, из нормального. Для работы со случайными числами из нормального распределения в R используется несколько функций: dnorm() для плотности вероятности, pnorm() для функции распределения, qnorm() для квантилей распределения и rnorm() для генерации случайных чисел. Почитать подробнее про них и посмотреть примеры можно тут или тут.\nЕсли вы не уверены в синтаксисе какой-то функции, вы можете воспользоваться встроенной справкой в RStudio (справочная информация появится во вкладке Help):\n\n?rnorm\n\nЕсли вам когда-нибудь понадобятся функции для других распределений, вы можете, конечно, их просто загуглить или ввести в окне Help запрос “Distributions”:\n\n?Distributions\n\nТеперь, когда мы точно знаем, как устроены аргументы у функции rnorm(n;mean;sd), давайте попробуем достать 5 чисел из стандартного нормального распределения \\(\\mathcal{N} \\sim \\left(0;1\\right)\\):\n\nrnorm(5,0,1)\n\n[1]  0.2145932 -0.1451404  1.0676682  0.2179064 -0.4037959\n\n\nЕсли вы повторяли за мной, то у вас, вероятно, получились другие значения. А теперь я тоже попробую ещё раз:\n\nrnorm(5,0,1)\n\n[1]  1.2952007  1.5398067 -1.2333194 -1.5992027  0.2232711\n\n\nКак и ожидалось, у меня тоже не совпало с предыдущим результатом. Существует по меньшей мере две причины, почему нам хотелось бы получать одинаковые результаты:\n\nРабота на семинарах, когда нам с вами было бы удобно сверяться\nВоспроизводимые научные исследования, когда любой читатель может реплицировать и проверить на корректность ваш результат\n\nВ R существует несколько алгоритмов, позволящих генерировать случайные числа (Random Number Generator (RNG), подробнее – ?RNGkind). По умолчанию используется Mersenne twister (Вихрь Мерсенна), поскольку он работает наиболее быстро. Однако все эти алгоритмы на самом деле детерминированы, поэтому генерируемые ими числа корректнее называть “псевдослучайными”.\nГенератор псевдослучайных чисел начинает свою работу с определенной точки в пространстве возможных чисел. Эту точку приянто называть начальное число или seed. Начальное число – это число (или вектор), используемое для инициализации генератора псевдослучайных чисел. Если вы хотите получить одинаковые результаты с помощью генератора случайных чисел, важно установить начальное число. Для этого в R используется функция set.seed(). По умолчанию начальное число не установлено, если ничего не указать, то создается новое из текущего времени и идентификатора процесса на вашем устройстве. Следовательно, по умолчанию разные сеансы дают разные результаты моделирования.\nДавайте снова попробуем сгенерировать 5 чисел из случайного нормального распределения, но в этот раз зафиксируем seed:\n\nset.seed(123)\nrnorm(5,0,1)\n\n[1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774\n\n\nИ еще разок:\n\nset.seed(123)\nrnorm(5,0,1)\n\n[1] -0.56047565 -0.23017749  1.55870831  0.07050839  0.12928774\n\n\nПолучилось! В качестве seed можно использовать любое число, главное, чтобы при репликации оно каждый раз было одинаковым.\nПочитать про set.seed можно тут на русском и тут на английском."
  },
  {
    "objectID": "experiments.html#мини-симуляция",
    "href": "experiments.html#мини-симуляция",
    "title": "1  Эксперименты",
    "section": "1.3 Мини-симуляция",
    "text": "1.3 Мини-симуляция\nСимуляции – это “игрушечные” примеры, которые позволят нам на протяжении курса разбираться с разными методами. Игрушечные они потому, что за ними не стоят реальные данные. Данные для симуляций мы будем специальным образом заранее моделировать. Это бывает удобно, когда идеально подходящих данных нет, или они не лежат в открытом доступе. К тому же, живые данные часто могут быть зашумлены из-за других факторов, на которые нам не всегда будет удобно отвлекаться на занятиях. Но с живыми данными мы тоже обязательно будем работать! В том числе, они будут доступны вам в домашних заданиях :)\nТеперь смоделируем небольшую симуляцию по мотивам изученного материала.\n\n1.3.1 Подготовка данных\nДавайте смоделируем гипотетическую ситуацию. Мы хотим оценить величину эффекта от использование сайта с расписанием cacs.ws на свободное время студента.\nПредположим, что наша экспериментальная выборка состоит из 1000 человек:\n\nN &lt;- 1000\n\nДля простоты у них будет всего две характеристики (\\(X\\) – возраст и \\(Z\\) – время в пути от дома до ЭФ), имеющих влияние на потенциальный исход (\\(Y_0\\) и \\(Y_1\\) – свободное время). При этом предположим, что реальный эффект воздействия равен \\(\\tau=15\\) минутам. Будем считать, что реальная зависимость потенциального исхода от ковариатов и тритмента выглядит следующим образом:\n\n\\(Y_0 = 240 - 3 \\cdot X - Z + 15 \\cdot \\underbrace{T}_{= 0} + \\varepsilon = 120 - 3 \\cdot X - Z + \\varepsilon\\) – потенциальный исход, если не было оказано воздействие\n\\(Y_1 = 240 - 3 \\cdot X - Z + 15 \\cdot \\underbrace{T}_{= 1} + \\varepsilon = 120 - 3 \\cdot X - Z + 15 + \\varepsilon\\) – потенциальный исход, если было оказано воздействие\n\nСгенерируем \\(X\\) и \\(Z\\) случайным образом:\n\nset.seed(123)\nX &lt;- runif(N, 18, 25)\nZ &lt;- rnorm(N, 60, 20)\n# Посмотрим на наши данные, нарисуем сразу 2 графика -- диаграмму разброса и гистограмму\npar(mfrow=c(2,2)) # читаем буквально как матрицы -- 2 строки и 2 столбца\nplot(X)\nhist(X)\nplot(Z)\nhist(Z)\n\n\n\n\nТакже создадим случайные ошибки для каждого из типов индивидов:\n\nset.seed(123)\ne &lt;- rnorm(N, 0, 1)\nplot(e, col=\"red\")\n\n\n\n\nВспомогательно пронумеруем наши наблюдения:\n\nnumber &lt;- 1:N\n\nИ соберем всё в общий датасет:\n\ndata &lt;- data.frame(number = number, X=X, Z=Z) # сшиваем столбики в data frame\nhead(data, 10) # смотрим только первые несколько строк датасета\n\n   number        X        Z\n1       1 20.01304 47.96214\n2       2 23.51814 40.12603\n3       3 20.86284 80.53570\n4       4 24.18112 75.02123\n5       5 24.58327 29.81667\n6       6 18.31890 58.09705\n7       7 21.69674 42.08104\n8       8 24.24693 18.58498\n9       9 21.86005 63.00240\n10     10 21.19630 58.41577\n\n\n\n\n1.3.2 Рандомизация\nЧто касается рандомизации, то наша глобальная задача, используя разные функции придумать способ, как случайным образом разбить выборку на 2 группы. Существует огромное множество вариантов, как это можно сделать. Мы обсудим лишь несколько из них. На практике вы можете пользоваться как этими вариантами, так и придумать что-то своё.\n\n1.3.2.1 Использование порядкового номера\nПервый вариант – просто взять половину наблюдений по их порядку расположения в датасете. Пусть воздействие будет оказано только на первую половину нашей выборки.\n\nT1 &lt;- c(rep(1,N/2), rep(0,N/2))\nmean(T1) # проверяем долю тритмента, должна получиться ровно половина\n\n[1] 0.5\n\ndata$T1 &lt;- T1 # добавляем переменную в датасет\n\nТут мы воспользовались функцией c(...), которая позволяет объединить величины внутри неё в вектор, и функцией rep(x;times) которая повторяет величину \\(x\\) столько раз, сколько указано в величине \\(times\\).\nВторой вариант, который практически дублирует первый, но немного отличается – мы можем взять каждое второе наблюдение:\n\nT2 &lt;- rep(0:1, N/2)\nmean(T2) # проверяем долю тритмента, должна получиться ровно половина\n\n[1] 0.5\n\ndata$T2 &lt;- T2 # добавляем переменную в датасет\n\n\n\n1.3.2.2 Использование свойств распределений\nЛогично, что если мы хотим случайным образом присвоить наблюдениям разные группы, то мы можем начать с того, что присвоим им случайные числа, которые мы потом разными способами переведем в бинарный формат, который уже будет соотвествовать конкретной группе. Протестируем этот способ на примере трех распределений – нормального, равномерного и биномиального.\n\n1.3.2.2.1 Равномерное распределение\n\nset.seed(123)\nV1 &lt;- runif(N) # генерим вспомогательную переменную из равномерного распределения\nT3 &lt;- as.numeric(V1 &lt; median(V1)) #генерим тритмент, отсекая половину выборки по медиане; as.numeric используется, чтобы перейти от логического типа (true, false) к численному (1 и 0)\nmean(T3) # проверяем долю тритмента, должна получиться ровно половина\n\n[1] 0.5\n\ndata$T3 &lt;- T3 # добавляем переменную в датасет\n\n\n\n1.3.2.2.2 Нормальное распределение\n\nset.seed(123)\nV2 &lt;- rnorm(N) # генерим вспомогательную переменную из нормального распределения\nT4 &lt;- as.numeric(V2&gt;0) #генерим тритмент, отсекая половину выборки по знаку вспомогательной переменной; as.numeric используется, чтобы перейти от логического типа (true, false) к численному (1 и 0)\nsummary(T4) # проверяем долю тритмента, должна получиться примерно половина\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   1.000   0.505   1.000   1.000 \n\ndata$T4 &lt;- T4 # добавляем переменную в датасет\n\n\n\n1.3.2.2.3 Биномиальное распределение\n\nset.seed(123)\nT5 &lt;- rbinom(N, 1, 0.5) #генерим тритмент, отсекая половину выборки по знаку вспомогательной переменной; as.numeric используется, чтобы перейти от логического типа (true, false) к численному (1 и 0)\nsummary(T5) # проверяем долю тритмента, должна получиться примерно половина\n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n  0.000   0.000   0.000   0.493   1.000   1.000 \n\ndata$T5 &lt;- T5 # добавляем переменную в датасет\n\n\n\n\n1.3.2.3 Использование готовых пакетов\n\n1.3.2.3.1 Пакет experiment\n\nlibrary('experiment') \nset.seed(123)\nrand &lt;- randomize(data, group= c(\"Treat\", \"Control\"))\nT6 &lt;- as.numeric(rand$treatment == \"Treat\") # преобразовываем переменную в численный формат \ndata$T6 &lt;- T6 # добавляем переменную в датасет\nhead(data, 10)\n\n   number        X        Z T1 T2 T3 T4 T5 T6\n1       1 20.01304 47.96214  1  0  1  0  0  1\n2       2 23.51814 40.12603  1  1  0  0  1  1\n3       3 20.86284 80.53570  1  0  1  1  0  1\n4       4 24.18112 75.02123  1  1  0  1  1  0\n5       5 24.58327 29.81667  1  0  0  1  1  1\n6       6 18.31890 58.09705  1  1  1  1  0  0\n7       7 21.69674 42.08104  1  0  0  1  1  0\n8       8 24.24693 18.58498  1  1  0  0  1  1\n9       9 21.86005 63.00240  1  0  0  0  1  1\n10     10 21.19630 58.41577  1  1  1  0  0  1\n\n\n\n\n1.3.2.3.2 Пакет radomizr\n\nlibrary('randomizr') \nset.seed(123)\nT7 &lt;- complete_ra(N=N, m=N/2)\ndata$T7 &lt;- T7 # добавляем переменную в датасет\nhead(data, 10)\n\n   number        X        Z T1 T2 T3 T4 T5 T6 T7\n1       1 20.01304 47.96214  1  0  1  0  0  1  0\n2       2 23.51814 40.12603  1  1  0  0  1  1  0\n3       3 20.86284 80.53570  1  0  1  1  0  1  0\n4       4 24.18112 75.02123  1  1  0  1  1  0  1\n5       5 24.58327 29.81667  1  0  0  1  1  1  0\n6       6 18.31890 58.09705  1  1  1  1  0  0  1\n7       7 21.69674 42.08104  1  0  0  1  1  0  1\n8       8 24.24693 18.58498  1  1  0  0  1  1  0\n9       9 21.86005 63.00240  1  0  0  0  1  1  0\n10     10 21.19630 58.41577  1  1  1  0  0  1  0\n\n\n\n\n\n1.3.2.4 Хэш-функции\nСуществует ряд ситуаций, когда подходы к рандомизации, которые мы разобрали выше, работают не очень хорошо. Например, в вашу выборку добавилось несколько наблюдений, которые по какой-то причине добавились не в конец вашего датасета, а может у вас есть какая-то хитрая сортировка датасета. В этом случае рандомизация не будет воспроизводимой, а тритмент и контрольная группы будут различаться. Однако есть способ решить эту сложность.\nХэш-функция (hash function) – функция, осуществляющая преобразование массива входных данных произвольной длины в выходную битовую строку установленной длины, выполняемое определённым алгоритмом. Преобразование, производимое хэш-функцией, называется хэшированием.\nХэш-функции применяются в следующих случаях:\n\nпри построении ассоциативных массивов;\nпри поиске дубликатов в последовательностях наборов данных;\nпри построении уникальных идентификаторов для наборов данных;\nпри вычислении контрольных сумм от данных (сигнала) для последующего обнаружения в них ошибок (возникших случайно или внесённых намеренно), возникающих при хранении и/или передаче данных;\nпри сохранении паролей в системах защиты в виде хэш-кода (для восстановления пароля - по хэш-коду требуется функция, являющаяся обратной по отношению к использованной хэш-функции);\nпри выработке электронной подписи (на практике часто подписывается не само сообщение, а его “хэш-образ”);\nи др.\n\nДля нас важно то, что с помощью хэш-функции мы сможем взаимно однозначно переводить данные формата строки в число.\nПример хэширования с помощью пакета digest:\n\nlibrary(\"digest\")\nhash &lt;- digest('econometrics', algo=\"murmur32\")\nhash\n\n[1] \"24b6de5a\"\n\n\nПакет digest применяет хеш-функцию к произвольным объектам R. В пакете реализовано много разных алгоритмов преобразований, однако мы будем использовать алгоритм “murmur32” (подробнее почитать можно тут). Этот алгоритм совершенно не подходит для криптографических целей, но зато идеально подходит нам, поскольку он 32-битный, что позволяет нам перевести полученный хэш-код в целое число.\nПрежде чем начать разбирать пример, немного отвлечемся на техническую полезную вещь – функцию sapply().\nПро семейство apply функций рекомендую почитать подробнее на русском тут или тут, а на английском тут.\nПрелесть функции sapply() состоит в том, что она позволяет нам избежать громоздких циклов при написании кода и ускорить вычисления благодаря “векторной ориентированности” языка R. Например, функция позволяет нам найти минимальное и максимальное значение для каждой из ковариат:\n\nsapply(list(X,Z), min)\n\n[1] 18.003257  3.804506\n\nsapply(list(X,Z), max)\n\n[1]  24.99583 127.80742\n\n\nТо есть функция проводит однотипную операцию (по сути вложенную функцию) над каждым элементом списка. Если кто-то хорошо владеет python, то аналогичной функцией там является map().\nВернемся к нашей симуляции. Изначально мы это все затеяли, чтобы сделать хорошую рандомизацию. Сначала хэшируем номера наших наблюдений. Так делать не очень хорошо, обычно, для хэширования данных используют ФИО и/или СНИЛС, но мы не будем ради этого громоздить генерацию еще одной переменной. Для иллюстрации просто воспользуемся номерами, это тоже сработает.\n\nhashes &lt;- sapply(data$number, function(x) {digest(x, algo=\"murmur32\")}) # хэшируем строчки\nhashes[1:20]\n\n [1] \"5e6216f3\" \"8b8b3789\" \"ad1bf356\" \"b2df92b2\" \"1d1b8e3a\" \"98d09cab\"\n [7] \"2e366c5a\" \"4d110361\" \"91d6bfe0\" \"f568e543\" \"08bd74cd\" \"e979af4b\"\n[13] \"a82e5827\" \"485cbd08\" \"bc4e5bd8\" \"95f68430\" \"7180d744\" \"da414596\"\n[19] \"70aa2885\" \"afd0ffd2\"\n\n\nДалее нужно перевести получившиеся строчки в цифровой числовой. Функция strtoi() конвертирует строковое представление числа, которое хранится в строке, в длинное целое.\n\nresult &lt;- strtoi(substring(hashes, 2), base=16) \nresult[1:20]\n\n [1] 241309427 193673097 219935574  48206514 219909690 147889323 238447706\n [8] 219218785  30851040  90760515 146633933 158969675 137254951 140295432\n[15] 206461912 100041776  25220932 172049814  11151493 265355218\n\n\nДалее, используя эти числа, нужно как-то разбить выборку на тритмент и контроль. Будем смотреть на последнюю цифру, если она меньше 5, то наблюдение попадет в тритмент, если больше – в контроль.\n\nT8 &lt;- result %% 10 &lt; 5 # берем остаток от деления на 10 (получится последняя цифра) и сравниваем его с 5\ndata$T8 &lt;- as.numeric(T8) # переводим из логического типа в числовой и добавляем в датасет\ndata$T8[1:20]\n\n [1] 0 0 1 1 1 1 0 0 1 0 1 0 1 1 1 0 1 1 1 0\n\n\nПроверим нашу рандомизацию на сбалансированность:\n\nsummary(data)\n\n     number             X               Z                 T1            T2     \n Min.   :   1.0   Min.   :18.00   Min.   :  3.805   Min.   :0.0   Min.   :0.0  \n 1st Qu.: 250.8   1st Qu.:19.78   1st Qu.: 46.232   1st Qu.:0.0   1st Qu.:0.0  \n Median : 500.5   Median :21.43   Median : 60.576   Median :0.5   Median :0.5  \n Mean   : 500.5   Mean   :21.48   Mean   : 60.239   Mean   :0.5   Mean   :0.5  \n 3rd Qu.: 750.2   3rd Qu.:23.23   3rd Qu.: 73.101   3rd Qu.:1.0   3rd Qu.:1.0  \n Max.   :1000.0   Max.   :25.00   Max.   :127.807   Max.   :1.0   Max.   :1.0  \n       T3            T4              T5              T6            T7     \n Min.   :0.0   Min.   :0.000   Min.   :0.000   Min.   :0.0   Min.   :0.0  \n 1st Qu.:0.0   1st Qu.:0.000   1st Qu.:0.000   1st Qu.:0.0   1st Qu.:0.0  \n Median :0.5   Median :1.000   Median :0.000   Median :0.5   Median :0.5  \n Mean   :0.5   Mean   :0.505   Mean   :0.493   Mean   :0.5   Mean   :0.5  \n 3rd Qu.:1.0   3rd Qu.:1.000   3rd Qu.:1.000   3rd Qu.:1.0   3rd Qu.:1.0  \n Max.   :1.0   Max.   :1.000   Max.   :1.000   Max.   :1.0   Max.   :1.0  \n       T8       \n Min.   :0.000  \n 1st Qu.:0.000  \n Median :1.000  \n Mean   :0.508  \n 3rd Qu.:1.000  \n Max.   :1.000  \n\n\n\n\n\n1.3.3 Реализация исходов\nПосчитаем потенциальные исходы:\n\nY0 &lt;- 240 - 3*X - Z + 15*0 + e # T=0\nY1 &lt;- 240 - 3*X - Z + 15*1 + e # T=1\ndata$Y0 &lt;- Y0 # добавляем переменные в датасет\ndata$Y1 &lt;- Y1\n\nА также наблюдаемые исходы:\n\ndata$Y &lt;- T1*Y1 + (1-T1)*Y0\n\nМожно ли было бы сделать все то же самое за меньшее число строчек кода и время? Конечно, можно. Более того, если бы похожую процедуру вам пришлось бы по каким-то причинам проводить несколько раз, например, когда у вас несколько экспериментов, функция для вас просто была бы незаменимым помощником. Еще раз генерим данные о нашем умозрительном эксперименте, но на этот раз для общего развития попробуем переписать все то же самое с помощью функций (не пугайтесь, на семинарах мы отдельно еще раз обсудим техническую сторону вопроса про функции):\n\nФункция для генерации данных\n\n\ngenerate_data &lt;- function(N){\n  N=N\n  X &lt;- runif(N, 18, 25)\n  Z &lt;- rnorm(N, 60, 20)\n  e0 &lt;- rnorm(N/2, 0, 1)\n  e1 &lt;- rnorm(N/2, 0, 1)\n  number &lt;- 1:N\n  Y0 &lt;- 240 - 3*X - Z + 15*0 + e0 \n  Y1 &lt;- 240 - 3*X - Z + 15*1 + e1 \n  data &lt;- data.frame(number = number, X=X, Z=Z, Y0=Y0, Y1=Y1)\n}\n\n\nФункция для рандомизации\n\n\nrandomization &lt;- function(data, type){\n  N &lt;- nrow(data)\n  if (type=='in order'){\n    T &lt;- c(rep(1,N/2), rep(0,N/2))\n    data$T &lt;- T\n  } else if (type=='by turns'){\n    T &lt;- rep(0:1, N/2)\n    data$T &lt;- T\n  } else if (type=='unif'){\n    V &lt;- runif(N)\n    T &lt;- as.numeric(V1 &lt; median(V1))\n    data$T &lt;- T\n  } else if (type=='norm'){\n    V &lt;- rnorm(N) \n    T &lt;- as.numeric(V2&gt;0)\n    data$T &lt;- T\n  } else if (type=='binom'){\n    T &lt;- rbinom(N, 1, 0.5)\n  }\n  return(data)\n}\n\n\nФункция для расчета наблюдаемого исхода\n\n\noutcome &lt;- function(data){\n  observed_data &lt;- data\n  observed_data$Y &lt;- data$T*observed_data$Y1 + (1 - data$T)*observed_data$Y0\n  return(observed_data)\n}\n\nА теперь посмотрим, сколько строчек займет наша симуляция с использованием функций:\n\nset.seed(123)\ndata &lt;- generate_data(1000)\nset.seed(123)\ndata &lt;- randomization(data=data, type='in order')\ndata &lt;- outcome(data=data)\ntail(data,10)\n\n     number        X         Z        Y0        Y1 T         Y\n991     991 18.61054  75.36015 107.71110 125.93429 0 107.71110\n992     992 19.56646  37.83344 144.39269 158.58181 0 144.39269\n993     993 22.00504  44.27528 129.95640 144.11565 0 129.95640\n994     994 20.80118 105.68233  71.17735  87.99218 0  71.17735\n995     995 21.95826  38.13398 134.71123 149.89166 0 134.71123\n996     996 23.80737  64.28959 104.36495 120.01488 0 104.36495\n997     997 22.49480  77.85142  94.91935 111.10506 0  94.91935\n998     998 20.74049  80.37516  97.68081 112.19320 0  97.68081\n999     999 22.96706  81.78224  89.85344 105.76786 0  89.85344\n1000   1000 18.76177  56.73742 126.51679 142.61883 0 126.51679\n\n\n\n\n1.3.4 Считаем эффект\nКогда данные подготовлены, мы забываем, что что-то о них знали :)\nС данного момента мы действуем согласно предпосылке, что мы знаем только \\(Y\\), \\(X\\) и \\(T\\).\nПоскольку мы знаем, что тритмент распределялся среди наблюдений случайно, мы можем сделать вывод, что предпосылка о независимости воздействия выполнена. Также мы знаем, что данные устроены так, что SUTVA тоже выполнена. Следовательно, можем использовать обычную разницу в средних, чтобы оценить эффнект воздействия:\n\\(\\widehat{ATE} = \\overline{Y_1} - \\overline{Y_0}\\)\n\nATE_hat &lt;- mean(data[which(data$T == 1),]$Y) - mean(data[which(data$T == 0),]$Y)\nATE_hat\n\n[1] 15.53169\n\n\nИз курса ЭКМ-2 помним, что то же самое можно было бы получить, с помощью обычного парного МНК:\n\nmodel1 &lt;- lm(Y ~ T, data=data)\nsummary(model1)\n\n\nCall:\nlm(formula = Y ~ T, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-78.525 -14.782  -0.268  14.040  64.919 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 115.0500     0.9369  122.80   &lt;2e-16 ***\nT            15.5317     1.3249   11.72   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 20.95 on 998 degrees of freedom\nMultiple R-squared:  0.121, Adjusted R-squared:  0.1202 \nF-statistic: 137.4 on 1 and 998 DF,  p-value: &lt; 2.2e-16\n\n\nЕсли обе предпосылки выполнены, то оценка должна быть несмещенной даже без контрольных переменных (ковариат). Попробуем их добавить и сравним оценки эффекта:\n\nmodel2 &lt;- lm(Y ~ T + X + Z, data=data)\nsummary(model2)\n\n\nCall:\nlm(formula = Y ~ T + X + Z, data = data)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-2.97985 -0.63057 -0.01498  0.69005  3.04683 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 240.123033   0.347927   690.2   &lt;2e-16 ***\nT            14.874547   0.061883   240.4   &lt;2e-16 ***\nX            -2.988124   0.015384  -194.2   &lt;2e-16 ***\nZ            -1.005280   0.001546  -650.4   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9783 on 996 degrees of freedom\nMultiple R-squared:  0.9981,    Adjusted R-squared:  0.9981 \nF-statistic: 1.732e+05 on 3 and 996 DF,  p-value: &lt; 2.2e-16\n\n\nВидим, что результаты устойчивы, величина эффекта практически не изменилась, но существенно уменьшилась его стандартная ошибка. Вывод: контрольные переменные хорошо включать для снижения дисперсии оценок.\nДалее в качестве упраженения посчитаем средние эффекты на разных группах:\n\nATT &lt;- mean(data[which(data$T == 1),]$Y1) - mean(data[which(data$T == 1),]$Y0)\nATT\n\n[1] 14.87723\n\n\n\nATnT &lt;- mean(data[which(data$T == 0),]$Y1) - mean(data[which(data$T == 0),]$Y0)\nATnT\n\n[1] 14.87723\n\n\nПолучили, то что и должны были получить \\(ATT = ATnT\\). Если мы вернемся в раздел, где мы подготовливали данные, то увидим, что в двух потенциальных исходах мы “зашифровали” одинаковый эффект:\n\n\\(Y_0 = 120 - 3 \\cdot X - Z + 15 \\cdot \\underbrace{T}_{= 0} + \\varepsilon = 120 - 3 \\cdot X - Z + \\varepsilon\\)\n\\(Y_1 = 120 - 3 \\cdot X - Z + 15 \\cdot \\underbrace{T}_{= 1} + \\varepsilon = 120 - 3 \\cdot X - Z + 15 + \\varepsilon\\)\n\nСодержательно это иллюстрирует то, что эффект воздействия гомогенен, то есть \\(\\text{Heterogeneous treatment effect bias} = (1-\\pi)(ATT - ATnT) = 0\\).\n\n\n1.3.5 Баланс ковариатов\nТеперь проверим насколько наша рандомизация оказалась хорошей, то есть проверим контрольную и тритмент группу на “похожесть”. Сравним средние значения ковариат в двух группах.\n\n1.3.5.1 Сравнение средних\n\nmean(data[which(data$T == 1),]$X) - mean(data[which(data$T == 0),]$X)\n\n[1] -0.02791759\n\nmean(data[which(data$T == 1),]$Z) - mean(data[which(data$T == 0),]$Z)\n\n[1] -0.5707093\n\n\nЭто не очень информативный и субъективный способ, но если мы вспомним, что порядок значений ковариат измерялся десятками, то можно сделать вывод, что группы в среднем похожи.\n\n\n1.3.5.2 Тест Стьюдента\nА теперь проведем тест на разницу в средних с помощью формального t-теста Стьюдента:\n\n\\(H_0:\\) среднее значение параметра в группах одинаковое, группы не различаются\n\\(H_1:\\) среднее значение параметра в группах разное, группы различаются\n\n\nt.test(data[which(data$T == 1),]$X, data[which(data$T == 0),]$X)\n\n\n    Welch Two Sample t-test\n\ndata:  data[which(data$T == 1), ]$X and data[which(data$T == 0), ]$X\nt = -0.21924, df = 997.51, p-value = 0.8265\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -0.2777933  0.2219581\nsample estimates:\nmean of x mean of y \n 21.46699  21.49490 \n\nt.test(data[which(data$T == 1),]$Z, data[which(data$T == 0),]$Z)\n\n\n    Welch Two Sample t-test\n\ndata:  data[which(data$T == 1), ]$Z and data[which(data$T == 0), ]$Z\nt = -0.45032, df = 997.68, p-value = 0.6526\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.057656  1.916238\nsample estimates:\nmean of x mean of y \n 59.95331  60.52402 \n\n\nСогласно значению p-value мы принимаем \\(H_0\\) и делаем вывод, что группы одинаковые.\n\n\n1.3.5.3 Использование готовых пакетов\n\nlibrary(\"tableone\")\ntable &lt;- CreateTableOne(vars=c(\"X\", \"Z\"), strata=\"T\", data=data, test=TRUE)\nprint(table)\n\n               Stratified by T\n                0             1             p      test\n  n               500           500                    \n  X (mean (SD)) 21.49 (2.04)  21.47 (1.99)   0.827     \n  Z (mean (SD)) 60.52 (19.86) 59.95 (20.22)  0.653"
  },
  {
    "objectID": "experiments.html#про-важность-предпосылок-гаусса-маркова",
    "href": "experiments.html#про-важность-предпосылок-гаусса-маркова",
    "title": "1  Эксперименты",
    "section": "1.4 Про важность предпосылок Гаусса-Маркова",
    "text": "1.4 Про важность предпосылок Гаусса-Маркова\n\n1.4.1 Предпосылки Гаусса-Маркова\n\nЛинейная модель: \\(Y_i=\\tau T_i+\\beta X_i+\\varepsilon_i\\)\n\\(T_i\\) не выражается линейно через \\(X_i\\)\n\\(\\mathbb{E}\\left(\\varepsilon_i\\right)=0\\)\nГомоскедастичность, некоррелированность ошибок \\(\\mathbb{V}\\left(\\varepsilon_i\\right)=\\sigma I\\)\nЭкзогенность \\(\\operatorname{Cov}\\left(X_i, \\varepsilon_i\\right)=0\\)\nОцениваем методом наименьших квадратов: \\[\n\\left(Y_i-\\hat{\\tau} T_i-\\hat{\\beta} X_i\\right)^2 \\rightarrow \\min _{\\hat{\\tau}, \\hat{\\beta}}\n\\]\nСвойства оценки (теорема Гаусса-Маркова): несмещенность, эффективность, состоятельность\n\n\n\n1.4.2 Пример\nМы располагаем данными из 1000 наблюдений, про которые известно:\n\n\\(X_i \\sim U[0,1]\\) - контрольная переменная: успехи команды в прошлом году\n\\(T_i \\mid X_i \\sim \\operatorname{Bernoulli}\\left(0.1+0.8 X_i\\right)\\) - бинарная переменная переменная интереса: решение тренера взять команду\n\\(Y_i=f\\left(X_i, T_i\\right)+\\varepsilon_i\\) - переменная исхода: успехи команды в этом году\nВ соответствии с предпосылками оценим \\(Y_i \\sim T_i+X_i\\)\nТо же ли самое получится, если \\(T_i \\sim \\operatorname{Bernoulli}(0.5)\\) и оценим \\(Y_i \\sim T_i\\)?\n\n\n1.4.2.1 Генерация данных\nСгенерим данные согласно условию:\n\nlibrary(stargazer)\n\nset.seed(123)\n\nX &lt;- runif(1000, 0, 1)\n\nY0 &lt;- rnorm(1000)\nY1 &lt;- 10 * X + rnorm(1000)\n\n\n\n1.4.2.2 Генерация тритмента\nСлучай 1: эндогенный тритмент\n\nT_one = rbinom(1000, 1, 0.1 + 0.8*X)\nY_one = Y1 * T_one + Y0 * (1 - T_one)\n\ndata_one = data.frame(X=X, Y=Y_one, T=T_one)\n\nСлучай 2: экзогенный тритмент\n\nT_two = rbinom(1000, 1, 0.5)\nY_two = Y1 * T_two + Y0 * (1 - T_two)\n\ndata_two = data.frame(X=X, Y=Y_two, T=T_two)\n\n\n\n1.4.2.3 Оценка эффекта\nСравним оценки:\n\nmodel_one_1 &lt;- lm(Y ~ T, data=data_one)\nmodel_one_2 &lt;- lm(Y ~ T + X, data=data_one)\nmodel_two_1 &lt;- lm(Y ~ T, data=data_two)\nmodel_two_2 &lt;- lm(Y ~ T + X, data=data_two)\n\n#stargazer(model_one_1, model_one_2, model_two_1, model_two_2, type = 'text') \n\n# В обычной жизни вы просто можете пользоваться старгейзером, как в комментраии выше\n# Чтобы конкретно на этой странице влезло 4 регрессии, я воспользуюсь другой функцией msummary\nm_list &lt;- list(endogenous_without_control = model_one_1, \n               endogenous_with_control = model_one_2,\n               exogenous_without_control = model_two_1, \n               exogenous_with_control = model_two_2)\nlibrary('modelsummary')\nmsummary(m_list, output = 'markdown', stars = TRUE, title = 'Сравнение моделей')\n\n\nСравнение моделей\n\n\n\n\n\n\n\n\n\n\nendogenous_without_control\nendogenous_with_control\nexogenous_without_control\nexogenous_with_control\n\n\n\n\n(Intercept)\n0.022\n-1.847***\n0.030\n-2.234***\n\n\n\n(0.094)\n(0.102)\n(0.096)\n(0.120)\n\n\nT\n6.260***\n4.859***\n5.069***\n5.007***\n\n\n\n(0.131)\n(0.114)\n(0.137)\n(0.109)\n\n\nX\n\n5.206***\n\n4.612***\n\n\n\n\n(0.199)\n\n(0.189)\n\n\nNum.Obs.\n1000\n1000\n1000\n1000\n\n\nR2\n0.695\n0.820\n0.577\n0.735\n\n\nR2 Adj.\n0.695\n0.819\n0.577\n0.735\n\n\nAIC\n4299.4\n3778.1\n4390.7\n3924.6\n\n\nBIC\n4314.2\n3797.7\n4405.4\n3944.3\n\n\nLog.Lik.\n-2146.714\n-1885.056\n-2192.343\n-1958.311\n\n\nF\n2279.232\n2264.086\n1363.774\n1385.366\n\n\nRMSE\n2.07\n1.59\n2.17\n1.71\n\n\n\nNote: ^^ + p &lt; 0.1, * p &lt; 0.05, ** p &lt; 0.01, *** p &lt; 0.001\n\n\nВыводы:\n\nПо теореме Гаусса-Маркова мы должны были получить 2 состоятельные (значит одинаковые) оценки\nОни отличаются, потому что модель нелинейная: тренер решает тренировать только те команды, которые будут успешны, поэтому и эффект высокий\nЕсли бы эффект тренера всегда был одинаковым, теорема Гаусса-Маркова выполнялась бы и оценки действительно оказались бы одинаковыми.\n\n\n\n1.4.2.4 Баланс ковариатов\n\n\\(H_0:\\) среднее значение параметра в группах одинаковое, группы не различаются\n\\(H_1:\\) среднее значение параметра в группах разное, группы различаются\n\n\ntable1 &lt;- CreateTableOne(vars=c(\"X\", \"Z\"), strata=\"T\", data=data_one, test=TRUE)\n\nWarning in ModuleReturnVarsExist(vars, data): The data frame does not have: Z\nDropped\n\nprint(table1)\n\n               Stratified by T\n                0           1           p      test\n  n              486         514                   \n  X (mean (SD)) 0.36 (0.25) 0.63 (0.26) &lt;0.001     \n\ntable2 &lt;- CreateTableOne(vars=c(\"X\", \"Z\"), strata=\"T\", data=data_two, test=TRUE)\n\nWarning in ModuleReturnVarsExist(vars, data): The data frame does not have: Z\nDropped\n\nprint(table2)\n\n               Stratified by T\n                0           1           p      test\n  n              514         486                   \n  X (mean (SD)) 0.49 (0.29) 0.50 (0.29)  0.463     \n\n\nСогласно значению p-value мы принимаем \\(H_0\\) для второго случая, где тритмент экзогенный, и делаем вывод, что группы одинаковые; для первого случая с эндогенным тритментом баланс ковариатов не выполняется."
  },
  {
    "objectID": "prestratification.html#стратификация-stratification-sampling",
    "href": "prestratification.html#стратификация-stratification-sampling",
    "title": "4  Престратификация",
    "section": "4.1 Стратификация (stratification sampling)",
    "text": "4.1 Стратификация (stratification sampling)\nМы помним, что снижение дисперсии снижает необходимое число наблюдений.\nПредположим, что мы выбрали переменную, по которой мы можем разбить нашу выборку на группы (страты). Пусть таких групп K штук, а \\(n_k\\) – численность каждой из них, то есть \\(\\displaystyle{\\sum_{k=1}^K n_k = N}\\), где \\(N\\) величина генеральной совокупности. Тогда вероятность попасть в одну из групп равняется \\(p_k = \\frac{n_k}{N}\\) – доля людей из \\(k\\)-й страты в генеральной совокупности.\nПусть наша зависимая переменная равна \\(Y\\), причем \\(\\mathbb{E}(Y)=\\mu\\) и \\(var(Y)=\\sigma^2\\). Тогда среднее значение зависимой переменной равно:\n\nОбычное среднее по всей выборке:\\(\\displaystyle{\\bar{Y}=\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} Y_{kj}}\\)\nСредневзвешенное при стратификации равно сумме средних в каждой страте, взвешенных по вероятностям попасть в каждую из этих страт: \\(\\displaystyle{\\hat{Y}_{\\text{strat}}=\\sum_{k=1}^K p_k \\bar{Y}_k}\\), где \\(\\displaystyle{\\bar{Y}_k=\\frac{1}{n_k} \\sum_{j=1}^{n_k} Y_{kj}}\\) среднее значение метрики внутри \\(k\\)-й страты.\n\nРаспишем среднее при стратификации подробнее:\n\\(\\displaystyle{\\underbrace{\\sum_{k=1}^K p_k \\bar{Y}_k}_{\\hat{Y}_{\\text{strat}}} = \\sum_{k=1}^K \\frac{n_k}{N} \\frac{1}{n_k} \\sum_{j=1}^{n_k} Y_{kj} = \\underbrace{\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} Y_{kj}}_{\\bar{Y}}}\\) обе средние равны.\nНайдем среднее и дисперсию зависимой переменной при стратификации.\n\nСреднее: \\(\\displaystyle{\\mathbb{E}\\left(\\hat{Y}_{\\text{strat }}\\right)=\\mathbb{E}\\left[\\sum_{k=1}^K p_k \\bar{Y}_k\\right]=\\sum_{k=1}^K p_k \\mathbb{E}\\left(\\bar{Y}_k\\right)=\\sum_{k=1}^K p_k \\mu_k=\\boxed{\\mu}}\\)\nДисперсия: \\(\\displaystyle{var\\left(\\hat{Y}_{\\text{strat }}\\right)=\\operatorname{var}\\left[\\sum_{k=1}^K p_k \\bar{Y}_k\\right]=\\sum_{k=1}^K p_k^2 var\\left(\\bar{Y}_k\\right)=\\sum_{k=1}^K \\frac{n_k^2}{N^2} \\frac{1}{n_k^2} n_k \\sigma_k^2 = \\frac{1}{N} \\sum_{k=1}^K \\frac{n_k}{N} \\sigma_k^2 = \\boxed{\\frac{1}{N} \\sum_{k=1}^K p_k \\sigma_k^2}}\\)(1)"
  },
  {
    "objectID": "prestratification.html#простая-рандомизация-simple-random-sampling",
    "href": "prestratification.html#простая-рандомизация-simple-random-sampling",
    "title": "4  Престратификация",
    "section": "4.2 Простая рандомизация (simple random sampling)",
    "text": "4.2 Простая рандомизация (simple random sampling)\nАналогично найдем среднее и дисперсию зависимой переменной при классическом эксперименте.\n\nСреднее: \\(\\displaystyle{\\mathbb{E}(\\bar{Y})=\\mathbb{E}\\left[\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} Y_{k j}\\right]=\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} \\mathbb{E}\\left(Y_{k j}\\right)=\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} \\mu = \\frac{1}{N} \\sum_{k=1}^K n_k \\mu = \\frac{1}{N} N \\mu=\\boxed{\\mu}}\\)\nДисперсия: \\(\\displaystyle{\\operatorname{var}(\\bar{Y})=var\\left[\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} Y_{kj}\\right]= \\frac{1}{N^2} \\sum_{k=1}^K \\sum_{j=1}^{n_k} var\\left(Y_{kj}\\right) = \\frac{1}{N^2} \\sum_{k=1}^K n_k \\sigma^2 = \\frac{N \\sigma^2}{N^2}=\\boxed{\\frac{\\sigma^2}{N}}}\\)(2)"
  },
  {
    "objectID": "prestratification.html#total-variance-law",
    "href": "prestratification.html#total-variance-law",
    "title": "4  Престратификация",
    "section": "4.3 Total variance law",
    "text": "4.3 Total variance law\nДисперсия зависимой переменной при рандомизированном эксперименте может быть представлена в виде суммы внутригрупповой и межгрупповой дисперсии.\nДля этого нам понадобится total variance law (см. доказательство в приложении): \\(\\displaystyle{var(Y)=var[\\mathbb{E}(Y \\mid X)] + \\mathbb{E}[var(Y\\mid X)]}\\)\nПусть \\(Z\\) – номер страты от 1 до K, тогда: \\(\\displaystyle{var(Y)=\\mathbb{E}(var(Y \\mid Z))+var(\\mathbb{E}(Y \\mid Z))=}\\)\n\\(\\displaystyle{=\\left\\{ I(Z = k) \\text{ индикаторная переменная, равная 1, если $Z = k$, и равная нулю иначе} \\right\\}= }\\)\n\\(\\displaystyle{=\\mathbb{E}\\left[\\sum_{k=1}^K \\sigma_k^2 I(Z=k)\\right]+ var\\left[\\sum_{k=1}^K \\mu_k I(Z=k)\\right]=}\\)\n\\(\\displaystyle{=\\sum_{k=1}^K \\sigma_k^2 \\mathbb{E}[I(Z=k)]+\\mathbb{E}\\left[\\sum_{k=1}^K \\mu_k I(Z=k)\\right]^2-\\left[\\mathbb{E}\\left[\\sum_{k=1}^K \\mu_k I(Z=k)\\right]\\right]^2=}\\)\n\\(\\displaystyle{= \\sum_{k=1}^K \\sigma_k^2 p_k + \\sum_{k=1}^K \\mu_k^2 p_k - \\mu^2 = \\{*\\} = \\sum_{k=1}^K \\sigma_k^2 p_k + \\sum_{k=1}^K p_k (\\mu_k - \\mu)^2}\\) (3)\n\\(\\displaystyle{(*): \\sum_{k=1}^K p_k(\\mu_k - \\mu)^2 = \\sum_{k=1}^K p_k\\left(\\mu_k^2 - 2\\mu\\mu_k + \\mu^2\\right) =}\\)\n\\(\\displaystyle{= \\sum_{k=1}^K p_k \\mu_k^2 - 2\\mu \\sum_{k=1}^K \\mu_k p_k+ \\mu^2 \\sum_{k=1}^K p_k = \\sum_{k=1}^K \\mu_k^2 p_k - 2\\mu^2 + \\mu^2 =\\sum_{k=1}^K \\mu_k^2 p_k - \\mu^2}\\)\nИз (2) и (3) следует:\n\\(\\displaystyle{var(\\bar{Y})=\\frac{\\sigma^2}{N}}\\)\n\\(\\displaystyle{var(Y)=\\sum_{k=1}^K \\sigma_k^2 p_k+\\sum_{k=1}^K p_k\\left(\\mu_k-\\mu\\right)^2}\\)\n\\(\\displaystyle{var(\\bar{Y})= \\underbrace{\\frac{1}{N} \\sum_{k=1}^K p_k \\sigma_k^2}_{\\text{внутригрупповая дисперсия}} + \\underbrace{\\frac{1}{N} \\sum_{k=1}^K p_k \\left(\\mu_k-\\mu\\right)^2}_{\\text{межгрупповая дисперсия}}}\\) (4)\nИз (1) и (4) следует:\n\\(\\displaystyle{var\\left(\\hat{Y}_{\\text{strat}}\\right) = \\frac{1}{N} \\sum_{k=1}^K p_k \\sigma_k^2}\\)\n\\(\\displaystyle{var(\\bar{Y})= \\underbrace{\\frac{1}{N} \\sum_{k=1}^K p_k \\sigma_k^2}_{\\text{внутригрупповая дисперсия}} + \\underbrace{\\frac{1}{N} \\sum_{k=1}^K p_k \\left(\\mu_k-\\mu\\right)^2}_{\\text{межгрупповая дисперсия}}}\\)\nДисперсия среднего значения зависимой переменной всегда больше, чем дисперсия среднего значения зависимой переменной в случае стратификации, поскольку межгрупповая дисперсия всегда неотрицательная. Таким образом, \\(\\displaystyle{var(\\bar{Y}) \\geqslant var\\left(\\hat{Y}_{\\text{strat }}\\right)}\\)"
  },
  {
    "objectID": "prestratification.html#приложение",
    "href": "prestratification.html#приложение",
    "title": "4  Престратификация",
    "section": "4.4 Приложение",
    "text": "4.4 Приложение\n\n4.4.1 Условные обозначения\n\n\\(Y\\) – зависимая переменная, причем\n\n\\(\\mathbb{E}(Y)=\\mu\\)\n\\(var(y)=\\sigma^2\\)\n\nВыборка разбита на \\(k\\) страт по показателю \\(X\\), то есть\n\n\\(\\mu_k\\) – среднее в страте\n\\(\\sigma^2_k\\) – дисперсия в страте\n\\(n_k\\) – численность в страты, то есть \\(\\sum_{k=1}^K n_k = N\\)\n\\(p_k = \\frac{n_k}{N}\\) – доля людей из \\(k\\)-й страты в генеральной совокупности\n\\(Y_{kj}\\) – метрика \\(j\\)-го человека из \\(k\\)-й страты\n\nТогда среднее значение зависимой переменной\n\n\\(\\displaystyle{\\bar{Y}=\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} Y_{kj}}\\) обычное среднее\n\\(\\displaystyle{\\hat{Y}_{\\text{strat}}=\\sum_{k=1}^K p_k \\bar{Y}_k}\\) среднее при стратификации\n\n\\(\\displaystyle{\\bar{Y}_k=\\frac{1}{n_k} \\sum_{j=1}^{n_k} Y_{kj}}\\) среднее значение метрики внутри \\(k\\)-й страты\n\n\\(\\displaystyle{\\underbrace{\\sum_{k=1}^K p_k \\bar{Y}_k}_{\\hat{Y}_{\\text{strat}}} = \\sum_{k=1}^K \\frac{n_k}{N} \\frac{1}{n_k} \\sum_{j=1}^{n_k} Y_{kj} = \\underbrace{\\frac{1}{N} \\sum_{k=1}^K \\sum_{j=1}^{n_k} Y_{kj}}_{\\bar{Y}}}\\) обе средние равны\n\n\n\n\n4.4.2 Total variance law\nЭто вспомогательный факт из математической статистики, который нам понадобится в дальнейших выкладках.\nДоказать:\n\\(\\displaystyle{var(Y)=var_X(\\mathbb{E}(Y \\mid X)) + \\mathbb{E}_X(var(yX\\mid X))}\\)\nДоказательство:\n\\(\\displaystyle{var(Y)=\\mathbb{E}\\left(Y^2\\right)-(E(Y))^2 =}\\)\n\\(\\displaystyle{= \\left\\{\\text{закон повтороного мат. ожидания } \\mathbb{E}(Y) = \\mathbb{E}(\\mathbb{E}(Y \\mid X))\\right\\} =}\\)\n\\(\\displaystyle{=\\mathbb{E}\\left(\\mathbb{E}\\left(Y^2 \\mid X\\right)\\right)-\\mathbb{E}(\\mathbb{E}(Y \\mid X))]^2=}\\)\n\\(\\displaystyle{=\\left\\{\\text{добавим и вычтем } \\mathbb{E}\\left[(\\mathbb{E}(Y \\mid X))^2 \\mid X\\right] \\right\\} =}\\)\n\\(\\displaystyle{=\\underbrace{\\mathbb{E}\\left[\\mathbb{E}\\left(Y^2 \\mid X\\right)-(\\mathbb{E}(Y \\mid X))^2 \\mid X\\right]}_{\\mathbb{E}[var(Y \\mid X)]}+\\underbrace{ \\mathbb{E}\\left[(\\mathbb{E}(Y \\mid X))^2 \\mid X\\right]-\\mathbb{E}[\\mathbb{E}(Y \\mid X)] \\mathbb{E}[\\mathbb{E}(Y \\mid X)]}_{var[\\mathbb{E}(Y \\mid X)]}=}\\)\n\\(\\displaystyle{=\\mathbb{E}[\\operatorname{var}(Y \\mid X)]+\\operatorname{var}[\\mathbb{E}(Y \\mid X)]}\\)"
  },
  {
    "objectID": "prestratification.html#симуляция",
    "href": "prestratification.html#симуляция",
    "title": "4  Престратификация",
    "section": "4.5 Симуляция",
    "text": "4.5 Симуляция\nВ данной симуляции мы попробуем эмпирически доказать, что дисперсия оценки, полученной с помощью престратификации, действительно меньше, чем при оценивании с обычной рандомизацией. Чтобы получить распределение оценок, нам нужно осуществить множество реализаций нашего эксперимента. Для этого мы воспользуемся циклами.\n\nlibrary('dplyr')\n\nДля начала мы заготовим несколько функций, которые мы далее сможем использовать, чтобы наш код был более компактный. Функция generate_data будет генерить нам набор данных размером N наблюдений с параметрами ниже:\n\ngenerate_data &lt;- function(N){\n  N &lt;- N\n  X &lt;- runif(N, 5, 28)\n  e &lt;- rnorm(N, 0, 1)\n  number &lt;- 1:N\n  Y0 &lt;- 10 + X + e\n  Y1 &lt;- Y0 + 7\n  data &lt;- data.frame(number=number, X=X, Y0=Y0, Y1=Y1)\n  return(data)\n}\n\nФункция basic_experiment, ссылаясь на функцию generate_data, создает набор данных размером rows наблюдений, проводит на этих данных рандомизацию и считает эффект:\n\nbasic_experiment &lt;- function(rows){\n  data &lt;- generate_data(N=rows)\n  data$T &lt;- rbinom(rows, 1, 0.5)\n  data$Y &lt;- data$T*data$Y1 + (1-data$T)*data$Y0\n  mod &lt;- lm(Y~T, data)\n  ATE &lt;- summary(mod)$coefficients[2]\n  return(ATE)\n}\n\nФункция stratification_experiment, ссылаясь на функцию generate_data, создает набор данных размером rows наблюдений, затем разбивает его на страты и внутри каждой страты проводит рандомизацию, после чего считает эффект воздействия:\n\nstratification_experiment &lt;- function(rows){\n  data &lt;- generate_data(rows)\n  data &lt;- data[order(data$X),]\n  trashhold &lt;- quantile(data$X)\n  data$group &lt;- cut(data$X, breaks = trashhold, \n                    include.lowest = TRUE, labels = c(1:4))\n  data &lt;- data %&gt;% \n    group_by(group) %&gt;% \n    mutate(1:length(X) %in% sample.int(length(X), length(X)/2))\n  colnames(data)[6] &lt;- 'T'\n  data$T &lt;- as.numeric(data$T)\n  data$Y &lt;- data$T*data$Y1 + (1-data$T)*data$Y0\n  mod &lt;- lm(Y~T, data)\n  ATE &lt;- summary(mod)$coefficients[2]\n  return(ATE)\n}\n\nФункция stratification_experiment в зависимости от аргумента type проводит симуляцию либо со стратификацией (type='strata'), либо без нее (type='basic'). Внутри каждой “ветки” с условием реализуется цикл, который N раз проводит эксперимент с помощью функции, которую мы написали ранее – basic_experiment или stratification_experiment. Каждый раз результаты эксперимента (оценка эффекта) сохраняется в вектор ATEs.\n\nsimulation &lt;- function(N, rows, type){\n  if (type =='basic'){\n    ATEs &lt;- c()\n    i=1\n    while (i&lt;N+1) {\n      ATE &lt;- basic_experiment(rows)\n      ATEs &lt;- c(ATEs, ATE)\n      i=i+1\n    } \n  } else if (type =='strata'){\n    ATEs &lt;- c()\n    i=1\n    while (i&lt;N+1) {\n      ATE &lt;- stratification_experiment(rows)\n      ATEs &lt;- c(ATEs, ATE)\n      i=i+1\n    }\n  }\n  return(ATEs)\n}\n\nИспользуя функцию simulation, проводим симуляцию N=10000 раз, каждый раз создавая набор данных из rows=1000 со стратификацией (type='strata') и без нее (type='basic').\n\nstratification_ATEs &lt;- simulation(N=10000, rows=1000, type='strata')\nbasic_ATEs &lt;- simulation(N=10000, rows=1000, type='basic')\n\nПостроим гистограму, которая покажет нам, как распределены оценки эффекта в зависимости от способа рандомизации.\n\nhist(basic_ATEs, col=rgb(1, 0, 0, 0.5), freq=T)\nhist(stratification_ATEs, col=rgb(0, 0, 1, 0.5), freq=T, add=T)\n\n\n\n\nНаш теоретический вывод подтвердился. Действительно, дисперсия оценки, когда мы используем престратификацию, ниже, чем у обычной рандомизации."
  },
  {
    "objectID": "multiple_testing.html#проблема-множественного-тестирования-гипотез",
    "href": "multiple_testing.html#проблема-множественного-тестирования-гипотез",
    "title": "2  Множественное тестирование гипотез",
    "section": "2.1 Проблема множественного тестирования гипотез",
    "text": "2.1 Проблема множественного тестирования гипотез\nВаш исследовательский вопрос может быть таким, что вам интересно оценить воздействия разных типов тритмента, то есть у вас есть несколько экспериментальных групп и одна контрольная. При такой постановке мы хотим проверить не одну, а сразу много статистических гипотез о различии в группах. При проверке любой гипотезы существует вероятность совершить ошибку первого рода (отклонить нулевую гипотезу, если она верна = обнаружить эффект, которого нет). Особенность множественного тестирования гипотез состоит в том, что чем больше гипотез мы проверяем на одних и тех же данных, тем больше будет вероятность допустить как минимум одну ошибку первого рода – эффект множественных сравнений (multiple comparisons/testing).\nИсточниками множественного тестирования могут быть:\n\nНесколько типов воздействия (Multiple treatment arms)\nГетерогенное воздействие (Heterogeneous treatment effects)\nНесколько способов оценки (Multiple estimators)\nНесколько зависимых переменных (Multiple outcomes), эффект на которые мы хотим оценить\n\nРассмотрим это на примере. Предположим, что у нас есть 3 группы (A, B и С), в которых мы хотим сравнить среднее значение переменной интереса. Как и ранее, мы будем использовать t-тест Стьюдента. Если мы получили достаточно большое значение t-статистики такое, что p-value &lt; 0.05, то мы отклоняем нулевую гипотезу и заключаем, что группы статистически различаются по переменной интереса. Отсечка p-value &lt; 0.05 значит, что вероятность ошибочного вывода о различии между групповыми средними не превышает 0.05. Это будет работать именно так, когда у нас всего две группы, но в случае множественного тестирования вероятность будет больше 5%.\n\n\n\n\nflowchart LR\n  A(A) --&gt;|5%| B(B)\n  B(B) --&gt;|5%| C(C)\n  C(C) --&gt;|5%| A(A)\n\n\n\n\n\nВыполняя тест Стьюдента, исследователь проверяет нулевую гипотезу об отсутствии разницы между двумя группами. Сравнивая группы A и В, он может ошибиться с вероятностью 5%, В и С – 5%, А и С – тоже 5%. Соответственно, вероятность ошибиться хотя бы в одном из этих трех сравнений составит:\n\\(P = 1 - \\left(1-\\alpha \\right)^n = 1 - 0.95^3 \\approx 0.14 &gt; 0.05\\) – такая ошибка называется family-wise error rate\nЕсли бы групп было бы 5:\n\\(P = 1 - \\left(1-\\alpha \\right)^n = 1 - 0.95^{10} \\approx 0.4 &gt; 0.05\\)\nК счастью, существует несколько методов, позволяющих преодолеть эту сложность:\n\nКорректировка p-value (p-value adjustments)\nПланирование эксперимента и фиксирование его условий (pre-analysis plans)\nПовтороное проведение эксперимента (replication)\n\nВ рамках курса мы будем обсуждать первый способ борьбы с ошибками, возникающими при множественном тестировании гипотез."
  },
  {
    "objectID": "multiple_testing.html#контроль-ошибок-первого-и-второго-рода",
    "href": "multiple_testing.html#контроль-ошибок-первого-и-второго-рода",
    "title": "2  Множественное тестирование гипотез",
    "section": "2.2 Контроль ошибок первого и второго рода",
    "text": "2.2 Контроль ошибок первого и второго рода\nПредположим, что мы проверяем \\(n\\) гипотез. Для каждой гипотезы мы будем проводить тест Стьюдента. Результаты наших тестов можно обобщить следующим образом:\n\n\n\n\n\n\n\n\n\n\nЧисло принятых нулевых гипотез  \\((p-value &gt; \\alpha) \\Rightarrow \\hat{\\tau}=0\\)\nЧисло отвергнутых нулевых гипотез  \\((p-value &lt; \\alpha) \\Rightarrow \\hat{\\tau}\\neq 0\\)\nВсего гипотез\n\n\n\n\nЧисло верных нулевых гипотез  \\(\\hat{\\tau}=0\\)\nЧисло безошибочно принятых нулевых гипотез (TN, true negatives)\nЧисло ошибочно отвергнутых нулевых гипотез (FP, false positives) – ошибка первого рода\n\\(m_0\\) – Число верных нулевых гипотез (true null hypotheses)\n\n\nЧисло неверных нулевых гипотез  \\(\\hat{\\tau}\\neq 0\\)\nЧисло ошибочно принятых нулевых гипотез (FN, false negatives) – ошибка второго рода)\nЧисло безошибочно отвергнутых нулевых гипотез (TP, true positives)\n\\(m-m_0\\) – Число истинных альтернативных гипотез (true alternative hypotheses)\n\n\nВсего гипотез\n\\(m-R\\) – Общее число принятых гипотез\n\\(R\\) – Общее число отвергнутых гипотез\n\\(m\\) – всего гипотез\n\n\n\nВ теории всего существует \\(m_0\\) верных нулевых гипотез. В результате наших тестов мы ошибочно отвергаем \\(FP\\) гипотез и верно принимаем остальные \\(TN\\) гипотез. Также существует \\(m−m_0\\) альтернативных гипотез, из которых \\(TP\\) гипотез безошибочно отвергаются, а \\(FN\\) гипотез – ошибочно принимаются. Важно, что общие количества отвергнутых и принятых гипотез (\\(R\\) и \\(m-R\\)), а следовательно, и суммарное число гипотез \\(n\\) нам известны, тогда как остальные величины (\\(m_0\\), \\(TN\\), \\(FP\\), \\(FN\\) и \\(TP\\)) мы не наблюдаем.\n\n2.2.1 Групповая вероятность ошибки первого рода (family-wise error rate)\nПри одновременной проверке семейства статистических гипотез мы хотим, чтобы количество наших ошибок (\\(FP\\) и \\(FN\\)) было минимальным. Традиционно исследователи пытаются минимизировать величину ошибочно отвергнутых гипотез \\(FP\\). Это вполне логично, поскольку ложно отвергнутая нулевая гипотеза грозит нам ложноположительным найденным эффектом, которого реально может не быть.\nЕсли \\(FP \\geq 1\\), мы совершаем как минимум одну ошибку первого рода. Вероятность допущения такой ошибки при множественной проверке гипотез называют групповой вероятностью ошибки (familywise error rate, FWER или experiment-wise error rate). По определению, \\(FWER = P(FP \\geq 1)\\) – вероятность ошибочно отклонить хотя бы одну нулевую гипотезу во всех тестах. Соответственно, когда мы говорим, что хотим контролировать групповую вероятность ошибки на определенном уровне значимости \\(\\alpha\\), мы подразумеваем, что должно выполняться неравенство \\(FWER \\leq \\alpha\\).\nНиже мы обсудим методы, которые позволяют это делать.\n\n2.2.1.1 Коррекция Бонферрони\nВернемся к нашему примеру, когда мы сравнили 3 группы A, B и C с помощью t-теста. Предположим, что мы получили следующие Р-значения: 0.001, 0.01 и 0.04.\nКак было сказано выше, мы хотим, чтобы групповая вероятность ошибки была не больше уровня значимости \\(FWER \\leq \\alpha\\). Согласно методу Бонферрони, мы должны сравнить каждое из полученных p-значений не с \\(\\alpha\\), а с \\(\\frac{\\alpha}{n}\\), где \\(n\\) – число проверяемых гипотез. Деление исходного уровня значимости \\(\\alpha\\) на \\(n\\) – это и есть поправка Бонферрони. В рассматриваемом примере каждое из полученных p-значений необходимо было бы сравнить с \\(\\frac{\\alpha}{n}\\), например, с \\(\\frac{0.05}{3}\\approx 0.017\\).\n\n\\(p-value_1=0.001 &lt; \\alpha_{adjusted}=0.017\\) – гипотеза отклонена\n\\(p-value_2=0.01 &lt; \\alpha_{adjusted}=0.017\\) – гипотеза отклонена\n\\(p-value_3=0.04 &gt; \\alpha_{adjusted}=0.017\\) – гипотеза принята\n\nВместо деления уровня значимости на число гипотез, мы могли бы умножить каждое p-значение на это число и получить точно такие же выводы (эта эквивалентная процедура реалирована в R):\n\n\\(p-value_{1,adjusted} = 0.001 \\cdot 3 = 0.003 &lt; \\alpha = 0.05\\) – гипотеза отклонена\n\\(p-value_{2,adjusted} = 0.01 \\cdot 3 = 0.03 &lt; \\alpha = 0.05\\) – гипотеза отклонена\n\\(p-value_{3,adjusted} = 0.04 \\cdot 3 = 0.12 &gt; \\alpha = 0.05\\) – гипотеза принята\n\nИногда при домножении p-значений результат может получиться больше единицы. Из теории вероятностей мы знаем, что вероятность не может быть больше одного, поэтому в таких случаях p-значение принимают равным за единицу.\nРазличные виды коррекций p-значений представлены в функции p.adjust(), выбрать тип коррекции можно с помощью аргумента method. В этой функции используется домножение исходных p-значений на количество тестируемых гипотез, а не корректировка уровня значимости.\nПроверим наши рассчеты:\n\np.adjust(c(0.001, 0.01, 0.04), method = \"bonferroni\")\n\n[1] 0.003 0.030 0.120\n\n\nМожно на выходе сразу получить выводы относительно гипотез при \\(\\alpha = 5%\\):\n\nalpha &lt;- 0.05\np.adjust(c(0.001, 0.01, 0.04), method = \"bonferroni\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\n[1]  TRUE  TRUE FALSE\n\n\nВажно помнить об уязвимости коррекции Бонферрони – с ростом числа гипотез мощность метода уменьшается. Чем больше гипотез мы хотим проверить, тем сложнее нам будет их отвергать (даже если они реально должны быть отвергнуты). Например, для 5 групп (10 гипотез), применение поправки Бонферрони привело бы к снижению исходного уровня значимости до 0.01/10 = 0.001. Соответственно, для отклонения гипотез, соответствующие p-значения должны быть меньше 0.001, а это довольно жесткая отсечка. Из этого делаем вывод, что при большом числе гипотез коррекцию Бонферрони лучше не использовать.\n\n\n2.2.1.2 Нисходящая процедура Хольма (Хольма-Бонферрони)\nМетод Хольма позволяет побороть недостатки метода Бонферрони. Он устроен следующим образом:\n\nСначала p-значения сортируются по возрастанию \\(\\displaystyle{p-value_1 \\leq p-value_2 \\leq ... \\leq p-value_n}\\).\nЗатем проверяется условие для первого из p-значений: \\(\\displaystyle{p-value_1 \\geq \\frac{\\alpha}{n-i+1}=\\frac{\\alpha}{n}}\\), если условие выполнено, то все нулевые гипотезы принимаются, и процедура останавливается, иначе первая из гипотез отвергается, и начинается следующий шаг.\nНа следующем шаге проверяется условие \\(\\displaystyle{p-value_2 \\geq \\frac{\\alpha}{n-i+1}=\\frac{\\alpha}{n-1}}\\), если условние выполнено, то все гипотезы, начиная со второй, принимаются, иначе первые две гипотезы отклоняются и начинается следующий шаг.\nНа последнем шаге проверяется условие вида \\(\\displaystyle{p-value_n \\geq \\frac{\\alpha}{n-n+1}}\\), если оно выполнено, то последняя гипотеза принимается, если нет – отклоняется, на этом процедура заканчивается.\n\nМетод Хольма называют нисходящей (step-down) процедурой. Он начинается с наименьшего p-значения в упорядоченном ряду и последовательно “спускается” вниз к более высоким значениям. На каждом шаге соответствующее значение \\(p-value_i\\) сравнивается со скорректированным уровнем значимости \\(\\displaystyle{\\alpha_{adjusted}=\\frac{\\alpha}{n+i-1}}\\). Аналогично коррекции Бонферрони можно вместо корректировки уровня значимости корректировать p-значения \\(\\displaystyle{p-value_{i,adjusted}=p-value_{i}\\cdot(n-i+1)}\\) (эта эквивалентная процедура реалирована в R). Возвращаясь к нашему примеру:\n\n\\(p-value_{1,adjusted} = 0.001 \\cdot (3-1+1) = 0.003 &lt; \\alpha = 0.01\\) – гипотеза отклонена\n\\(p-value_{2,adjusted} = 0.01 \\cdot (3-2+1) = 0.02 &gt; \\alpha = 0.01\\) – гипотеза принята\n\\(p-value_{3,adjusted} = 0.04 \\cdot (3-3+1) = 0.04 &gt; \\alpha = 0.01\\) – гипотеза принята\n\nА теперь проверим себя с помощью R:\n\np.adjust(c(0.001, 0.01, 0.04), method = \"holm\")\n\n[1] 0.003 0.020 0.040\n\n\nИ результаты проверки гипотез при \\(\\alpha =5%\\):\n\nalpha &lt;- 0.05\np.adjust(c(0.001, 0.01, 0.04), method = \"holm\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\n[1] TRUE TRUE TRUE\n\n\n\n\n\n2.2.2 Средняя доля ложных отклонений (false discovery rate)\nРассмотренные выше FWER методы обеспечивают контроль над групповой вероятностью ошибки первого рода. Как мы выяснили, эти методы чересчур жестко работают, когда нужно одновременно проверить слишком много гипотез (падает статистическая мощность).Под “недостаточной мощностью” понимается сохранение многих нулевых гипотез, которые потенциально могут представлять исследовательский интерес и которые, соответственно, следовало бы отклонить. Недостаточная мощность традиционных процедур множественной проверки гипотез привела к разработке новых методов, например, метода Бенджамини-Хохберга.\nДля преодоления недостаточной мощности FWER методов был предложен новый подход к проблеме множественных проверок статистических гипотез. Суть подхода заключается в том, что вместо контроля над групповой вероятностью ошибки первого рода выполняется контроль над ожидаемой долей ложных отклонений (false discovery rate, FDR) среди всех отклоненных гипотез.\nВ терминах таблицы выше эта ожидаемая доля может быть записана следующим образом: \\(\\displaystyle{FDR=\\left(\\frac{FP}{R}\\right)}\\) (считают, что если \\(R=0\\), то и \\(FDR=0\\)). Часто можно встретить запись через мат. ожидание \\(\\displaystyle{FDR=\\mathbb{E}\\left(\\frac{FP}{R}\\right)}\\). FDR – ожидаемая доля ложных отклоненийсреди всех отклоненных гипотез.\nВ отличие от уровня значимости \\(\\alpha\\), каких-либо общепринятых значений FDR не существует. Многие исследователи по аналогии контролируют FDR на уровне 5%. Интерпретация порогового значения FDR очень проста: например, если в ходе анализа данных отклонено 1000 гипотез, то при q=0.10 ожидаемая доля ложно отклоненных гипотез не превысит 100.\n\n2.2.2.1 Восходящая процедура Бенджамини — Хохберга\nВ статье (Benjamini, Hochberg, 1995) описание процедуры контроля над FDR выглядит так:\n\nСначала p-значения сортируются по возрастанию \\(\\displaystyle{p-value_1 \\leq p-value_2 \\leq ... \\leq p-value_n}\\).\nНаходят максимальное значение \\(k\\) среди всех индексов \\(i=1,...,n\\), для которого \\(p-value_i \\leq \\frac{i}{n}q\\) выполняется неравенство\nОтклоняют все гипотезы \\(H_i\\) с индексами \\(i=1,...,k\\)\n\nЭквивалентная процедура, реалированая в R отличается тем, что вместо нахождения максимального индекса \\(k\\), исходные p-значения корректируются следующим образом: \\(q_i=\\frac{p_in}{i}\\).\nВ качестве примера рассмотрим следующий ряд из 15 упорядоченных по возрастанию p-значений (из оригинальной статьи Benjamini and Hochberg 1995):\n\np.adjust(c(0.0001, 0.0004, 0.0019, 0.0095,  0.0201, 0.0278, 0.0298, 0.0344, 0.0459, 0.3240, 0.4262, 0.5719, 0.6528, 0.7590, 1.000), method = \"BH\")\n\n [1] 0.00150000 0.00300000 0.00950000 0.03562500 0.06030000 0.06385714\n [7] 0.06385714 0.06450000 0.07650000 0.48600000 0.58118182 0.71487500\n[13] 0.75323077 0.81321429 1.00000000\n\n\nИ результаты проверки гипотез при \\(\\alpha =5 %\\):\n\nalpha &lt;- 0.05\np.adjust(c(0.0001, 0.0004, 0.0019, 0.0095,  0.0201, 0.0278, 0.0298, 0.0344, 0.0459, 0.3240, 0.4262, 0.5719, 0.6528, 0.7590, 1.000), method = \"BH\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\n [1]  TRUE  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE\n\n\nИнтерпретация этих Р-значений с поправкой (в большинстве литературных источников их называют q-значениями) такова:\n\nДопустим, что мы хотим контролировать долю ложно отклоненных гипотез на уровне FDR = 0.05\nВсе гипотезы, q-значения которых \\(q-value \\leq 0.05\\), отклоняются\nСреди всех этих отклоненных гипотез доля отклоненных по ошибке не превышает 5%\n\nКоррекция Р-значений по методу Беньямини-Хохберга работает особенно хорошо в ситуациях, когда необходимо принять общее решение по какому-либо вопросу при наличии информации (=проверенных гипотез) по многим параметрам.\nСледует помнить, что описанный здесь метод контроля над ожидаемой долей ложных отклонений предполагает, что все тесты, при помощи которых получают p-значения, независимы. На практике в большинстве случаев это условие выполняться не будет.\n\n\n2.2.2.2 Восходящая процедура Бенджамини-Йекутили\nДля преодоления ограничения независимости тестов при проверке гипотез в работе (Benjamini and Yekutieli 2001) был предложен усовершенствованный метод, учитывающий наличие корреляции между проверяемыми гипотезами.\nПроцедура Бенджамини-Йекутили очень похожа на процедуру Бенджамини-Хохберга. Основное отличие заключается во введении поправочной константы \\(\\displaystyle{c_n=\\sum \\limits_{i=1}^{n}\\frac{1}{i}}\\), далее аналогично:\n\nСначала p-значения сортируются по возрастанию \\(\\displaystyle{p-value_1 \\leq p-value_2 \\leq ... \\leq p-value_n}\\).\nНаходят максимальное значение \\(k\\) среди всех индексов \\(i=1,...,n\\), для которого \\(p-value_i \\leq \\frac{i}{n} \\frac{q}{c_n}\\) выполняется неравенство\nОтклоняют все гипотезы \\(H_i\\) с индексами \\(i=1,...,k\\)\n\nВ R реализуется эквивалентная процедура:\nЭквивалентная процедура, реалированая в R отличается тем, что вместо нахождения максимального индекса \\(k\\), исходные p-значения корректируются следующим образом: \\(\\displaystyle{q_i=\\frac{p_i\\cdot n\\cdot c_n}{i}}\\).\n\np.adjust(c(0.0001, 0.0004, 0.0019, 0.0095,  0.0201, 0.0278, 0.0298, 0.0344, 0.0459, 0.3240, 0.4262, 0.5719, 0.6528, 0.7590, 1.000), method = \"BY\")\n\n [1] 0.004977343 0.009954687 0.031523175 0.118211908 0.200089208 0.211892623\n [7] 0.211892623 0.214025770 0.253844518 1.000000000 1.000000000 1.000000000\n[13] 1.000000000 1.000000000 1.000000000\n\n\nИ результаты проверки гипотез при \\(\\alpha = 5%\\):\n\nalpha &lt;- 0.05\np.adjust(c(0.0001, 0.0004, 0.0019, 0.0095,  0.0201, 0.0278, 0.0298, 0.0344, 0.0459, 0.3240, 0.4262, 0.5719, 0.6528, 0.7590, 1.000), method = \"BY\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\n [1]  TRUE  TRUE  TRUE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE FALSE\n[13] FALSE FALSE FALSE"
  },
  {
    "objectID": "multiple_testing.html#обобщающий-алгоритм-для-разных-процедур",
    "href": "multiple_testing.html#обобщающий-алгоритм-для-разных-процедур",
    "title": "2  Множественное тестирование гипотез",
    "section": "2.3 Обобщающий алгоритм для разных процедур",
    "text": "2.3 Обобщающий алгоритм для разных процедур\n\n\n\n\n\nИсточник – мне не очень нравится сам текст, но схема хорошая."
  },
  {
    "objectID": "multiple_testing.html#симуляция-и-сравнение-результатов-работы-разных-коррекций-p-value",
    "href": "multiple_testing.html#симуляция-и-сравнение-результатов-работы-разных-коррекций-p-value",
    "title": "2  Множественное тестирование гипотез",
    "section": "2.4 Симуляция и сравнение результатов работы разных коррекций p-value",
    "text": "2.4 Симуляция и сравнение результатов работы разных коррекций p-value\nСравним как работают разные методы:\n\nalpha &lt;- 0.05\nn &lt;- 50\nset.seed(123)\nx &lt;- rnorm(n, mean = c(rep(0, n/2), rep(3, n/2))) # генерим вектор t статистик\npval &lt;- round(2*pnorm(sort(-abs(x))), 3) # переводим статистики в p-value\n\ndefault_bool &lt;- pval &lt; alpha # вектор с исходными выводами о принятии гипотез без коррекции\n\nbonferroni_pval &lt;- p.adjust(pval, method = \"bonferroni\")\nbonferroni_bool &lt;- p.adjust(pval, method = \"bonferroni\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\nholm_pval &lt;- p.adjust(pval, method = \"holm\")\nholm_bool &lt;- p.adjust(pval, method = \"holm\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\nbh_pval &lt;- p.adjust(pval, method = \"BH\") \nbh_bool &lt;- p.adjust(pval, method = \"BH\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\nby_pval &lt;- p.adjust(pval, method = \"BY\")\nby_bool &lt;- p.adjust(pval, method = \"BY\") &lt; alpha # отклоняем H_0 (есть эффект)? \n\nmethods &lt;- cbind(default_bool, bonferroni_bool, holm_bool, bh_bool, by_bool) # склеиваем столбики с выводами о принятии гипотез для разных корректировок; если бы вдруг хотели склеить строчки, то есть аналогичная функция rbind()\ncolnames(methods) &lt;- c('Без коррекции', 'Бонферрони', 'Хольм', 'Бенджамини-Хохберг', 'Бенджамини-Йекутили') # добавляем шапку таблицы\nrownames(methods) &lt;- c(1:n) # добавляем номера строчкам\nmethods\n\n   Без коррекции Бонферрони Хольм Бенджамини-Хохберг Бенджамини-Йекутили\n1           TRUE       TRUE  TRUE               TRUE                TRUE\n2           TRUE       TRUE  TRUE               TRUE                TRUE\n3           TRUE       TRUE  TRUE               TRUE                TRUE\n4           TRUE       TRUE  TRUE               TRUE                TRUE\n5           TRUE       TRUE  TRUE               TRUE                TRUE\n6           TRUE       TRUE  TRUE               TRUE                TRUE\n7           TRUE       TRUE  TRUE               TRUE                TRUE\n8           TRUE       TRUE  TRUE               TRUE                TRUE\n9           TRUE       TRUE  TRUE               TRUE                TRUE\n10          TRUE       TRUE  TRUE               TRUE                TRUE\n11          TRUE      FALSE  TRUE               TRUE                TRUE\n12          TRUE      FALSE FALSE               TRUE                TRUE\n13          TRUE      FALSE FALSE               TRUE               FALSE\n14          TRUE      FALSE FALSE               TRUE               FALSE\n15          TRUE      FALSE FALSE               TRUE               FALSE\n16          TRUE      FALSE FALSE               TRUE               FALSE\n17          TRUE      FALSE FALSE               TRUE               FALSE\n18          TRUE      FALSE FALSE               TRUE               FALSE\n19          TRUE      FALSE FALSE               TRUE               FALSE\n20          TRUE      FALSE FALSE               TRUE               FALSE\n21          TRUE      FALSE FALSE              FALSE               FALSE\n22          TRUE      FALSE FALSE              FALSE               FALSE\n23         FALSE      FALSE FALSE              FALSE               FALSE\n24         FALSE      FALSE FALSE              FALSE               FALSE\n25         FALSE      FALSE FALSE              FALSE               FALSE\n26         FALSE      FALSE FALSE              FALSE               FALSE\n27         FALSE      FALSE FALSE              FALSE               FALSE\n28         FALSE      FALSE FALSE              FALSE               FALSE\n29         FALSE      FALSE FALSE              FALSE               FALSE\n30         FALSE      FALSE FALSE              FALSE               FALSE\n31         FALSE      FALSE FALSE              FALSE               FALSE\n32         FALSE      FALSE FALSE              FALSE               FALSE\n33         FALSE      FALSE FALSE              FALSE               FALSE\n34         FALSE      FALSE FALSE              FALSE               FALSE\n35         FALSE      FALSE FALSE              FALSE               FALSE\n36         FALSE      FALSE FALSE              FALSE               FALSE\n37         FALSE      FALSE FALSE              FALSE               FALSE\n38         FALSE      FALSE FALSE              FALSE               FALSE\n39         FALSE      FALSE FALSE              FALSE               FALSE\n40         FALSE      FALSE FALSE              FALSE               FALSE\n41         FALSE      FALSE FALSE              FALSE               FALSE\n42         FALSE      FALSE FALSE              FALSE               FALSE\n43         FALSE      FALSE FALSE              FALSE               FALSE\n44         FALSE      FALSE FALSE              FALSE               FALSE\n45         FALSE      FALSE FALSE              FALSE               FALSE\n46         FALSE      FALSE FALSE              FALSE               FALSE\n47         FALSE      FALSE FALSE              FALSE               FALSE\n48         FALSE      FALSE FALSE              FALSE               FALSE\n49         FALSE      FALSE FALSE              FALSE               FALSE\n50         FALSE      FALSE FALSE              FALSE               FALSE\n\nplot(pval, bonferroni_pval, col = \"orange\", type=\"p\", pch=1)\nlines(pval, holm_pval, col=\"green\", type=\"p\", pch=1)\nlines(pval, bh_pval, col=\"blue\", type=\"p\", pch=1)\nlines(pval, by_pval, col=\"violet\", type=\"p\", pch=1)\nabline(h=alpha, col=\"red\")\nabline(v=alpha, col=\"red\")\nlegend(x=0.6, y=0.5, # координаты верхнего левого угла легенды\n       legend=c('Бонферрони', 'Хольм', 'Бенджамини-Хохберг', 'Бенджамини-Йекутили', 'Уровень значимости'), # категории легенды\n       col=c(\"orange\", \"green\", \"blue\", \"violet\", \"red\"), # цвета категорий\n       bty = \"n\", # чтобы не было рамочки вокруг легенды\n       pch=1) # форма маркера"
  },
  {
    "objectID": "bad_control.html#устройство-данных.-плохой-контроль.",
    "href": "bad_control.html#устройство-данных.-плохой-контроль.",
    "title": "3  Плохой контроль",
    "section": "3.1 Устройство данных. Плохой контроль.",
    "text": "3.1 Устройство данных. Плохой контроль.\nГлавная мысль семинара: контрольные переменные – это не всегда хорошо! Нужно выбирать их вдумчиво, а не закидывать в регрессию всё то, что удалось скачать.\nСуществует 3 основных варианта устройства данных, когда мы хотим оценить эффект от воздействия \\(T\\):\n\nИдеальный эксперимент\n\n\n\n\n\nflowchart LR\n  T(T) --&gt; Y(Y)\n  X(X) --&gt; Y(Y)\n  e(e) --&gt; Y(Y)\n\n\n\n\n\n\nПропуск существенной переменной\n\n\n\n\n\nflowchart LR\n  T(T) --&gt; Y(Y)\n  X(X) --&gt; Y(Y)\n  X(X) --&gt; T(T)\n  e(e) --&gt; Y(Y)\n\n\n\n\n\n\nПлохой контроль\n\n\n\n\n\nflowchart LR\n  T(T) --&gt; Y(Y)\n  X(X) --&gt; Y(Y)\n  T(T) --&gt; X(X)\n  e(e) --&gt; Y(Y)"
  },
  {
    "objectID": "bad_control.html#пример-из-angrist-pischke-2009",
    "href": "bad_control.html#пример-из-angrist-pischke-2009",
    "title": "3  Плохой контроль",
    "section": "3.2 Пример из (Angrist, Pischke, 2009)",
    "text": "3.2 Пример из (Angrist, Pischke, 2009)\nДальше разберем проблему плохого контроля на примере 3.2.3 из книги Энгриста и Пишке “Mostly harmless econometrics”. Тут я перевела условия заданий, оригинал задачки лежит на on.econ в разделе “Неделя 2” под названием “Ozier Bad control exercise”.\nНиже общая схема задачи:\n\n\n\n\n\n\n3.2.1 Генерация данных\na) Сгенерируйте набор данных из 10 000 наблюдений. Обязательно установите начальное число, чтобы ваш код давал идентичные результаты при повтороном запуске. Все четыре перечисленные переменные не должны зависеть друг от друга.\n\nСгенерируйте переменную способности равномерно распределенную между -1 и 1;\nСгенерируйте индикаторную переменную колледжа, равную единице для случайной половины наблюдений;\nСгенерируйте \\(\\varepsilon_1\\) и \\(\\varepsilon_2\\) так, чтобы каждая из них имела стандартное нормальное распределение.\n\n\nn &lt;- 10000\n\nset.seed(123)\nability &lt;- runif(n, min=-1, max=1) # способности людей\ncollege &lt;- c(rep(0,n/2), rep(1,n/2)) # факт обучения в колледже\nepsilon1 &lt;- rnorm(n,sd=1) # врожденная склонность быть белым воротничком\nepsilon2 &lt;- rnorm(n,sd=1) # случайный шок дохода\n\ncor(data.frame(ability, college, epsilon1, epsilon2)) # все переменные получились независимыми\n\n               ability      college     epsilon1     epsilon2\nability   1.0000000000 0.0003448777 -0.011632887 -0.011652074\ncollege   0.0003448777 1.0000000000  0.006161457  0.008334883\nepsilon1 -0.0116328869 0.0061614570  1.000000000  0.011595971\nepsilon2 -0.0116520742 0.0083348828  0.011595971  1.000000000\n\n\nb) Сгенерируйте \\(w_0\\) – переменную, указывающую, будет ли кто-то белым воротничком независимо от факта обучения в колледже. Интерпретируйте \\(\\varepsilon_1\\) как склонность быть белым воротничком, тогда \\(w_0\\) должен быть равен 1, когда \\(\\varepsilon_1\\) больше нуля, и должен быть равен нулю в противном случае.\n\nw0 &lt;- as.numeric(epsilon1&gt;0) # Индикатор белого воротничка\n\nc) Затем сгенерируйте две версии переменной-индикатора быть белым воротничком при условии обучения в колледже для двух сценариев:\n\nВ первом сценарии колледж превращает всех работников с низкими способностями (\\(ability&lt;0\\)) в белых воротничков, но это не влияет на работников с высокими способностями. Создайте индикатор \\(w_1v_1\\) для этого сценария.\nВо втором сценарии колледж приводит к тому, что все высококвалифицированные работники (\\(ability \\geq 0\\)) становятся белыми воротничками, но при этом не влияет на поведение работников с низкими способностями. Создайте индикатор \\(w_1v_2\\) для этого второго сценария.\n\nОбратите внимание, что это всего лишь потенциальные исходы, поэтому они еще не зависят от того, действительно ли человек поступил в колледж, они просто зависят от \\(ability\\) и \\(w_0\\).\nСценарий v1: система образования помогает отстающим.\nКолледж помогает отстающим устроиться на хорошую работу, а на умных никак не влияет:\n\nw1v1 &lt;- as.numeric(ability&lt;0 | w0&gt;0) \nsummary(w1v1) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  1.0000  1.0000  0.7504  1.0000  1.0000 \n\n\nСценарий v2: система образования помогает умным.\nКолледж помогает умным устроиться на хорошую работу, а на отстающих никак не влияет:\n\nw1v2 &lt;- as.numeric(ability&gt;=0 | w0&gt;0)  \nsummary(w1v2) \n\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n 0.0000  0.0000  1.0000  0.7483  1.0000  1.0000 \n\n\nd) Затем сгенерируйте две версии фактического индикатора белого воротничка. Сгенерируйте \\(wv_1\\) так, чтобы он был равен \\(w_0\\) для тех, кто не учился в колледже, и \\(w_1v_1\\) для тех, кто учился. Аналогичным образом сгенерируйте \\(wv_2\\) так, чтобы он равнялся \\(w_0\\) для тех, кто не учится в колледже, и \\(w_1v_2\\) для тех, кто его посещает.\nИтого реализовавшееся устройство на работу:\n\nwv1&lt;-w0*(1-college)+w1v1*college\nwv2&lt;-w0*(1-college)+w1v2*college\n\ne) Затем сгенерируйте потенциальный исход для дохода, если человек не оканчивал колледж. Сгенерируйте \\(y_0\\) так, чтобы он был равен утроенным способностям плюс шок дохода \\(\\varepsilon_2\\).\n\ny0 &lt;- 3*ability + epsilon2\n\nf) Затем сгенерируйте потенциальный исход для дохода, если человек оканчивал колледж. Сгенерируйте \\(y_1\\) так, чтобы он был равен \\(y_0\\) плюс один (то есть наш истинный эффект воздействия \\(\\tau = 1\\)).\n\ny1 &lt;- y0 + 1\n\ng) Затем рассчитайте фактический доход. Сгенерируйте \\(y\\) так, чтобы он был равен \\(y_0\\), когда \\(сollege = 0\\), и \\(y_1\\), когда \\(сollege = 1\\).\n\ny &lt;- y0*(1-college) + y1*college\n\n\n\n3.2.2 Оценка эффекта\nh) Мы готовы гонять регрессию! Оцените регрессию \\(wv_1\\) на \\(сollege\\), коэффициент должен быть около 0,25. Почему?\nОценка эффекта от колледжа на устройство на работу (сценарий v1:):\n\nmodel1 &lt;- lm(wv1 ~ college)\nsummary(model1)\n\n\nCall:\nlm(formula = wv1 ~ college)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7548 -0.4942  0.2452  0.2452  0.5058 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.494200   0.006596   74.92   &lt;2e-16 ***\ncollege     0.260600   0.009329   27.93   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4664 on 9998 degrees of freedom\nMultiple R-squared:  0.0724,    Adjusted R-squared:  0.07231 \nF-statistic: 780.4 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\nМы получили в нашей регрессии 0.261, что с учетом доверительного интервала соответствует условию задачи.\nЭффект равен 0.25 потому, что в первом сценарии в колледж идет половина, из тех, кто идет, половина обладает низкими способностями (а в первом сценарии колледж помогает найти работу только им), итого эффект \\(0.5\\cdot 0.5=0.25\\).\ni) Затем оцените регрессию \\(wv_2\\) на \\(сollege\\), коэффициент тоже должен быть около 0,25. Почему?\nОценка эффекта от колледжа на устройство на работу (сценарий v2:):\n\nmodel2 &lt;- lm(wv2 ~ college)\nsummary(model2)\n\n\nCall:\nlm(formula = wv2 ~ college)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.7484 -0.4942  0.2516  0.2516  0.5058 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.494200   0.006621   74.64   &lt;2e-16 ***\ncollege     0.254200   0.009363   27.15   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.4682 on 9998 degrees of freedom\nMultiple R-squared:  0.06866,   Adjusted R-squared:  0.06857 \nF-statistic: 737.1 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\nМы получили в нашей регрессии 0.254, что с учетом доверительного интервала соответствует условию задачи.\nЭффект равен 0.25 потому, что во втором сценарии в колледж идет половина, из тех, кто идет, половина обладает высокими способностями (а во втором сценарии колледж помогает найти работу только им), итого эффект \\(0.5\\cdot 0.5=0.25\\).\nj) Наконец, следуя примеру из «Mostly Harmless Econometrics», оцените регрессию \\(y\\) на \\(college\\), но только на подвыборке, где \\(wv_1 = 1\\). Как предлагается в книге, это должна быть сумма причинного эффекта и смещения выборки.\nОценка эффекта от коллежда на доход среди белых воротничков (cценарий v1:):\n\nmodel3 &lt;- lm(y[wv1==1] ~ college[wv1==1])\nsummary(model3) # 0.55 = ATE + selection bias\n\n\nCall:\nlm(formula = y[wv1 == 1] ~ college[wv1 == 1])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8386 -1.4852 -0.1235  1.3864  6.1680 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -0.05897    0.03913  -1.507    0.132    \ncollege[wv1 == 1]  0.54993    0.05034  10.925   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.945 on 6243 degrees of freedom\nMultiple R-squared:  0.01876,   Adjusted R-squared:  0.0186 \nF-statistic: 119.3 on 1 and 6243 DF,  p-value: &lt; 2.2e-16\n\n\nМы помним, что истинный эффект колледжа равен 1, смещение возникает из-за дисбаланса системы образования – в первом сценарии колледж помог только отстающим.\nВопросы, которые остаются вам на подумать и посчитать на дом:\n\nКаким должен быть ожидаемый причинный эффект? Почему?\nЧему должно равняться ожидаемое смещение выборки? Почему?\nНасколько близок ваш коэффициент к ожидаемому значению? Находится ли причинный эффект как сумма причинного эффекта и смещения выборки в пределах доверительного интервала для оцененного коэффициента?\n\nk) Теперь оцените регрессию \\(y\\) на \\(college\\), но только на выборке, где \\(wv2 = 1\\). Как предлагается в книге, это должна быть сумма причинно-следственного эффекта и смещения выборки. Как меняются результаты и почему?\nОценка эффекта от коллежда на доход среди белых воротничков (cценарий v2:):\n\nmodel4 &lt;- lm( y[wv2==1] ~ college[wv2==1])\nsummary(model4) # 1.51 = ATE + selection bias\n\n\nCall:\nlm(formula = y[wv2 == 1] ~ college[wv2 == 1])\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8386 -1.4519  0.1057  1.4730  6.3340 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)       -0.05897    0.03959  -1.489    0.136    \ncollege[wv2 == 1]  1.51320    0.05101  29.662   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.968 on 6211 degrees of freedom\nMultiple R-squared:  0.1241,    Adjusted R-squared:  0.1239 \nF-statistic: 879.8 on 1 and 6211 DF,  p-value: &lt; 2.2e-16\n\n\nТут точно так же истинный эффект колледжа равен 1, а смещение возникает из-за тог, что колледж помог только умным.\nl) Наконец, оцените регрессию \\(y\\) на \\(college\\), не ограничивая выборку и не включая любой другой контроль. Какой коэффициент вы получаете и почему?\nОценка эффекта от коллежда на доход без ограничения выборки по “плохой” контрольной переменной:\n\nmodel5&lt;-lm(y ~ college)\nsummary(model5)\n\n\nCall:\nlm(formula = y ~ college)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.8559 -1.5228 -0.0112  1.4784  6.8120 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -0.04168    0.02804  -1.487    0.137    \ncollege      1.01795    0.03965  25.673   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.982 on 9998 degrees of freedom\nMultiple R-squared:  0.06185,   Adjusted R-squared:  0.06175 \nF-statistic: 659.1 on 1 and 9998 DF,  p-value: &lt; 2.2e-16\n\n\nВидим, что теперь мы получили практически истинный эффект (1.02) с поправкой на доверительный интрвал.\nА теперь снова вернемся к главной мысли семинара. Контрольные переменные в случае оценки тритмент эффекта нужно выбирать очень аккуратно. Если в качестве контроля включить переменную, которая зависит от распределения в тритмент, то в конечном итоге мы получим смещенную оценку. Это тот случай, когда лучше ничего не делать, чем делать плохо.\n\n\n3.2.3 Бонус\nВозможно эта картинка поможет вам ответить на вопрос с семинара.\n\ndf &lt;- data.frame(ability, college, epsilon1, epsilon2, y0, y1, w0, w1v1, wv1, w1v2, wv2, y)\ndummy &lt;- colnames(df[,c(2,7,8,9,10,11)])\nlibrary('ComplexUpset')\nupset(df, dummy)"
  },
  {
    "objectID": "subclassification.html#про-постстратификацию",
    "href": "subclassification.html#про-постстратификацию",
    "title": "5  Постстратификация",
    "section": "5.1 Про постстратификацию",
    "text": "5.1 Про постстратификацию\nin progress…"
  },
  {
    "objectID": "subclassification.html#пример-про-титаник",
    "href": "subclassification.html#пример-про-титаник",
    "title": "6  Взвешивание (subclassification)",
    "section": "6.1 Пример про Титаник",
    "text": "6.1 Пример про Титаник\n\n6.1.1 Предварительный анализ\nДля иллюстрации этого подхода, рассмотрим пример на одном из популярных наборов даных про Титаник. Как известно, лайнер столкнулся с айсбергом и затонул во время своего первого рейса. Из 2200 человек на борту выжило чуть более 700 пассажиров и членов экипажа.\nПосле по имеющимся данным высказывалась гипотеза, что пассажиры, которые передвигались в каютах первого класса (самого дорогого), выживали чаще. Именно её мы и проверим.\nПроблема заключается в том, что женщинам и детям отдавался приоритет при посадке в спасательные шлюпки. Если женщины и дети с большей вероятностью будут сидеть в каютах первого класса, то, возможно, различия в выживаемости в каютах первого класса и остальных каютах просто улавливают эффект этой социальной нормы.\nПодключаем библиотеку для импорта данных в формате .dta (формат Stata):\n\nlibrary('haven')\n\nИмпортируем данные:\n\ndata &lt;- read_dta('https://raw.github.com/scunning1975/mixtape/master/titanic.dta')\n\nНаш набор данных состоит из четырех переменных (каждая строчка – конкретный пассажир): - class – класс каюты, который был у пасажира (1 – самый дорогой, 4 – самый дешевый) - age – возраст пасажира (0 – дети, 1 – взрослые) - sex – пол пасажира (0 – женщины, 1 – мужчины) - survived – выжил ли пасажир после крушения лайнера (0 – не выжил, 1 – выжил)\n\nsummary(data)\n\n     class            age              sex            survived    \n Min.   :1.000   Min.   :0.0000   Min.   :0.0000   Min.   :0.000  \n 1st Qu.:2.000   1st Qu.:1.0000   1st Qu.:1.0000   1st Qu.:0.000  \n Median :3.000   Median :1.0000   Median :1.0000   Median :0.000  \n Mean   :2.977   Mean   :0.9505   Mean   :0.7865   Mean   :0.323  \n 3rd Qu.:4.000   3rd Qu.:1.0000   3rd Qu.:1.0000   3rd Qu.:1.000  \n Max.   :4.000   Max.   :1.0000   Max.   :1.0000   Max.   :1.000  \n\n\nМы хотим проверить, действительно ли пассажиры, которые передвигались в каюте первого класса при прочих равных выживали чаще. При этом есть сведения того, что женщинам и детям отдавался приоритет при посадке в спасательные шлюпки. Для начала проверим, нет ли тенденции, что в каютах первого класса чаще также чаще находились дети и женщины. Для этого проведем предварительный анализ данных и построим sankey chart.\nСделаем копию набора данных data_sankey, чтобы использовать его для преобразований. Исходный набор данных data будем использовать для оценки эффекта:\n\ndata_sankey &lt;- data\n\nЧтобы подписи на нашем графике были более очевидными, перезаполним нашу таблицу более “говорящими” категорями. Функция str_replace(строка, что заменить, на что заменить) из пакета stringr в строке, которую вы ей передаете, заменяет все фрагменты на те, которые вы ей скажете.\n\nlibrary('stringr')\n\nЗаменяем номера классов на словесное описание:\n\ndata_sankey$class &lt;- str_replace(data_sankey$class, \"1\", \"1 класс\")\ndata_sankey$class &lt;- str_replace(data_sankey$class, \"2\", \"2 класс\")\ndata_sankey$class &lt;- str_replace(data_sankey$class, \"3\", \"3 класс\")\ndata_sankey$class &lt;- str_replace(data_sankey$class, \"4\", \"4 класс\")\n\nЗаменяем бинарную переменную пола на словесное описание:\n\ndata_sankey$sex &lt;- str_replace(data_sankey$sex, \"0\", \"Женщины\")\ndata_sankey$sex &lt;- str_replace(data_sankey$sex, \"1\", \"Мужчины\")\n\nЗаменяем бинарную переменную возраста на словесное описание:\n\ndata_sankey$age &lt;- str_replace(data_sankey$age, \"0\", \"Дети\")\ndata_sankey$age &lt;- str_replace(data_sankey$age, \"1\", \"Взрослые\")\n\nЗаменяем бинарную выживаемости пола на словесное описание:\n\ndata_sankey$survived &lt;- str_replace(data_sankey$survived, \"0\", \"Не выжил\")\ndata_sankey$survived &lt;- str_replace(data_sankey$survived, \"1\", \"Выжил\")\n\nТперь наш набор данных выглядит следующим образом (каждая строчка – конкретный пассажир):\n\nhead(data_sankey)\n\n# A tibble: 6 × 4\n  class   age      sex     survived\n  &lt;chr&gt;   &lt;chr&gt;    &lt;chr&gt;   &lt;chr&gt;   \n1 1 класс Взрослые Мужчины Выжил   \n2 1 класс Взрослые Мужчины Выжил   \n3 1 класс Взрослые Мужчины Выжил   \n4 1 класс Взрослые Мужчины Выжил   \n5 1 класс Взрослые Мужчины Выжил   \n6 1 класс Взрослые Мужчины Выжил   \n\n\nДля граифка нам понадобится еще две дополнительных библиотеки:\n\n# library(devtools)\n# devtools::install_github(\"davidsjoberg/ggsankey\")\nlibrary(ggsankey)\nlibrary(ggplot2)\n\nПодробнее почитать про пакет ggsankey и ознакомиться с синтаксисом можно тут.\nНаш пакет умеет понимать данные определенной структуры. Помните, когда у вас был курс методов оптимальных решений, где вы решали транспортную задачу, вам сначала нужно было по условию нарисовать граф и нанести потоки. Вот примерно такое же условие мы сейчас будем готовить для пакета.\nСначала используем функцию make_long() из пакета ggsankey, чтобы перекроить\n\ndata_sankey1 &lt;- data_sankey %&gt;% make_long(class, sex, age, survived)\n\nНам понадобиться функция tally() из библиотеки dplyr:\n\nlibrary(dplyr)\ndata_sankey2 &lt;- data_sankey1 %&gt;% group_by(node) %&gt;% tally()\n\n\ndata_sankey3 &lt;- merge(data_sankey1, data_sankey2, by.x = 'node', by.y = 'node', all.x = TRUE)\n\n\nsankey &lt;- ggplot(data_sankey3, aes(x = x,\n                                next_x = next_x,\n                                node = node,\n                                next_node = next_node,\n                                fill = factor(node),\n                                label = paste0(node,\", \", n, \" чел.\"))) +\n  geom_sankey(flow.alpha = 0.6) +\n  geom_sankey_label(size = 4) +\n  theme_sankey(base_size = 16) +\n  labs(x = NULL) +\n  theme(legend.position = \"none\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())\n\nА теперь посмотрим разные разбивки данных:\n\n6.1.1.1 класс – пол – возраст – выживаемость\n\ndata_sankey1 &lt;- data_sankey %&gt;% make_long(class, sex, age, survived)\ndata_sankey2 &lt;- data_sankey1 %&gt;% group_by(node) %&gt;% tally()\ndata_sankey3 &lt;- merge(data_sankey1, data_sankey2, by.x = 'node', by.y = 'node', all.x = TRUE)\nsankey &lt;- ggplot(data_sankey3, aes(x = x,\n                                next_x = next_x,\n                                node = node,\n                                next_node = next_node,\n                                fill = factor(node),\n                                label = paste0(node,\", \", n, \" чел.\"))) +\n  geom_sankey(flow.alpha = 0.6) +\n  geom_sankey_label(size = 4) +\n  theme_sankey(base_size = 16) +\n  labs(x = NULL) +\n  theme(legend.position = \"none\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())\nsankey\n\n\n\n\n\n\n6.1.1.2 класс – выживаемость\n\ndata_sankey1 &lt;- data_sankey %&gt;% make_long(class, survived)\ndata_sankey2 &lt;- data_sankey1 %&gt;% group_by(node) %&gt;% tally()\ndata_sankey3 &lt;- merge(data_sankey1, data_sankey2, by.x = 'node', by.y = 'node', all.x = TRUE)\nsankey &lt;- ggplot(data_sankey3, aes(x = x,\n                                next_x = next_x,\n                                node = node,\n                                next_node = next_node,\n                                fill = factor(node),\n                                label = paste0(node,\", \", n, \" чел.\"))) +\n  geom_sankey(flow.alpha = 0.6) +\n  geom_sankey_label(size = 4) +\n  theme_sankey(base_size = 16) +\n  labs(x = NULL) +\n  theme(legend.position = \"none\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())\nsankey\n\n\n\n\n\n\n6.1.1.3 класс – пол\n\ndata_sankey1 &lt;- data_sankey %&gt;% make_long(class, sex)\ndata_sankey2 &lt;- data_sankey1 %&gt;% group_by(node) %&gt;% tally()\ndata_sankey3 &lt;- merge(data_sankey1, data_sankey2, by.x = 'node', by.y = 'node', all.x = TRUE)\nsankey &lt;- ggplot(data_sankey3, aes(x = x,\n                                next_x = next_x,\n                                node = node,\n                                next_node = next_node,\n                                fill = factor(node),\n                                label = paste0(node,\", \", n, \" чел.\"))) +\n  geom_sankey(flow.alpha = 0.6) +\n  geom_sankey_label(size = 4) +\n  theme_sankey(base_size = 16) +\n  labs(x = NULL) +\n  theme(legend.position = \"none\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())\nsankey\n\n\n\n\n\n\n6.1.1.4 класс – возраст\n\ndata_sankey1 &lt;- data_sankey %&gt;% make_long(class, age)\ndata_sankey2 &lt;- data_sankey1 %&gt;% group_by(node) %&gt;% tally()\ndata_sankey3 &lt;- merge(data_sankey1, data_sankey2, by.x = 'node', by.y = 'node', all.x = TRUE)\nsankey &lt;- ggplot(data_sankey3, aes(x = x,\n                                next_x = next_x,\n                                node = node,\n                                next_node = next_node,\n                                fill = factor(node),\n                                label = paste0(node,\", \", n, \" чел.\"))) +\n  geom_sankey(flow.alpha = 0.6) +\n  geom_sankey_label(size = 4) +\n  theme_sankey(base_size = 16) +\n  labs(x = NULL) +\n  theme(legend.position = \"none\") +\n  theme(axis.title.x=element_blank(),\n        axis.text.x=element_blank(),\n        axis.ticks.x=element_blank())\nsankey\n\n\n\n\n\n\n\n6.1.2 Альтернативные пакеты для sankey chart по запросу трудящихся (факультативный раздел)\n\n6.1.2.1 ggforce\n\n## делаем факторные переменные для ggplot\ndata_sankey$class &lt;- as.factor(data_sankey$class)\ndata_sankey$age &lt;- as.factor(data_sankey$age)\ndata_sankey$sex &lt;- as.factor(data_sankey$sex)\ndata_sankey$survived &lt;- as.factor(data_sankey$survived)\n\n## считаем количество наблюдений по группам\nlibrary('dplyr')\ndata_sankey &lt;- data_sankey %&gt;% group_by(class, sex, age, survived) %&gt;% summarise(value=n())\n\n## преобразовываем данные в адресный вид\nlibrary('ggforce')\nlibrary('ggplot2')\ndata_sankey &lt;- gather_set_data(data_sankey, c(1,3,4))\n\n## sankey chart\nsankey &lt;- ggplot(data_sankey, aes(x, id = id, split = y, value = value)) +\n    geom_parallel_sets(aes(fill = sex),\n                       alpha = 0.5, # яркость\n                       axis.width = 0.1) + # отступы от бортиков\n    geom_parallel_sets_axes(axis.width = 0.1) +  # толщина бортиков\n    geom_parallel_sets_labels(colour = 'white') # цвет подписей на бортиках\nsankey\n\n\n\n\n\n\n\n\n6.1.3 Считаем эффект\nНаивная оценка\n\nATE_naive\n\n[1] 0.3538265\n\n\nВзвешивание\n\ndata &lt;- data %&gt;% \n  mutate(str = case_when(sex == 0 & age == 1 ~ 1, # женщины\n                         sex == 0 & age == 0 ~ 2, # девочки\n                         sex == 1 & age == 1 ~ 3, # мужчины\n                         sex == 1 & age == 0 ~ 4, # мальчики\n                         TRUE ~ 0))\n\n\nconditional_treatment_data &lt;- data %&gt;% group_by(str, d) %&gt;% summarise(ct = mean(survived), \n                                                                      w = n()/nrow(data))\n\n`summarise()` has grouped output by 'str'. You can override using the `.groups`\nargument.\n\n\n\nconditional_treatment_data &lt;- conditional_treatment_data %&gt;% group_by(str) %&gt;% mutate(W = w + lag(w),\n                                                                                      W_t = lead(w),\n                                                                                      W_c = lag(w),\n                                                                                      diff=ct-lag(ct))\n\n\nATE &lt;- sum(na.omit(conditional_treatment_data$W*conditional_treatment_data$diff))\nATT &lt;- sum(na.omit(conditional_treatment_data$W_t)*na.omit(conditional_treatment_data$diff))\nATnT &lt;- sum(na.omit(conditional_treatment_data$W_c)*na.omit(conditional_treatment_data$diff))\n\n\nATE\n\n[1] 0.1959843\n\nATT\n\n[1] 0.0350755\n\nATnT\n\n[1] 0.1609087"
  },
  {
    "objectID": "high_dimension_regularization.html",
    "href": "high_dimension_regularization.html",
    "title": "7  Регуляризация и большая размерность",
    "section": "",
    "text": "8 Double LASSO\nЖивем в ситуации unconfoundedness \\(T_i \\perp Y_{i1}, Y_{i0} | X_i\\)\nВ качестве примера использования регуляризации мы воспользуется работой (Veterinarov, Ivanov, 2018), которые изучали цену этнической дискриминации для арендодателей на рынке жилья. Авторы пытались оценить эффект наличия в объявлении дискриминирующих по этническому признаку формулировак на стоимость аренды квартир. Оказалось, что этническая дискриминация связана со значительным снижением цены.\nИмпортируем данные:\ndata &lt;- read.csv(\"high_dimension_regularization_data/table_cian_mos_ecm.csv\")\nНабор данных включает следующие переменные:\nСоздадим логарифмы площади и цены:\ndata$log_total_area &lt;- log(data$total_area)\ndata$log_price &lt;- log(data$price)"
  },
  {
    "objectID": "high_dimension_regularization.html#что-такое-регуляризация",
    "href": "high_dimension_regularization.html#что-такое-регуляризация",
    "title": "7  Регуляризация и большая размерность",
    "section": "7.1 Что такое регуляризация?",
    "text": "7.1 Что такое регуляризация?\nЗачем нужна регуляризация?\n\nочень много ковариат, которые нужно как-то отобрать, а другие способы не подходят\nпроблема мультиколинеарности\nснижение размерности\nпереобучение\nфильтры\nинформационные критерии Акаике и Шварца\n\nПредположим, что мы находимся в ситуации мультиколинеарности.\n\nСтрогая мультиколинеарность создает проблему неедиснтвенности МНК-оценок.\nПри нестрогой мультиколинеарности оценки все еще являются несмещенными и асимптотически нормальными, однако стандартные ошибки в такой модели будут больше. Это приводит к широким доверительным интервалам и незначимым оценкам.\n\nТогда у нас есть 2 варианта, как с ней бороться. Первый – выбросить часть регрессоров, снизив дисперсию оценок и пожертвовав несмещенностью. Второй – использовать регуляризацию (МНК со штрафной функцией) – включение штрафа в сумму наименьших квадратов. Этот способ, однако, тоже несколько смещает оценки и порождает дилему смещения и дисперсии (bias–variance tradeoff).\n\n\n\nBias–variance tradeoff\n\n\nИсходная постановка МНК:\n\\[\n\\begin{aligned}\n&\\min _{\\hat{\\beta}_j} ESS = \\min _{\\hat{\\beta}_j} \\sum_{i=1}^{n} e_i^2 = \\min _{\\hat{\\beta}_j} \\sum_{i=1}^{n} \\left(y_{i}-\\hat{y}_{i}\\right)^{2} =  \\min _{\\hat{\\beta}_j} \\sum_{i=1}^{n} \\left(y_{i}-\\hat{\\beta}_1 - \\hat{\\beta_2}\\cdot x_i - ...\\right)^{2}\n\\end{aligned}\n\\]\n\n\n\nBias–variance tradeoff\n\n\nЕсли построить график суммы квадратов остатков в зависимости от величины коэффициентов, то он и его линии уровня будут выглядеить следующим образом:\n\n\n\n\n\n\nГрафик ESS\n\n\n\n\n\n\n\nЛинии уровня ESS\n\n\n\n\n\nРегуляризация фактически является задачей Лагранжа, которую вы много раз решали. В исходную оптимизационную задачу мы добавляем дополнительное ограничение, чтобы оценки были не очень большими. Тогда \\(\\lambda\\) является множителем Лагранжа (но в этот раз для нас более важно, что это коэффициент регуляризации).\nВ общем виде постановка задачи регуляризации выглядит следующим образом:\n\\[\n\\begin{aligned}\n&\\min _{\\hat{\\beta}_j} ESS + \\text{штраф}\n\\end{aligned}\n\\]\nВ зависимости от того, какую штрафную функцию мы используем, выделяют несколько основных видов регуляризации:\n\nРидж-регрессия\nРегрессия лассо\nМетод эластичной сети\n\n\n7.1.1 Ридж-регрессия (ridge)\nИногда еще называют L2 или регуляризация Тихонова (почему именно L2 можно почитать тут). В качестве функции штрафа используется сумма квадратов оценок коэффициентов:\n\\[\n\\begin{aligned}\n&\\min _{\\hat{\\beta}_j} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\lambda\\left(\\hat{\\beta}_{1}^{2}+\\hat{\\beta}_{2}^{2}+\\ldots+\\hat{\\beta}_{k}^{2}\\right)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\begin{cases}\n&\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2} \\rightarrow \\underset{\\hat{\\beta}_j}{\\min} \\\\\n&\\hat{\\beta}_{1}^{2}+\\hat{\\beta}_{2}^{2}+\\ldots+\\hat{\\beta}_{k}^{2} \\leq t\n\\end{cases}\n\\end{aligned}\n\\] А такую задачу мы умеем решать графически!\n\n\n\nRigge\n\n\n\n\n\nСравнение LASSO и Rigge\n\n\n\n\n7.1.2 LASSO регрессия\nИногда еще называют L1 или регуляризация через манхэттенское расстояние. В качестве функции штрафа используется сумма модулей оценок коэффициентов:\n\\[\n\\begin{aligned}\n&\\min _{\\hat{\\beta}_j} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\lambda\\left(\\left|\\hat{\\beta}_{1}\\right|+\\left|\\hat{\\beta}_{2}\\right|+\\ldots+\\left|\\hat{\\beta}_{k}\\right|\\right)\n\\end{aligned}\n\\]\n\\[\n\\begin{aligned}\n\\begin{cases}\n&\\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2} \\rightarrow \\underset{\\hat{\\beta}_j}{\\min} \\\\\n&\\left|\\hat{\\beta}_{1}\\right|+\\left|\\hat{\\beta}_{2}\\right|+\\ldots+\\left|\\hat{\\beta}_{k}\\right| \\leq t\n\\end{cases}\n\\end{aligned}\n\\]\n\n\n\nLASSO\n\n\n\n\n\nСравнение LASSO и Rigge\n\n\nКак правило, LASSO чаще приводит к занулению коэффициентов, чем Ridge, это обусловлено геометрией регуляризационного ограничения:\n\n\n\nСравнение LASSO и Rigge\n\n\n\n\n7.1.3 Метод эластичной сети (Elastic Net)\nКомбинацией LASSO и Rigge регрессий является метод эластичной сети.\n\\[\n\\min _{\\hat{\\beta}_j} \\sum_{i=1}^{n}\\left(y_{i}-\\hat{y}_{i}\\right)^{2}+\\lambda_{1} \\sum_{j=1}^{k}\\left|\\hat{\\beta}_{j}\\right|+\\lambda_{2} \\sum_{j=1}^{k} \\hat{\\beta}_{j}^{2}\n\\]\n\n\n\nСравнение LASSO, Rigge и Elastic Net"
  },
  {
    "objectID": "high_dimension_regularization.html#как-выбрать-коэффициент-регуляризации",
    "href": "high_dimension_regularization.html#как-выбрать-коэффициент-регуляризации",
    "title": "7  Регуляризация и большая размерность",
    "section": "7.2 Как выбрать коэффициент регуляризации?",
    "text": "7.2 Как выбрать коэффициент регуляризации?\nЭто делают с помощью кросс валидации (cross validation). Как правило, почти всегда, когда говорят о кросс-валидации, имеют в виду метод k-Fold.\n\n7.2.1 k-Fold\n\nВыбираем \\(m\\) штук \\(\\lambda\\), которые будем проверять;\nФиксируем одну из \\(\\lambda\\);\nВся выборка разделяется на k частей (k - произвольное число, часто от 5 до 10, на картинке внизу как раз 10). В машинке эти части называют фолдами;\nДалее происходит k итераций, во время каждой из которых один фолд выступает в роли тестового множества, а объединение остальных — в роли обучающего. Модель оценивается на k−1 фолде и тестируется на оставшемся. На каждом шаге итерации на тестовом фолде считается метрика качества подгонки, например, MSE (mean squared error);\nДалее k получившихся метрик агрегируются в финальный общий показатель качества модели для зафиксированной \\(\\lambda\\), например считается средняя MSE из k штук;\nПовторяем процедуру для всех \\(m\\) штук \\(\\lambda\\);\nВыбираем \\(\\lambda\\) с минимальным финальным общим показателем \\(\\overline{MSE}\\).\n\n\\[\nMSE_j = \\frac{1}{n_j}\\sum \\left(y_i - \\hat{m}^{(-j)}(x_i)\\right)^2\n\\]\n\\[\n\\overline{MSE}_{\\lambda_m} = \\frac{1}{k}\\sum_{j=1}^k MSE_j\n\\] \\[\n\\lambda^* = \\underset{\\lambda_m}{argmin}\\{\\overline{MSE}_{\\lambda_1}, ... , \\overline{MSE}_{\\lambda_m}\\}\n\\]\n\n\n\nk-Fold\n\n\n\n\n\nk-Fold алгоритм\n\n\n\n\n7.2.2 Кросс-валидация временных рядов\nКросс-валидация моделей для временных рдов осложняется тем, что данные не должны пересекаться по времени: обучающие данные должны идти до тестовых. С учётом этих особенностей фолды в кросс-валидации для временных рядов располагаются вдоль временной оси так, как показано на следующей картинке:\n\n\n\nКросс-валидация временных рядов"
  },
  {
    "objectID": "high_dimension_regularization.html#фильтр-ходрика-прескота",
    "href": "high_dimension_regularization.html#фильтр-ходрика-прескота",
    "title": "7  Регуляризация и большая размерность",
    "section": "7.3 Фильтр Ходрика-Прескота",
    "text": "7.3 Фильтр Ходрика-Прескота\nПо сути формазизация задачи выделения тренда с помощью фильтра Ходрика-Прескота является регуляризацией. Мы ищем компромисс между точностью описания временного ряда и его гладкостью (тренд предыдущего периода должен быть похож на тренд текущего):\n\\[\n\\begin{aligned}\n&\\min_{g} \\underbrace{\\sum_{t=1}^{T}\\left(y_{t}-g_{t}\\right)^{2}}_{\\text{точность описания}}+ \\lambda\\underbrace{\\sum_{t=2}^{T-1} \\left[\\left(g_{t+1}-g_t\\right)-(g_t-g_{t-1})\\right]^2}_{\\text{гладкость тренда}}\n\\end{aligned}\n\\] где \\(y_t\\) – изучаемый временной ряд, \\(g_t\\) – выделяемый тренд.\n\nесли \\(\\lambda=0\\), то \\(y_t=g_t\\);\nесли \\(\\lambda=\\infty\\), то \\(g_{t+1}=g_t=g_{t-1}\\), то есть получим линейный тренд.\n\n\n\n\nФильтр Ходрика-Прескота с разным гиперпараметром"
  },
  {
    "objectID": "high_dimension_regularization.html#double-selection",
    "href": "high_dimension_regularization.html#double-selection",
    "title": "7  Регуляризация и большая размерность",
    "section": "8.1 Double selection",
    "text": "8.1 Double selection\n\nВыбираем набор переменных с помощью LASSO\n\n\\(Y\\sim X\\), получаем \\(\\hat{\\beta}_j^Y \\neq 0\\), оставляем эти иксы;\n\nВыбираем набор переменных с помощью LASSO\n\n\\(T\\sim X\\), получаем \\(\\hat{\\beta}_j^T \\neq 0\\), оставляем эти иксы;\n\nФинальная регрессия (иногда называют post LASSO OLS)\n\n\\(Y \\sim T + \\text{отобранные на прошлых шагах } X\\), получаем \\(\\hat{\\tau}^{DL}=\\hat{ATE}\\)"
  },
  {
    "objectID": "high_dimension_regularization.html#partialling-out",
    "href": "high_dimension_regularization.html#partialling-out",
    "title": "7  Регуляризация и большая размерность",
    "section": "8.2 Partialling-out",
    "text": "8.2 Partialling-out\nПо теореме Фриша-Ву-Ловелла то же самое можно сделать с помощью другой процедуры.\n\nВыбираем набор переменных с помощью LASSO\n\n\\(Y\\sim X\\), получаем \\(\\hat{\\beta}_j^Y \\neq 0\\), оставляем эти иксы;\n\nОцениваем регрессию \\(Y\\sim X\\) только на те \\(X\\), которые отобрали на прошлом шаге, где \\(\\hat{\\beta}_j^Y \\neq 0\\). Получаем остатки модели \\(e_i^Y\\);\nВыбираем набор переменных с помощью LASSO\n\n\\(T\\sim X\\), получаем \\(\\hat{\\beta}_j^T \\neq 0\\), оставляем эти иксы;\n\nОцениваем регрессию \\(T\\sim X\\) только на те \\(X\\), которые отобрали на прошлом шаге, где \\(\\hat{\\beta}_j^T \\neq 0\\). Получаем остатки модели \\(e_i^T\\);\nФинальная регрессия остатков на остатки\n\n\\(e_i^Y \\sim e_i^T\\), получаем \\(\\hat{\\tau}^{DL}=\\hat{ATE}\\)"
  },
  {
    "objectID": "high_dimension_regularization.html#lasso",
    "href": "high_dimension_regularization.html#lasso",
    "title": "7  Регуляризация и большая размерность",
    "section": "9.1 LASSO",
    "text": "9.1 LASSO\n\n9.1.1 Подготовка\nСинтаксис функции, которую мы будем далее использовать, предполагает, что мы должны передавать ей зависимую переменную, контрольные переменные и формулу модели отдельными объектами. Поэтому нам нужно их заранее заготовить.\n\nformula &lt;- log_price ~ log_total_area + discrim_proxy + Mos_center + \n  Akimanka_rajon + Hamovniki_rajon + Tverskoj_rajon + Taganskij_rajon +\n  Krasnoselskij_rajon + Mesanskij_rajon + Zamoskvorece_rajon +\n  Basmannyj_rajon + Arbat_rajon + first_floor + one_room + two_rooms +\n  three_rooms + four_and_over_rooms + starii_fond + blochnii + \n  derevjannii + kirpichnii + monolitnii + panelnii + stalinskii + repair # формула для регресии\n\nX &lt;- model.matrix(data=data,formula) # матрица для оценки модели\n\nСледующий шаг, который нам нужно выполнить, это решить, какую \\(\\lambda\\) мы будем использовать. Мы можем захотеть проверить сразу несколько, для этого создадим вектор, в который поместим все значения \\(\\lambda\\), которые мы хотим перебрать:\n\nlambdas &lt;- seq(0,1,length=30) # 10 штук от 0 до 1 с равными интервалами\nlambdas \n\n [1] 0.00000000 0.03448276 0.06896552 0.10344828 0.13793103 0.17241379\n [7] 0.20689655 0.24137931 0.27586207 0.31034483 0.34482759 0.37931034\n[13] 0.41379310 0.44827586 0.48275862 0.51724138 0.55172414 0.58620690\n[19] 0.62068966 0.65517241 0.68965517 0.72413793 0.75862069 0.79310345\n[25] 0.82758621 0.86206897 0.89655172 0.93103448 0.96551724 1.00000000\n\n\n\n\n9.1.2 Оценивание\nРегуляризация в R реализована в библиотеке glmnet:\n\nlibrary(glmnet)\n\n\nmodel_lasso &lt;- glmnet(x=X, # матрица иксов\n                      y=data$log_price, # зависимая переменная\n                      alpha = 1, # 1 лассо, 0 ридж\n                      lambda = lambdas) # вектор лямбд\n\n\n\n9.1.3 Диагностика\nВ первую очередь мы можем посмотреть общую сводку по оцененным тридцати моделям:\n\nprint(model_lasso)\n\n\nCall:  glmnet(x = X, y = data$log_price, alpha = 1, lambda = lambdas) \n\n   Df  %Dev  Lambda\n1   0  0.00 1.00000\n2   0  0.00 0.96550\n3   0  0.00 0.93100\n4   0  0.00 0.89660\n5   0  0.00 0.86210\n6   0  0.00 0.82760\n7   0  0.00 0.79310\n8   0  0.00 0.75860\n9   0  0.00 0.72410\n10  0  0.00 0.68970\n11  0  0.00 0.65520\n12  0  0.00 0.62070\n13  1  0.71 0.58620\n14  1  7.94 0.55170\n15  1 14.73 0.51720\n16  1 21.09 0.48280\n17  1 27.00 0.44830\n18  1 32.48 0.41380\n19  1 37.52 0.37930\n20  1 42.12 0.34480\n21  1 46.28 0.31030\n22  2 50.33 0.27590\n23  2 55.24 0.24140\n24  2 59.50 0.20690\n25  2 63.10 0.17240\n26  2 66.04 0.13790\n27  3 68.36 0.10340\n28  4 70.63 0.06897\n29  5 72.20 0.03448\n30 25 73.15 0.00000\n\n\nЭта сводка включает в себя:\n\nDf – количество ненулевых коэффициентов;\n%Dev – процент объясненной дисперсии;\nLambda – значение параметра регуляризации.\n\nНапример, мы видим, что сокращая процент объясненной дисперсии с 73% до 68% мы убираем целых 22 коэффициента!\nТакже мы можем получить коэффициенты модели для одной или нескольких лямбд в диапазоне задаваемой нами ранее последовательности. Первый столбец содержит оценки при \\(\\lambda = 1\\) и соответсвует обычному МНК без регуляризации:\n\ncoef(model_lasso, s = c(0, 0.1, 0.3, 0.5, 0.7))\n\n27 x 5 sparse Matrix of class \"dgCMatrix\"\n                              s1           s2         s3         s4       s5\n(Intercept)          6.688934013  6.884354744 8.30906359 10.0798005 10.87369\n(Intercept)          .            .           .           .          .      \nlog_total_area       1.000871639  0.956754318 0.62494599  0.1935012  .      \ndiscrim_proxy       -0.067431338  .           .           .          .      \nMos_center           0.526321806  0.363336145 0.00375921  .          .      \nAkimanka_rajon      -0.003209375  .           .           .          .      \nHamovniki_rajon      0.049532158  .           .           .          .      \nTverskoj_rajon       0.053744571  .           .           .          .      \nTaganskij_rajon     -0.257458484  .           .           .          .      \nKrasnoselskij_rajon -0.164909968  .           .           .          .      \nMesanskij_rajon     -0.031110726  .           .           .          .      \nZamoskvorece_rajon  -0.018498909  .           .           .          .      \nBasmannyj_rajon     -0.201802963  .           .           .          .      \nArbat_rajon          0.022684170  .           .           .          .      \nfirst_floor         -0.061025196  .           .           .          .      \none_room            -0.026247169  .           .           .          .      \ntwo_rooms           -0.024026147  .           .           .          .      \nthree_rooms          0.001392248  .           .           .          .      \nfour_and_over_rooms  0.029859360  .           .           .          .      \nstarii_fond          0.066064231  .           .           .          .      \nblochnii            -0.026137209  .           .           .          .      \nderevjannii         -0.543010257  .           .           .          .      \nkirpichnii          -0.048384083  .           .           .          .      \nmonolitnii          -0.019660744  .           .           .          .      \npanelnii            -0.122118162 -0.001149653 .           .          .      \nstalinskii           0.050088144  .           .           .          .      \nrepair               0.146070488  0.006971480 .           .          .      \n\n\nЕсть еще несколько способов взглянуть как выбор гиперпараметра влияет на коэффициенты модели. Построим несколько графиков.\n\n9.1.3.1 Изменение коэффициентов в зависимости от размера штрафов (lambda)\nНачнем с графика зависимости величины коэффициентов от логарифма лямбды:\n\nplot(model_lasso, xvar = 'lambda', label = TRUE)\n\n\n\n\n\n2.7^(-2.3)\n\n[1] 0.1018271\n\n2.7^(-1.3)\n\n[1] 0.2749331\n\n2.7^(-0.5)\n\n[1] 0.6085806\n\n\nВидим, что при лямбде, равной 0.6, зануляются все коэффициенты модели.\n\n\n9.1.3.2 Изменение коэффициентов в зависимости от величины доли объясненной дисперсии\nТеперь построим график зависимости величины коэффициентов от величины объясненной дисперсии:\n\nplot(model_lasso, xvar = 'dev', label = TRUE)\n\n\n\n\nСнова видим, что снижение объясненной дисперсии с 70% на несколько процентных пунктов позволяет убрать из регрессии более десятка коэффициентов.\n\n\n9.1.3.3 Изменение коэффициентов в зависимости от суммарного штрафа\nПоследний график – зависимость величины коэффициентов от размера накладываемого штрафа.\n\nplot(model_lasso, xvar = 'norm', label = TRUE)\n\n\n\n\nВидим, что большую часть штрафа объясняют второй и четвертый коэффициенты.\n\n\n\n9.1.4 Кросс-валидация\nКак было оговорено выше, выбрать величину лямды нам помогает процедура под названием кросс-валидация. Найдем лямбду, которая минимизирует MSE:\n\nmodel_cv &lt;- cv.glmnet(X, # матрица иксов\n                      data$log_price, # зависимая переменная\n                      alpha=1, # 1 лассо, 0 ридж\n                      type.measure =\"mse\") # метрика качества\n\nГрафик зависимости MSE в кросс-валидации в зависимости от лямд:\n\nplot(model_cv)\n\n\n\n\nФункция cv.glmnet расчитывает две лямды.\nПервая лямбда минимизирует MSE:\n\nmodel_cv$lambda.min\n\n[1] 0.0009607159\n\n\nМы можем видеть, что эта лямбда получается очень маленькой, то есть оценки регрессии практически дублируют МНК без регуляризации. Поэтому также рассчитывается вторая лямбда (консервативная), которая закладывает чуть больший запас прочности. Она больше минимальной лямбды (которая минимизирует MSE) на одно стандартное отклонение:\n\nmodel_cv$lambda.1se\n\n[1] 0.01299894\n\n\nМы также можем сравнить коэффициенты в двух моделях с вышеуказанными лямбдами:\n\ncoef(model_cv, s = \"lambda.min\")\n\n27 x 1 sparse Matrix of class \"dgCMatrix\"\n                               s1\n(Intercept)          6.6370458325\n(Intercept)          .           \nlog_total_area       1.0068449681\ndiscrim_proxy       -0.0657833140\nMos_center           0.5040949860\nAkimanka_rajon       0.0139579052\nHamovniki_rajon      0.0648867791\nTverskoj_rajon       0.0739094983\nTaganskij_rajon     -0.2241082038\nKrasnoselskij_rajon -0.1289100034\nMesanskij_rajon     -0.0004072351\nZamoskvorece_rajon   .           \nBasmannyj_rajon     -0.1664366224\nArbat_rajon          0.0419087352\nfirst_floor         -0.0571914907\none_room            -0.0001325229\ntwo_rooms            .           \nthree_rooms          0.0215989064\nfour_and_over_rooms  0.0479392737\nstarii_fond          0.0565052634\nblochnii            -0.0179282802\nderevjannii         -0.4934208218\nkirpichnii          -0.0413662251\nmonolitnii          -0.0124146216\npanelnii            -0.1161728511\nstalinskii           0.0488024624\nrepair               0.1441384544\n\n\n\ncoef(model_cv, s = \"lambda.1se\")\n\n27 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s1\n(Intercept)          6.50826092\n(Intercept)          .         \nlog_total_area       1.03670531\ndiscrim_proxy       -0.04528514\nMos_center           0.49361870\nAkimanka_rajon       .         \nHamovniki_rajon      .         \nTverskoj_rajon       0.04236198\nTaganskij_rajon     -0.06999387\nKrasnoselskij_rajon  .         \nMesanskij_rajon      .         \nZamoskvorece_rajon   .         \nBasmannyj_rajon      .         \nArbat_rajon          .         \nfirst_floor         -0.01300153\none_room             .         \ntwo_rooms            .         \nthree_rooms          .         \nfour_and_over_rooms  .         \nstarii_fond          .         \nblochnii             .         \nderevjannii          .         \nkirpichnii           .         \nmonolitnii           .         \npanelnii            -0.08397409\nstalinskii           .         \nrepair               0.12813136"
  },
  {
    "objectID": "high_dimension_regularization.html#ridge",
    "href": "high_dimension_regularization.html#ridge",
    "title": "7  Регуляризация и большая размерность",
    "section": "9.2 Ridge",
    "text": "9.2 Ridge\nС ридж всё аналогично, набор переменных и лямбд будем использовать те же, поэтому шаг с подготовкой можем пропустить.\n\n9.2.1 Оценивание\n\nmodel_ridge &lt;- glmnet(x=X, # матрица иксов\n                      y=data$log_price, # зависимая переменная\n                      alpha = 0, # 1 лассо, 0 ридж\n                      lambda = lambdas) # вектор лямбд\n\n\n\n9.2.2 Диагностика\n\nprint(model_ridge)\n\n\nCall:  glmnet(x = X, y = data$log_price, alpha = 0, lambda = lambdas) \n\n   Df  %Dev  Lambda\n1  25 63.20 1.00000\n2  25 63.55 0.96550\n3  25 63.90 0.93100\n4  25 64.25 0.89660\n5  25 64.60 0.86210\n6  25 64.95 0.82760\n7  25 65.30 0.79310\n8  25 65.66 0.75860\n9  25 66.01 0.72410\n10 25 66.36 0.68970\n11 25 66.71 0.65520\n12 25 67.06 0.62070\n13 25 67.41 0.58620\n14 25 67.76 0.55170\n15 25 68.10 0.51720\n16 25 68.45 0.48280\n17 25 68.79 0.44830\n18 25 69.14 0.41380\n19 25 69.48 0.37930\n20 25 69.82 0.34480\n21 25 70.16 0.31030\n22 25 70.50 0.27590\n23 25 70.84 0.24140\n24 25 71.19 0.20690\n25 25 71.54 0.17240\n26 25 71.90 0.13790\n27 25 72.27 0.10340\n28 25 72.63 0.06897\n29 25 72.97 0.03448\n30 25 73.15 0.00000\n\n\n\nDf – количество ненулевых коэффициентов;\n%Dev – процент объясненной дисперсии;\nLambda – значение параметра регуляризации.\n\n\ncoef(model_ridge, s = c(0, 0.1, 0.3, 0.5, 0.7))\n\n27 x 5 sparse Matrix of class \"dgCMatrix\"\n                             s1          s2          s3          s4\n(Intercept)          6.64622923  7.82150033  8.59638355  8.94662237\n(Intercept)          .           .           .           .         \nlog_total_area       0.99897873  0.72448212  0.53737656  0.45303267\ndiscrim_proxy       -0.06742813 -0.08381652 -0.09346609 -0.09479466\nMos_center           0.27926934  0.28275601  0.26996717  0.25443798\nAkimanka_rajon       0.24401916  0.27056845  0.27099289  0.25843118\nHamovniki_rajon      0.29645525  0.27270608  0.24487862  0.22459975\nTverskoj_rajon       0.30072404  0.29333929  0.27584561  0.25871019\nTaganskij_rajon     -0.01039935 -0.01933351 -0.01607290 -0.01063353\nKrasnoselskij_rajon  0.08210284  0.06971030  0.06511376  0.06345969\nMesanskij_rajon      0.21590629  0.21929606  0.21465652  0.20559180\nZamoskvorece_rajon   0.22849227  0.21641093  0.19970664  0.18628395\nBasmannyj_rajon      0.04522337  0.05166245  0.06357240  0.06975185\nArbat_rajon          0.26975954  0.27304921  0.26068747  0.24494209\nfirst_floor         -0.06115603 -0.08482058 -0.09276298 -0.09073422\none_room             0.02345361 -0.12797503 -0.18005839 -0.18634001\ntwo_rooms            0.02646231 -0.03230265 -0.04218364 -0.04271241\nthree_rooms          0.05268420  0.10293849  0.14283069  0.14877111\nfour_and_over_rooms  0.08163659  0.19559792  0.25532900  0.25750181\nstarii_fond          0.06617482  0.10309458  0.14759133  0.16771742\nblochnii            -0.02655046 -0.06011294 -0.07320187 -0.07488527\nderevjannii         -0.54356480 -0.53405633 -0.46142388 -0.39987828\nkirpichnii          -0.04863661 -0.05742225 -0.04577488 -0.03476132\nmonolitnii          -0.01960235  0.01351756  0.03902709  0.04758936\npanelnii            -0.12243000 -0.13729045 -0.13396670 -0.12668462\nstalinskii           0.04997978  0.05383198  0.07283667  0.08357672\nrepair               0.14621993  0.15011033  0.14200161  0.13225801\n                              s5\n(Intercept)          9.168951934\n(Intercept)          .          \nlog_total_area       0.399735732\ndiscrim_proxy       -0.093328861\nMos_center           0.239758886\nAkimanka_rajon       0.244137214\nHamovniki_rajon      0.208128549\nTverskoj_rajon       0.243037619\nTaganskij_rajon     -0.006234785\nKrasnoselskij_rajon  0.061843445\nMesanskij_rajon      0.195679384\nZamoskvorece_rajon   0.174760220\nBasmannyj_rajon      0.072451510\nArbat_rajon          0.229961879\nfirst_floor         -0.086664976\none_room            -0.182340426\ntwo_rooms           -0.041285275\nthree_rooms          0.146608650\nfour_and_over_rooms  0.248081512\nstarii_fond          0.176042856\nblochnii            -0.073901381\nderevjannii         -0.352313526\nkirpichnii          -0.026721380\nmonolitnii           0.050441717\npanelnii            -0.119637562\nstalinskii           0.088649856\nrepair               0.123386550\n\n\n\n9.2.2.1 Изменение коэффициентов в зависимости от размера штрафов (lambda)\n\nplot(model_ridge, xvar = 'lambda', label = TRUE)\n\n\n\n\n\n\n9.2.2.2 Изменение коэффициентов в зависимости от величины доли объясненной дисперсии\n\nplot(model_ridge, xvar = 'dev', label = TRUE)\n\n\n\n\n\n\n9.2.2.3 Изменение коэффициентов в зависимости от суммарного штрафа\n\nplot(model_ridge, xvar = 'norm', label = TRUE)\n\n\n\n\n\n\n\n9.2.3 Кросс-валидация\n\nmodel_cv &lt;- cv.glmnet(X, # матрица иксов\n                      data$log_price, # зависимая переменная\n                      alpha=1, # 1 лассо, 0 ридж\n                      type.measure =\"mse\") # метрика качества\n\nГрафик зависимости MSE в кросс-валидации в зависимости от лямд:\n\nplot(model_cv)\n\n\n\n\nОптимальные лямды:\n\nmodel_cv$lambda.min\n\n[1] 0.0009607159\n\nmodel_cv$lambda.1se\n\n[1] 0.03295706"
  },
  {
    "objectID": "high_dimension_regularization.html#double-lasso-1",
    "href": "high_dimension_regularization.html#double-lasso-1",
    "title": "7  Регуляризация и большая размерность",
    "section": "9.3 Double LASSO",
    "text": "9.3 Double LASSO\n\nlibrary(hdm)\n\n\n9.3.1 Способ 1 (с помощью пакета)\nГотовим аргументы:\n\nformula2 &lt;- log_price ~ log_total_area + Mos_center + \n  Akimanka_rajon + Hamovniki_rajon + Tverskoj_rajon + Taganskij_rajon +\n  Krasnoselskij_rajon + Mesanskij_rajon + Zamoskvorece_rajon +\n  Basmannyj_rajon + Arbat_rajon + first_floor + one_room + two_rooms +\n  three_rooms + four_and_over_rooms + starii_fond + blochnii + \n  derevjannii + kirpichnii + monolitnii + panelnii + stalinskii + repair # формула для регресии без тритмента\n\nX &lt;- model.matrix(data=data, formula2) # матрица для оценки модели\ny &lt;- data$log_price # зависимая переменная\n\nОцениваем double lasso модель:\n\nmodel_DR &lt;- rlassoEffect(X, # матрица иксов\n                         y, # зависимая переменная\n                         data$discrim_proxy, # тритмент\n                         method = 'double selection') # по умолчанию 'partialling out', но можно и 'double selection'\n\nТаким образом, эффект от дискриминации равен -0.067:\n\nsummary(model_DR)\n\n[1] \"Estimates and significance testing of the effect of target variables\"\n   Estimate. Std. Error t value Pr(&gt;|t|)    \nd1  -0.06736    0.00564  -11.94   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nМожем посмотреть, какие переменные процедура выкинула, а какие оставила:\n\nmodel_DR$selection.index\n\n        (Intercept)      log_total_area          Mos_center      Akimanka_rajon \n              FALSE                TRUE                TRUE               FALSE \n    Hamovniki_rajon      Tverskoj_rajon     Taganskij_rajon Krasnoselskij_rajon \n               TRUE                TRUE                TRUE                TRUE \n    Mesanskij_rajon  Zamoskvorece_rajon     Basmannyj_rajon         Arbat_rajon \n              FALSE               FALSE                TRUE               FALSE \n        first_floor            one_room           two_rooms         three_rooms \n               TRUE               FALSE               FALSE               FALSE \nfour_and_over_rooms         starii_fond            blochnii         derevjannii \n               TRUE               FALSE                TRUE                TRUE \n         kirpichnii          monolitnii            panelnii          stalinskii \n               TRUE                TRUE                TRUE                TRUE \n             repair \n               TRUE \n\n\n\n\n9.3.2 Способ 2 (Double selection руками)\nШаг 1\n\nstep_1 &lt;- cv.glmnet(X, \n                    data$log_price, \n                    alpha=1, \n                    type.measure =\"mse\")\n\nПосмотрим, какие коэффициенты остались после шага 1:\n\ncoef(step_1, s=\"lambda.1se\")\n\n26 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s1\n(Intercept)          6.50654463\n(Intercept)          .         \nlog_total_area       1.03594098\nMos_center           0.48603593\nAkimanka_rajon       .         \nHamovniki_rajon      .         \nTverskoj_rajon       0.01793005\nTaganskij_rajon      .         \nKrasnoselskij_rajon  .         \nMesanskij_rajon      .         \nZamoskvorece_rajon   .         \nBasmannyj_rajon      .         \nArbat_rajon          .         \nfirst_floor          .         \none_room             .         \ntwo_rooms            .         \nthree_rooms          .         \nfour_and_over_rooms  .         \nstarii_fond          .         \nblochnii             .         \nderevjannii          .         \nkirpichnii           .         \nmonolitnii           .         \npanelnii            -0.07360519\nstalinskii           .         \nrepair               0.11702770\n\n\nОстались log_total_area, Mos_center, panelnii, repair\nШаг 2\n\nstep_2 &lt;- cv.glmnet(X, \n                    data$discrim_proxy, \n                    alpha=1, \n                    type.measure =\"mse\",\n                    family=\"binomial\")\n\nПосмотрим, какие коэффициенты остались после шага 2:\n\ncoef(step_2, s=\"lambda.1se\")\n\n26 x 1 sparse Matrix of class \"dgCMatrix\"\n                             s1\n(Intercept)          2.58136299\n(Intercept)          .         \nlog_total_area      -0.99628560\nMos_center          -0.59645010\nAkimanka_rajon       .         \nHamovniki_rajon      .         \nTverskoj_rajon       .         \nTaganskij_rajon      .         \nKrasnoselskij_rajon  .         \nMesanskij_rajon      .         \nZamoskvorece_rajon   .         \nBasmannyj_rajon      .         \nArbat_rajon          .         \nfirst_floor          .         \none_room             .         \ntwo_rooms            0.01441866\nthree_rooms          .         \nfour_and_over_rooms  .         \nstarii_fond          .         \nblochnii             .         \nderevjannii          .         \nkirpichnii           .         \nmonolitnii           .         \npanelnii             0.21044197\nstalinskii           .         \nrepair              -0.15377264\n\n\nОстались log_total_area, Mos_center, panelnii, repair\nШаг 3\n\nstep_3 &lt;- lm(data$log_price ~ discrim_proxy + log_total_area + Mos_center + panelnii + repair,\n             data=data)\n\nПосмотрим оценку эффекта:\n\nsummary(step_3)\n\n\nCall:\nlm(formula = data$log_price ~ discrim_proxy + log_total_area + \n    Mos_center + panelnii + repair, data = data)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.6650 -0.2068  0.0192  0.2200  1.9787 \n\nCoefficients:\n                Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)     6.458639   0.023902  270.22   &lt;2e-16 ***\ndiscrim_proxy  -0.067855   0.006365  -10.66   &lt;2e-16 ***\nlog_total_area  1.048082   0.005808  180.47   &lt;2e-16 ***\nMos_center      0.521361   0.006913   75.42   &lt;2e-16 ***\npanelnii       -0.100640   0.005454  -18.45   &lt;2e-16 ***\nrepair          0.145571   0.004981   29.23   &lt;2e-16 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3842 on 26035 degrees of freedom\nMultiple R-squared:  0.7281,    Adjusted R-squared:  0.728 \nF-statistic: 1.394e+04 on 5 and 26035 DF,  p-value: &lt; 2.2e-16\n\n\nТаким образом, эффект от дискриминации равен -0.067."
  },
  {
    "objectID": "heterogenous_treatment_effects.html#теория",
    "href": "heterogenous_treatment_effects.html#теория",
    "title": "7  Гетерогенные эффекты",
    "section": "7.1 Теория",
    "text": "7.1 Теория\nin progress…"
  },
  {
    "objectID": "heterogenous_treatment_effects.html#пример",
    "href": "heterogenous_treatment_effects.html#пример",
    "title": "7  Гетерогенные эффекты",
    "section": "7.2 Пример",
    "text": "7.2 Пример\n\nlibrary(dplyr)\nlibrary(ggplot2)\nlibrary(stargazer)\nlibrary(grf)\n\ndata &lt;- read.csv(\"table_cian_mos_ecm.csv\")\n\nНабор данных включает следующие переменные:\n\nprice – цена аренды квартиры в рублях;\ntotal_area – общая площадь квартиры в квадратных метрах;\n\ndiscrim_proxy – наличие дискриминирующего текста в описании объявления;\n*_rajon – набор бинарных переменных, соотвествующих районам Москвы, где расположена квартира;\nfirst_floor – бинарная переменная, равная единице, если квартира расположена на первом этаже;\n*_rooms – набор бинарных переменных, соотвествующих количеству комнат в квартире;\nstarii_fond – бинарная переменная, равная единице, если квартира принадлежит к старому жилому фонду;\nblochnii – бинарная переменная, равная единице, если квартира находится в блочном доме;\nderevjannii – бинарная переменная, равная единице, если квартира находится в деревянном доме;\nkirpichnii – бинарная переменная, равная единице, если квартира находится в кирпичном доме;\nmonolitnii – бинарная переменная, равная единице, если квартира находится в монолитном доме;\npanelnii – бинарная переменная, равная единице, если квартира находится в кирпичном доме;\nstalinskii – бинарная переменная, равная единице, если квартира находится в сталинском доме;\nrepair – бинарная переменная, равная единице, если в квартире сделан ремонт;\nfour_and_over_rooms – бинарная переменная, равная единице, если в квартире четыре и более комнат.\n\n\n7.2.1 Подготовка\nСоздадим логарифмы площади и цены:\n\ndata$log_total_area &lt;- log(data$total_area)\ndata$log_price &lt;- log(data$price)\n\nПроизвольно разделим выборку на 2 части.\nКак и раньше выберем нужные нам строчки, используя двоеточие для создания последовательности чисел. Первая половина датасета будет обучающей выборкой, вторая – тестовой:\n\ndata_train &lt;- data[1:13000,] # обучающая выборка\ndata_test &lt;- data[13001:26041,] # тестовая выборка\n\nСинтаксис функции, которую мы будем далее использовать, предполагает, что мы должны передавать ей зависимую переменную, контрольные переменные и формулу модели отдельными объектами. Поэтому нам нужно их заранее заготовить.\n\nformula &lt;- log_price ~ log_total_area + Mos_center + \n  Akimanka_rajon + Hamovniki_rajon + Tverskoj_rajon + Taganskij_rajon +\n  Krasnoselskij_rajon + Mesanskij_rajon + Zamoskvorece_rajon +\n  Basmannyj_rajon + Arbat_rajon + first_floor + one_room + two_rooms +\n  three_rooms + four_and_over_rooms + starii_fond + blochnii + \n  derevjannii + kirpichnii + monolitnii + panelnii + stalinskii + repair \n\nX &lt;- model.matrix(data=data,formula)\n\nX матрица контрольных переменных, где первый столбец – константа.\n\nhead(X, 5)\n\n  (Intercept) log_total_area Mos_center Akimanka_rajon Hamovniki_rajon\n1           1       4.812184          0              0               0\n2           1       3.427515          0              0               0\n3           1       3.637586          0              0               0\n4           1       5.075174          1              0               0\n5           1       3.912023          0              0               0\n  Tverskoj_rajon Taganskij_rajon Krasnoselskij_rajon Mesanskij_rajon\n1              0               0                   0               0\n2              0               0                   0               0\n3              0               0                   0               0\n4              1               0                   0               0\n5              0               0                   0               0\n  Zamoskvorece_rajon Basmannyj_rajon Arbat_rajon first_floor one_room two_rooms\n1                  0               0           0           0        0         0\n2                  0               0           0           0        1         0\n3                  0               0           0           0        1         0\n4                  0               0           0           0        0         0\n5                  0               0           0           1        0         1\n  three_rooms four_and_over_rooms starii_fond blochnii derevjannii kirpichnii\n1           1                   0           0        0           0          0\n2           0                   0           0        0           0          0\n3           0                   0           0        0           0          0\n4           1                   0           0        0           0          0\n5           0                   0           0        1           0          0\n  monolitnii panelnii stalinskii repair\n1          0        0          1      0\n2          0        1          0      0\n3          0        1          0      1\n4          0        0          0      0\n5          0        0          0      0\n\n\nСохраним все нужные нам объекты отдельно:\n\nX_mod &lt;- X[1:13000,]\nY_mod &lt;- data_train$log_price\nT_mod &lt;- data_train$discrim_proxy\n\n\n\n7.2.2 Причинный случайный лес\nИспользуя заготовленную обучающую выборку строим лес, состоящий из 1000 деревьев:\n\nB &lt;- 10000\nmodel &lt;- causal_forest(X = X_mod, \n                       Y = Y_mod, \n                       W = T_mod,\n                       num.trees = B)\n\nСчитаем оценки на тестовой выборке:\n\nX.test &lt;- X[13001:26041,]\ntau_forest &lt;- predict(model, \n                      X.test, \n                      estimate.variance = TRUE )\n\nПосмотрим как распределены оценки:\n\nhist(tau_forest$predictions)\n\n\n\nsummary(tau_forest$predictions)\n\n     Min.   1st Qu.    Median      Mean   3rd Qu.      Max. \n-0.330294 -0.120687 -0.061557 -0.071005 -0.007958  0.090587 \n\n\nПосчитаем для каждой оценки доверительный интервал:\n\nlow &lt;- tau_forest$predictions - 1.96*sqrt(tau_forest$variance.estimates)\nupper &lt;- tau_forest$predictions + 1.96*sqrt(tau_forest$variance.estimates)\nCI &lt;- data.frame(estimation = tau_forest$predictions, low = low, upper = upper)\nhead(CI,5)\n\n   estimation          low       upper\n1  0.06194145  0.005284023  0.11859887\n2 -0.02367664 -0.117214051  0.06986076\n3 -0.15582478 -0.254837879 -0.05681168\n4 -0.05883448 -0.140415310  0.02274634\n5  0.02018377 -0.046290165  0.08665770\n\n\n\n\n7.2.3 Важность факторов\nПомимо того, что основным посылом для гетерогенных оценок было желание определить тритмент эффект для каждого наблюдения, имеющего уникальный набор характеристик, нам еще может быть интересно исследовать, какой вклад имеют эти характеристики в эффект:\n\nvariable_importance(model)\n\n              [,1]\n [1,] 0.000000e+00\n [2,] 4.253223e-01\n [3,] 8.881583e-04\n [4,] 0.000000e+00\n [5,] 0.000000e+00\n [6,] 3.955426e-05\n [7,] 0.000000e+00\n [8,] 8.780927e-06\n [9,] 0.000000e+00\n[10,] 0.000000e+00\n[11,] 0.000000e+00\n[12,] 2.748574e-04\n[13,] 1.702933e-02\n[14,] 1.136934e-02\n[15,] 1.827115e-02\n[16,] 1.037088e-02\n[17,] 6.833166e-04\n[18,] 0.000000e+00\n[19,] 1.404885e-02\n[20,] 0.000000e+00\n[21,] 1.956268e-02\n[22,] 3.874035e-02\n[23,] 8.259465e-02\n[24,] 0.000000e+00\n[25,] 3.607958e-01\n\nplot(variable_importance(model))\n\n\n\n\nИз-за того, что подписаны не все точки, неудобно рассматривать факторы, перерисуем в ggplot. Идейно будет то же самое, но визуально приятнее.\n\n# Для ggplot нужен отдельный набор данных, поэтому сохраним важность факторов и их номера в отдельный фрейм данных\nimportance &lt;- data.frame(n = c(1:dim(variable_importance(model))[1]), \n                         variable_importance = variable_importance(model))\n\nggplot(importance, aes(x = factor(n), y = variable_importance)) +\n  geom_point() # если навесить factor() у икса, то подпишутся сразу все точки, если нет, то будет как на прошлом графике\n\n\n\n\nПосмотрим что же это за характеристики:\n\ncolnames(X)[2]\n\n[1] \"log_total_area\"\n\ncolnames(X)[22]\n\n[1] \"monolitnii\"\n\ncolnames(X)[23]\n\n[1] \"panelnii\"\n\ncolnames(X)[25]\n\n[1] \"repair\"\n\n\nПлощадь квартиры и ремонт в доме самые важные, меньше вклад типа дома (панельки и монолитные).\n\n\n7.2.4 Гетерогенность эффекта по характеристикам\nПопробуем понять для каких квартир эффект наибольший.\n\nplot(tau_forest$predictions ~ data_test$total_area)\n\n\n\n\nЭффект отрицательный для примерно 60-100 м2\n\n# эффект больше, если был ремонт\nggplot(data_test) + \n  geom_boxplot(aes(factor(repair), tau_forest$predictions))\n\n\n\n# эффект больше в центре\nggplot(data_test) + \n  geom_boxplot(aes(factor(Mos_center), tau_forest$predictions))\n\n\n\n# эффект меньше для панелек\nggplot(data_test)+geom_boxplot(aes(factor(panelnii), \n                                   tau_forest$predictions))\n\n\n\n\n\n# проверяем по комнатам:\ndata_test$room_number&lt;- 1*data_test$one_room + \n  2*data_test$two_rooms + \n  3* data_test$three_rooms + \n  4*data_test$four_and_over_rooms\n\n# эффект негативнее для 2-3 комнатных\nggplot(data_test) + \n  geom_boxplot(aes(factor(room_number), tau_forest$predictions))\n\n\n\n\n\n\n7.2.5 Heatmaps\nНамного интереснее смотреть вклад сразу нескольких эффектов. Для этого есть тепловые карты. По осям располагаются характеристики, а интенсивность эффекта отражается цветом ячейки, расположенной на пересечении значений характеристик:\n\ndata_test$tau &lt;- tau_forest$predictions\n\nggplot(data=data_test, aes(repair, Mos_center)) +\n  geom_tile(aes(fill=data_test$tau))\n\n\n\nggplot(data=data_test, aes(repair, room_number)) +\n  geom_tile(aes(fill=data_test$tau))\n\n\n\nggplot(data=data_test, aes(Mos_center, room_number)) +\n  geom_tile(aes(fill=data_test$tau))\n\n\n\n\n\nhist(data_test$total_area)\n\n\n\ndata_test$cut_area&lt;-cut(data_test$total_area,\n                  breaks=c(0,30,40,50,60,70,80,90,100,110,Inf))\n\n\nggplot(data=data_test, aes(Mos_center, cut_area)) +\n  geom_tile(aes(fill=data_test$tau))\n\n\n\n\n\nggplot(data=data_test, aes(room_number, cut_area)) +\n  geom_tile(aes(fill=data_test$tau))\n\n\n\n\nИтог: больше всего теряют хозяева больших двушек не в центре, до -25% арендной платы."
  },
  {
    "objectID": "regression_discontinuity.html#четкая-разрывная-регрессия",
    "href": "regression_discontinuity.html#четкая-разрывная-регрессия",
    "title": "8  Разрывная регрессия",
    "section": "8.1 Четкая разрывная регрессия",
    "text": "8.1 Четкая разрывная регрессия\nВ нашей жизни есть много правил. Очень часто эти правила регламентированы какими-то критериями. Например, чтобы поступить в университет, нужно набрать определенное количество баллов, чтобы понести наказание за вождение в нетрезвом виде, в крови должно быть обнаружено более определенного числа промилле алкоголя, чтобы получить отличную оценку, нужно набрать критерий по теории на экзамене и так далее… Иными словами мы в своем изучении эконометрических методов столнулись с ситуацией, когда наш тритмент не просто эндогенный, он еще и может зависеть от какой-то другой континуальной переменной. Для того, чтобы решать такие задачи, был придуман дизайн разрывной регрессии.\nБазовая постановка выглядит следующим образом:\n\n\\(Y_0, Y_1\\) – потенциальные исходы\n\\(T\\) – тритмент переменная\n\\(R\\) – переменная, по которой есть критерий попадания в тритмент (running variable, “бегущая перменная”)\n\\(X\\) – прочие контрольные переменные\n\nТритмент переменная \\(T\\) является функцией от \\(R\\), такой что \\(T = \\mathbb{I}(R&gt;c)\\), где \\(\\mathbb{I}(.)\\) индикаторная функция, принимающее значение 1, если выражение в скабках истинно, а \\(c\\) – некоторая отсечка (cutoff), после достижения которой наблюдение попадает в группу воздействия. То же самое можно записать в виде системы:\n\\[\nT(R)=\n\\begin{cases}\n1, R&gt;c\\\\\n0, R&lt;c\\\\\n\\end{cases}\n\\]\nНа рисунках ниже изображена вероятность попадания в тритмент группу. По оси абсцисс – бегущая переменная, по оси ординат – вероятность попадания в тритмент. В данном примере \\(c=6\\).\n\n\n\n\n\n\n\n\nДалее обратимся к потенциальным исходам, которые обозначены ниже пунктирными линиями. Видим, что левее от отсечки по бегущей переменной реализуется \\(Y_0\\), правее – \\(Y_1\\). Таким образом, наблюдаемый \\(Y\\) обозначен сплошной линией. Математически это как и раньше описывается формулой \\(Y = T\\cdot Y_1 + (1-T)\\cdot Y_0\\)\n\n\n\n\n\n\n\n\nВернемся к формальному описанию предпосылок.\n\nпредпосылка об экзогенности \\((Y_0, Y_1, R) \\perp T\\) не просто нарушена, назначение \\(T\\) в нашем случае вообще является правилом \\(T(R)\\)\nпредпосылка о несмешиваемости (unconfoundedness) \\((Y_0, Y_1) \\perp T | R\\) выполнена\nпредпосылка о перекрытии (overlap) \\(1&gt;P(T|R)&gt;0\\) нарушена\n\nЗаметим, что в такой ситуации мы не можем использовать другие методы, например, мэтчинг. Почему? Как раз из-за нарушения последней предпосылки, у нас просто нет для этого контрольной группы.\nВместо предпосылки об экзогенности тритмента выше предположим непрерывность функций \\(E(Y_1|R), E(Y_0|R), E(X|R)\\). Можем ли мы как-то проверить этот факт? Для потенциальных исходов, конечно, нет, мы их вовсе не наблюдаем. В непрерывность \\(Y\\) мы, увы просто верим и можем обосновывать её содержательными соображениями, а вот непрерывность \\(X\\) мы вполне можем проверить. Например, мы можем нарисовать график зависимости \\(X\\) от running variable. Таким образом, мы можем обоснованно заявлять, что разрыв в \\(Y\\) вызван изучаемым эффектом, а не каким-либо структурным сдвигом в \\(X\\).\nОтдельно, как ниже, стоит проверить распределение количества людей относительно отсечки, чтобы обезопасить себя от проблемы самоотбора, как на картинке справа:\n\n\n\n\n\nДалее перейдём к оценке. Как мы говорили ранее, самая сложная проблема, которая перед нами стоит – это то, что у нас нет контрольной группы. Сравнить среднее значение зависимой переменной слева от отсечки со средним значением справа будет являться плохой оценкой, потому что наблюдения будут несопоставимы и полученная разница может объясняться различиями к контрольных переменных, а не тем эффектом, который мы хотим оценить.\nЭконометристы придумали следующий финт – если мы возьмём наблюдения, которые расположены достаточно близко к отсечке, то они будут похожи друг на друга по величине running variable. Промежуток по running variable, который мы выбираем вокруг отсечки называется окном, размер этого промежутка – шириной окна (bandwidth). Если мы выберем маленькое окно, то получим что-то вроде локальной рандомизации, где наша оценка будет равна обычной разнице в средних.\n\\[ \\tau_{SRD} = \\underset{R \\rightarrow c+}{lim} E [Y|R] - \\underset{R \\rightarrow c-}{lim} E [Y|R]\\]\n\\[ \\hat{\\tau}_{SRD} = \\left.\\overline{Y} \\right|_{c&lt;R&lt;c+h}-\\left.\\overline{Y} \\right|_{c-h&lt;R&lt;c}\\]\n\n\n\n\n\nИтак, подведем итог, чтобы оценить эффект, нам сначала нужно выбрать шиину окна (обозначим её \\(h\\)). Затем на данных, которые лежат в пределах нашего окна \\(R \\in [c-h;c+h]\\) считаем оценку \\(\\displaystyle{LATE = E(\\tau|R=c) = \\hat{\\tau}_{SRD} = \\frac{\\sum \\limits_{c&lt;R&lt;c+h} Y_i}{\\sum (c&lt;R&lt;c+h)} - \\frac{\\sum \\limits_{c-h&lt;R&lt;c} Y_i}{\\sum (c-h&lt;R&lt;c)}}\\), как и раньше это эквивалентно регресии \\(\\displaystyle{Y = \\beta_1 + \\tau \\cdot T}\\). Добавлять контрольные переменные можно, это позволит дополнительно снизить дисперсию оценки. Иногда еще добавляют контроль на тренд \\(\\displaystyle{Y = \\beta_1 + \\tau \\cdot T + \\beta_2 \\cdot R + \\beta_3 \\cdot T \\cdot R}\\).\nВажно отметить, что чем более широкое окно мы возьмём, тем больше наблюдений мы захватим и тем более точную оценку с меньшей дисперисей мы получим (и с более узким доверительным интервалом, что хорошо!), однако если взять слишком широкое окно, то это чревато тем, что мы захватим слишком непохожие друг на друга наблюдения и наша оценка получится смещенной. Верно и обратно, чем меньше окно, тем меньше вероятность нарваться на смещение, однако дисперсия оценки (и доверительный интервал) с маленьким окном будет выше:\n\n\n\n\n\nСуществует некоторое дополнение метода, связанное с перевзвешиванием данных. Мы предположили, что наблюдения, которые находятся внутри выбранного нами окна, достаточно похожи друг на друга, чтобы мы могли их сравнивать. Однако чем ближе наблюдения к отсечке, тем больше они похожи друг на друга. Может стоит придавать им больший вес? Для этого были придуманы оценки с помощью ядер (по сути взвешенный МНК). Некоторые из них нарисованы на рисунке ниже.\n\n\n\n\n\nТогда задача МНК примет вид:\n\\[ \\hat{\\mathbb{\\beta}} = \\underset{\\beta_0, \\beta_1, \\beta_2, \\tau}{\\operatorname{argmin}} ESS = \\underset{\\beta_0, \\beta_1, \\beta_2, \\tau}{\\operatorname{argmin}} \\sum_{i=1}^n\\left[\\left(y_i-\\hat{\\beta}_0-\\hat{\\beta}_1 R_i-\\hat{\\tau} T_i-\\beta_2 T_i R_i\\right)^2\\right. \\cdot \\left.K\\left(\\frac{R_i-c}{h}\\right)\\right]\\]\nгде \\(K(.)\\) – функция плотности ядерной оценки.\nНапример, если мы хотим для всех наблюдений использовать одинаковые веса, то мы используем равномерное распределение, функция плотности которого равна:\n\\[K\\left(\\frac{R_i-c}{h}\\right)=\\left\\{\\begin{array}{l}\n\\frac{1}{2 h}, \\text{внутри окна} \\\\\n0, \\text{вне окна}\n\\end{array}\\right.\\]"
  },
  {
    "objectID": "regression_discontinuity.html#пример",
    "href": "regression_discontinuity.html#пример",
    "title": "8  Разрывная регрессия",
    "section": "8.2 Пример",
    "text": "8.2 Пример\nОдним из вопросов государственной политики является вопрос о том, каким должен быть минимальный возраст, с которого разрешается продавать алкоголь.В большинстве стран этот возраст установлен на уровне 18 лет, но в США (в большинстве штатов) в настоящее время он составляет 21 год.\nПроявляют ли США чрезмерную осторожность? Можно ли снизить допустимый возраст до 18 лет? Или это тот случай, когда другие страны должны повысить границу минимального возраста употребления алкоголя?\nОдин из способов ответить на этот вопрос – оценить ситуацию с точки зрения уровня смертности (Carpenter and Dobkin, 2009). С точки зрения государственной политики можно утверждать, что мы должны максимально снизить уровень смертности. Если потребление алкоголя значительно увеличивает смертность, нам следует избегать снижения минимального возраста употребления алкоголя.\nЧтобы оценить влияние алкоголя на смертность, мы могли бы использовать тот факт, что возраст, в котором разрешено употребление алкоголя, создает разрыв. В США люди младше 21 года не пьют (или пьют гораздо меньше), а те, кому чуть больше 21 года, пьют. Это означает, что вероятность пьянства резко возрастает в возрасте 21 года, и это то, что мы можем исследовать с помощью RDD.\nДля начала импортируем данные из статьи (Carpenter and Dobkin, 2009):\n\nlibrary(foreign)\ndata &lt;- read.dta(\"AEJfigs.dta\")\n\nИмеем следующие переменные:\n\nagecell – возраст\nколичество смертей на 100 000 людей в данной возрастной группе\n\nall – общее количество смертей\ninternal – смерти от внутренних причин (состояние здоровья и т.д.)\nexternal – смерти от внешних причин (связанные с воздействием окружающей среды, разные травмы и т.д.), в том числе:\n\nalcohol – смерти, вызванные алкоголем\nhomicide – смерти, связанные с убийствами\nsuicide – самоубийства\nmva – смерти, вызванные ДТП\ndrugs – смерти, вызванные наркотиками\nexternalother – другие внешние причины\n\n\n\n\nlibrary(stargazer)\nstargazer(data, type = \"text\")\n\n\n=====================================================\nStatistic           N   Mean  St. Dev.  Min     Max  \n-----------------------------------------------------\nagecell             50 21.000  1.127   19.068 22.932 \nall                 48 95.673  3.831   88.428 105.268\nallfitted           50 95.803  3.286   91.706 102.892\ninternal            48 20.285  2.254   15.977 24.373 \ninternalfitted      50 20.281  1.995   16.738 24.044 \nexternal            48 75.387  2.986   71.341 83.331 \nexternalfitted      50 75.522  2.270   73.158 81.784 \nalcohol             48 1.257   0.350   0.639   2.519 \nalcoholfitted       50 1.267   0.260   0.794   1.817 \nhomicide            48 16.912  0.730   14.948 18.411 \nhomicidefitted      50 16.953  0.453   16.261 17.762 \nsuicide             48 12.352  1.063   10.889 14.832 \nsuicidefitted       50 12.363  0.760   11.592 13.547 \nmva                 48 31.623  2.385   26.855 36.385 \nmvafitted           50 31.680  2.003   27.868 34.818 \ndrugs               48 4.250   0.616   3.202   5.565 \ndrugsfitted         50 4.255   0.521   3.449   5.130 \nexternalother       48 9.599   0.748   7.973  11.483 \nexternalotherfitted 50 9.610   0.465   8.388  10.353 \n-----------------------------------------------------\n\n\n\n8.2.0.1 Подготовка данных\nСначала оценим эффект вручную с помощью МНК без использования ядер, затем воспользуемся специальным пакетом.\nДля этого создадим тритмент переменную на основе отсечки и переменную квадрата возраста (наверняка вы уже встречались с примерами, когда зависимость от возраста бывает квадратичной, то есть существует какой-то минимальный или максимальный возраст в зависимости \\(Y\\) от \\(X\\)):\n\ndata$T &lt;- data$agecell&gt;=21\ndata$age2 &lt;- data$agecell^2\n\nДалее нам нужно ограничить данные окном. Предположительно выберем окно шириной в один год. Далее пакет нам посчитает оптимальную ширину окна, а пока сделаем пробный вариант. Для этого отфильтруем наши данные по окну:\n\nlibrary(dplyr)\ndata_h &lt;- data %&gt;% filter(agecell&gt;20 & agecell&lt;22)\n\n\n\n8.2.0.2 Вручную с помощью регрессии\n\n8.2.0.2.1 Оценка разрыва в общей смертности\nТеперь непосредственно регрессия:\n\nmod_ols &lt;- lm(all ~ agecell + T, data = data_h)\nsummary(mod_ols)\n\n\nCall:\nlm(formula = all ~ agecell + T, data = data_h)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2577 -1.1736  0.0033  1.2509  3.9358 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  160.094     34.860   4.592 0.000158 ***\nagecell       -3.256      1.700  -1.916 0.069094 .  \nTTRUE          9.753      1.934   5.043 5.41e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.362 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7029,    Adjusted R-squared:  0.6746 \nF-statistic: 24.84 on 2 and 21 DF,  p-value: 2.924e-06\n\n\nПолучили, что смертность людей старше 21 года на 9.8 выше, чем среди людей моложе 21.\nТот же результат, но графически:\n\nlibrary(ggplot2)\n\nggplot(data_h, aes(x = agecell, y = all, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\nПосмотрим то же самое, но теперь еще добавим квадрат возраста:\n\nmod_ols2&lt;-lm(all ~ agecell + age2 + T, data = data_h)\nsummary(mod_ols2)\n\n\nCall:\nlm(formula = all ~ agecell + age2 + T, data = data_h)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-4.2063 -1.0465 -0.1178  1.0289  4.1069 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) -242.2799   749.5323  -0.323    0.750    \nagecell       35.0933    71.3774   0.492    0.628    \nage2          -0.9131     1.6990  -0.537    0.597    \nTTRUE          9.7533     1.9676   4.957 7.59e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.403 on 20 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.7071,    Adjusted R-squared:  0.6632 \nF-statistic: 16.09 on 3 and 20 DF,  p-value: 1.473e-05\n\n\n\nggplot(data_h, aes(x = agecell, y = all, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\",\n            formula = y ~ x + I(x ^ 2)) +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\nМы поняли, что разрыв точно есть и он значим. Поробуем разобраться за счет каких причин он происходит.\n\n\n8.2.0.2.2 Разбивка на внутренние и внешние причины\n\n8.2.0.2.2.1 Внутренние\n\nmod_internal&lt;-lm(internal ~ agecell + T, data = data_h)\nsummary(mod_internal)\n\n\nCall:\nlm(formula = internal ~ agecell + T, data = data_h)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.92574 -0.62316  0.07478  0.72291  1.38703 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 19.686485  13.438734   1.465   0.1578  \nagecell     -0.009418   0.655204  -0.014   0.9887  \nTTRUE        1.692263   0.745552   2.270   0.0339 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.9107 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4938,    Adjusted R-squared:  0.4456 \nF-statistic: 10.24 on 2 and 21 DF,  p-value: 0.0007851\n\n\n\nggplot(data_h, aes(x = agecell, y = internal, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\nРазыв маленький (гораздо меньше общего) и значим только на 5% уровне.\n\n\n8.2.0.2.2.2 Внешние\n\nmod_external &lt;- lm(external ~ agecell + T, data = data_h)\nsummary(mod_external)\n\n\nCall:\nlm(formula = external ~ agecell + T, data = data_h)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-5.1759 -1.3786 -0.1486  1.7247  4.2633 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  140.408     33.698   4.167 0.000436 ***\nagecell       -3.247      1.643  -1.976 0.061409 .  \nTTRUE          8.061      1.869   4.312 0.000308 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 2.284 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5967,    Adjusted R-squared:  0.5582 \nF-statistic: 15.53 on 2 and 21 DF,  p-value: 7.236e-05\n\n\n\nggplot(data_h, aes(x = agecell, y = external, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\nВидим, что общая смертность преимущественно объясняется разрывом в смертности от внешних причин, то есть гипотеза про последствия от снижения минимального возраста продажи алкоголя пока не отвергается. Рассмотрим за счет каких причин возникает разрыв в смертности от внешних причин.\nПреимущественно это алкоголь и ДТП.\n\nАлкоголь\n\nmod_alcohol &lt;- lm(alcohol ~ agecell + T, data = data_h)\nsummary(mod_alcohol)\n\n\nCall:\nlm(formula = alcohol ~ agecell + T, data = data_h)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-0.4320 -0.1958 -0.0712  0.1912  0.8790 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)   7.7760     4.2741   1.819  0.08315 . \nagecell      -0.3268     0.2084  -1.568  0.13177   \nTTRUE         0.7405     0.2371   3.123  0.00515 **\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.2897 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4161,    Adjusted R-squared:  0.3605 \nF-statistic: 7.481 on 2 and 21 DF,  p-value: 0.003522\n\n\n\nggplot(data_h, aes(x = agecell, y = alcohol, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\n\n\nУбийства\n\nmod_homicide &lt;- lm(homicide ~ agecell + T, data = data_h)\nsummary(mod_homicide)\n\n\nCall:\nlm(formula = homicide ~ agecell + T, data = data_h)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.13706 -0.35555  0.03508  0.35236  1.08442 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)\n(Intercept)  12.4593     9.8133   1.270    0.218\nagecell       0.2211     0.4784   0.462    0.649\nTTRUE         0.1638     0.5444   0.301    0.766\n\nResidual standard error: 0.665 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.09453,   Adjusted R-squared:  0.008298 \nF-statistic: 1.096 on 2 and 21 DF,  p-value: 0.3525\n\n\n\nggplot(data_h, aes(x = agecell, y = homicide, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\n\n\nСамоубийства\n\nmod_suicide &lt;- lm(suicide ~ agecell + T, data = data_h)\nsummary(mod_suicide)\n\n\nCall:\nlm(formula = suicide ~ agecell + T, data = data_h)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.54946 -0.57179  0.09345  0.56743  1.46789 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept) 11.754110  12.491886   0.941   0.3574  \nagecell     -0.005422   0.609040  -0.009   0.9930  \nTTRUE        1.724426   0.693023   2.488   0.0213 *\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.8466 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5409,    Adjusted R-squared:  0.4972 \nF-statistic: 12.37 on 2 and 21 DF,  p-value: 0.0002819\n\n\n\nggplot(data_h, aes(x = agecell, y = suicide, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\n\n\nДТП\n\nmod_mva &lt;- lm(mva ~ agecell + T, data = data_h)\nsummary(mod_mva)\n\n\nCall:\nlm(formula = mva ~ agecell + T, data = data_h)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-2.1088 -0.8810 -0.3918  0.7157  3.1297 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 102.4206    19.7941   5.174 3.98e-05 ***\nagecell      -3.4683     0.9651  -3.594 0.001708 ** \nTTRUE         4.7593     1.0981   4.334 0.000292 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 1.341 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.4736,    Adjusted R-squared:  0.4234 \nF-statistic: 9.445 on 2 and 21 DF,  p-value: 0.001186\n\n\n\nggplot(data_h, aes(x = agecell, y = mva, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\n\n\nНаркотики\n\nmod_drugs &lt;- lm(drugs ~ agecell + T, data = data_h)\nsummary(mod_drugs)\n\n\nCall:\nlm(formula = drugs ~ agecell + T, data = data_h)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-0.62926 -0.27343  0.02269  0.29434  0.42476 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  -4.9942     4.9216  -1.015   0.3218  \nagecell       0.4355     0.2400   1.815   0.0838 .\nTTRUE         0.2065     0.2730   0.756   0.4578  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.3335 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.5446,    Adjusted R-squared:  0.5013 \nF-statistic: 12.56 on 2 and 21 DF,  p-value: 0.0002587\n\n\n\nggplot(data_h, aes(x = agecell, y = drugs, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\n\n\nПрочие внешние причины\n\nmod_externalother &lt;- lm(externalother ~ agecell + T, data = data_h)\nsummary(mod_externalother)\n\n\nCall:\nlm(formula = externalother ~ agecell + T, data = data_h)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.14575 -0.38546 -0.00161  0.35788  0.85794 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)  \n(Intercept)  13.1630     7.8140   1.685    0.107  \nagecell      -0.1856     0.3810  -0.487    0.631  \nTTRUE         0.8308     0.4335   1.917    0.069 .\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5295 on 21 degrees of freedom\n  (2 observations deleted due to missingness)\nMultiple R-squared:  0.305, Adjusted R-squared:  0.2388 \nF-statistic: 4.608 on 2 and 21 DF,  p-value: 0.02192\n\n\n\nggplot(data_h, aes(x = agecell, y = externalother, color = T)) +\ngeom_point() +\ngeom_smooth(method = \"lm\") +\nscale_color_brewer(palette = \"Dark2\") +\ngeom_vline(xintercept = 21, color = \"darkblue\", size = 1, linetype = \"dashed\") +\ngeom_vline(xintercept = 20) +\ngeom_vline(xintercept = 22) +\nlabs(y = \"Mortality rate (per 100.000)\",\n     x = \"Age\")\n\n\n\n\n\n\n\n\n\n8.2.0.3 С помощью пакета rdd\nТеперь та же оценка, но с помощью специального пакета, где можно выбрать ядра и ширину окна.\n\n8.2.0.3.1 Выбор окна\nМы можем установить любое окно вручную, используя аргумент bw, а также ядро с помощью аргумента kernel:\n\nlibrary(rdd)\n\nmod_rdd &lt;- RDestimate(all ~ agecell, data=data, cutpoint = 21, bw = 1)\nsummary(mod_rdd)\n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data, cutpoint = 21, \n    bw = 1)\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       1.0        24            9.700     1.932       5.022    5.112e-07\nHalf-BW    0.5        12            9.567     2.118       4.517    6.283e-06\nDouble-BW  2.0        48            8.381     1.345       6.232    4.603e-10\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       26.74  3         20          6.711e-07\nHalf-BW    15.27  3          8          2.257e-03\nDouble-BW  36.57  3         44          1.024e-11\n\n\n\nBandwidth – ширина окна\nObservations – количество наблюдений, которые попали в окно\nEstimate – оценка эффекта\nStd. Error стандартная ошибка\nPr(&gt;|z|) – p-value\n\nВ строке LATE указано оптимально окно, Half-BW в 2 раза меньшего оптимального, а Double-BW в 2 раза больше.\nВидим, что оценка совпала практически в точности с той, что мы получили вручную (в п. 2.2 получили эффект 9.753).\nДалее воспользуемся встренной опцией расчета оптимальной ширины окна:\n\nmod_rdd1 &lt;- RDestimate(all ~ agecell, data=data, cutpoint = 21)\nsummary(mod_rdd1)\n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data, cutpoint = 21)\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       1.6561     40            9.001     1.480       6.080    1.199e-09\nHalf-BW    0.8281     20            9.579     1.914       5.004    5.609e-07\nDouble-BW  3.3123     48            7.953     1.278       6.223    4.882e-10\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       33.08  3         36          3.799e-10\nHalf-BW    29.05  3         16          2.078e-06\nDouble-BW  32.54  3         44          6.129e-11\n\n\nОказалось, что оптимальное окно шире того, что мы использовали и равно 1.65.\n\n\n8.2.0.3.2 Выбор ядер\nПроверим на робастность с разными ядрами.\nВеса из равномерного распределения одинаковые всех наблюдений, поэтму оценка почти совпадает с МНК, в остальных случаях оценка получилась выше и примерно равна 9.\nАналогичным образом мы можем проверить разрыв по всем видам причин.\n\n8.2.0.3.2.1 Прямоугольное (равномерное)\n\nmod_kernel1 &lt;- RDestimate(all ~ agecell, data = data, cutpoint = 21, kernel = \"rectangular\")\nsummary(mod_kernel1)\n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data, cutpoint = 21, \n    kernel = \"rectangular\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       2.603      48            7.663     1.273       6.017    1.776e-09\nHalf-BW    1.302      32            9.094     1.498       6.072    1.267e-09\nDouble-BW  5.207      48            7.663     1.273       6.017    1.776e-09\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       29.47  3         44          2.651e-10\nHalf-BW    21.81  3         28          3.470e-07\nDouble-BW  29.47  3         44          2.651e-10\n\n\n\n\n8.2.0.3.2.2 Треугольное\n\nmod_kernel2 &lt;- RDestimate(all ~ agecell, data=data, cutpoint = 21, kernel = \"triangular\")\nsummary(mod_kernel2)\n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data, cutpoint = 21, \n    kernel = \"triangular\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       1.6561     40            9.001     1.480       6.080    1.199e-09\nHalf-BW    0.8281     20            9.579     1.914       5.004    5.609e-07\nDouble-BW  3.3123     48            7.953     1.278       6.223    4.882e-10\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       33.08  3         36          3.799e-10\nHalf-BW    29.05  3         16          2.078e-06\nDouble-BW  32.54  3         44          6.129e-11\n\n\n\n\n8.2.0.3.2.3 Епанечникова\n\nmod_kernel3 &lt;- RDestimate(all ~ agecell, data=data, cutpoint = 21, kernel = \"epanechnikov\")\nsummary(mod_kernel3) \n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data, cutpoint = 21, \n    kernel = \"epanechnikov\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       1.5417     38            9.079     1.480       6.135    8.502e-10\nHalf-BW    0.7708     18            9.450     1.998       4.730    2.242e-06\nDouble-BW  3.0833     48            7.779     1.271       6.121    9.298e-10\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       29.18  3         34          3.205e-09\nHalf-BW    26.01  3         14          1.104e-05\nDouble-BW  30.70  3         44          1.457e-10\n\n\n\n\n8.2.0.3.2.4 Квадратное\n\nmod_kernel4 &lt;- RDestimate(all ~ agecell, data=data, cutpoint = 21, kernel = \"quartic\")\nsummary(mod_kernel4) \n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data, cutpoint = 21, \n    kernel = \"quartic\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       1.7603     42            9.046     1.469       6.157    7.415e-10\nHalf-BW    0.8801     22            9.445     1.950       4.845    1.269e-06\nDouble-BW  3.5205     48            7.842     1.271       6.168    6.904e-10\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       34.26  3         38          1.350e-10\nHalf-BW    32.25  3         18          3.759e-07\nDouble-BW  31.29  3         44          1.100e-10\n\n\n\n\n8.2.0.3.2.5 Гауссиан\n\nmod_kernel5 &lt;- RDestimate(all ~ agecell, data=data, cutpoint = 21, kernel = \"gaussian\")\nsummary(mod_kernel5) \n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data, cutpoint = 21, \n    kernel = \"gaussian\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|) \nLATE       0.6064     48            9.068     1.490       6.084    1.172e-09\nHalf-BW    0.3032     48            9.431     1.838       5.132    2.869e-07\nDouble-BW  1.2128     48            8.027     1.279       6.279    3.418e-10\n              \nLATE       ***\nHalf-BW    ***\nDouble-BW  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F      Num. DoF  Denom. DoF  p        \nLATE       44.94  3         44          3.770e-13\nHalf-BW    73.65  3         44          0.000e+00\nDouble-BW  33.02  3         44          4.915e-11\n\n\n\n\n\n\n8.2.0.4 Bias-variance tradeoff\n\nest&lt;-c()\nfor (i in 1:3){\n  reg_rdd &lt;- RDestimate(all ~ agecell, data = data, cutpoint = 21, bw=i, kernel = \"triangular\")\n  est[i]&lt;-reg_rdd$est[1]\n}\n\n\nse&lt;-c()\nfor (i in 1:3){\n  reg_rdd &lt;- RDestimate(all ~ agecell, data = data, cutpoint = 21, bw=i, kernel = \"triangular\")\n  se[i]&lt;-reg_rdd$se[1]\n}\n\n\nCIlow &lt;- est - 1.96*se\nCIup &lt;- est + 1.96*se\n\n\nlibrary(Hmisc)\nerrbar(x = c(1:3), y = est, yplus = CIup, yminus = CIlow, type = 'b')\n\n\n\n\n\n\n8.2.0.5 Плацебо тест\nОтсечка 20\n\ndata_new &lt;- data[data$agecell &lt; 21,]\nmod_rdd_20 &lt;- RDestimate(all ~ agecell, data = data_new, cutpoint = 20, kernel = \"triangular\")\nsummary(mod_rdd_20)\n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data_new, cutpoint = 20, \n    kernel = \"triangular\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|)   \nLATE       0.5553     14             0.7998   3.209        0.2493  0.8032     \nHalf-BW    0.2777      7            -3.4455   2.663       -1.2940  0.1956     \nDouble-BW  1.1107     24             0.7401   2.088        0.3544  0.7230     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F       Num. DoF  Denom. DoF  p     \nLATE       0.5695  3         10          0.7047\nHalf-BW    0.5823  3          3          0.6678\nDouble-BW  1.4173  3         20          0.5342\n\n\nОтсечка 20.5\n\ndata_new &lt;- data[data$agecell &lt; 21,]\nmod_rdd_20.5 &lt;- RDestimate(all ~ agecell, data = data_new, cutpoint = 20.5, kernel = \"triangular\")\nsummary(mod_rdd_20.5)\n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data_new, cutpoint = 20.5, \n    kernel = \"triangular\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|)   \nLATE       0.4051     10            2.3938    1.7961      1.3328   0.1826     \nHalf-BW    0.2025      5            0.9779    0.7401      1.3212   0.1864     \nDouble-BW  0.8101     16            0.4816    1.3249      0.3635   0.7162     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F       Num. DoF  Denom. DoF  p     \nLATE       1.4778  3          6          0.6246\nHalf-BW    1.6303  3          1          0.9813\nDouble-BW  0.9465  3         12          0.8978\n\n\nОтсечка 22\n\ndata_new2 &lt;- data[data$agecell &gt; 21,]\nmod_rdd_22 &lt;- RDestimate(all ~ agecell, data = data_new2, cutpoint = 22, kernel = \"triangular\")\nsummary(mod_rdd_22)\n\n\nCall:\nRDestimate(formula = all ~ agecell, data = data_new2, cutpoint = 22, \n    kernel = \"triangular\")\n\nType:\nsharp \n\nEstimates:\n           Bandwidth  Observations  Estimate  Std. Error  z value  Pr(&gt;|z|)   \nLATE       0.8808     22            -0.2917   2.125       -0.1373  0.8908     \nHalf-BW    0.4404     11            -0.6552   3.344       -0.1959  0.8447     \nDouble-BW  1.7616     24             0.2413   1.894        0.1274  0.8986     \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nF-statistics:\n           F       Num. DoF  Denom. DoF  p      \nLATE       1.1277  3         18          0.72852\nHalf-BW    0.2613  3          7          0.29760\nDouble-BW  3.4606  3         20          0.07151"
  },
  {
    "objectID": "regression_discontinuity.html#размытая-разрывная-регрессия",
    "href": "regression_discontinuity.html#размытая-разрывная-регрессия",
    "title": "8  Разрывная регрессия",
    "section": "8.3 Размытая разрывная регрессия",
    "text": "8.3 Размытая разрывная регрессия\nКак известно, строгость правил смягчается необязательностью их исполнения, именно под этим слоганом работает метод размытой разрывной регрессии. В прошлом пукте мы предполагали, что все, у кого running variable больше cutoff, попадают в группу воздействия. Однако это не всегда бывает так. Бывает, что несмотря на предписание оказаться в группе воздействия, человек отказывается в этой опции или несмотря на то, что человеку предписано быть в контрольной группе, он находит возможность оказаться в группе воздействия. То есть мы снова столкнулись с ситуацией эндогенного тритмента.\nКак устроен мир: \\(Z-&gt;T-&gt;Y\\)\n\nReduced form (Intention to treat): \\(Z \\rightarrow Y\\) -First stage: \\(Z \\rightarrow T\\)\nSecond stage: \\(T-&gt;Y\\)\n\nОбозначения:\n\n\\(Y(00), Y(10), Y(01), Y(11)-\\) Зависимая переменная (potential outcomes)\n\\(T(1), T(0)\\) - Переменная интереса (теперь тоже с потенциальными исходами)\nZ - Инструментальная переменная (instrumental variable)\n\\(X\\) - Независимые переменные (Covariates)\nМы наблюдаем только \\((Y, Z, T, X)\\), где \\(T=Z T(1)+(1-Z) T(0)\\) - observed treatment \\(Y=\\) длинная формула - observed outcomes\n\nПредпосылки:\n\n\\(\\left(Y_{i j}, T_i, X\\right) \\perp Z\\) – рандомизация\n\\(Y(T, Z=1)=Y(T, Z=0)\\) – exclusion restriction: напрямую \\(\\mathrm{T}\\) влияет на \\(\\mathrm{Y}\\), а не \\(Z\\) напрямую не влияет на \\(Y\\)\nSUTVA\n\\(T|Z=1&gt;=T| Z=0\\) – монотонность\n\nМы хотим, чтобы никогда не было \\(T_1&lt;T_0\\), но бывало такое, что \\(T_1&gt;T_0\\)\nБывает одностороннее неповиновение тритменту (one-sided noncompliance)\nБывает двустороннее неповиновение тритменту (two-sided noncompliance)\n\n\nКогда выполнены все эти предпосылки, мы говорим, что эффект идентифицирован.\nЕсли вы вспомните изученный ранее курс эконометрики, то с подобным вы уже встречались в теме LATE.\nПусть \\(Z\\) обозначает предписание исследователей о том, в какой группе длжно оказаться наблюдение, а \\(T\\) – в какой группе оно реально оказалось.\nПодробнее про предпосылки:\n\n\\(P\\left(T_1 \\geq T_0\\right)=1-\\) монотонность. На самом деле возможных случает в только 4\nAlways takers: \\(T_1=1, T_0=1\\)\nCompliers: \\(T_1=1, T_0=0\\)\nNever takers: \\(T_1=0, T_0=0\\) Defiers: \\(T_1=0, T_0=1\\)\nTwo-sided noncompliance: no Defiers\nOne-sided noncompliance: no Defiers and no Always takers\n\n\n\n\n\n\nФормула:\n\\(\\mathrm{ITT}_T=\\bar{T}_{Z=1}-\\bar{T}_{Z=0}=P \\text { (compliers) }\\) (оценка первого шага), физический смысл – доля комплаеров в выборке\n\\(\\mathrm{ITT}_Y=\\bar{Y}_{Z=1}-\\bar{Y}_{Z=0}\\) (оценка второго шага), физический смысл – “оценка эффекта от намерения”, Intention to treat\n\\(\\mathrm{TE}=\\frac{\\mathrm{ITT}_Y}{\\mathrm{ITT}_T}=E(\\tau \\mid \\text { Compliers })=\\text { LATE }\\) – тритмент эффект для комплаеров, численно совпадает с оценкой с помощью метода инструментальных переменных\n\\(\\tau_{FRD} = \\frac{\\underset{R \\rightarrow c+}{lim} E [Y|R] - \\underset{R \\rightarrow c-}{lim} E [Y|R]}{\\underset{R \\rightarrow c+}{lim} E [T|R] - \\underset{R \\rightarrow c-}{lim} E [T|R]}\\)\n\nЧто у нас инстументальная переменная? \\(Z=\\{R&gt;c\\}\\)\nЧто у нас переменная интереса? \\(T\\)\nГлавное предположение разрывной регрессии – предположим непрерывность всего: \\(E\\left(Y_{00} \\mid R\\right), E\\left(Y_{01} \\mid R\\right), E\\left(Y_{10} \\mid R\\right), E\\left(Y_{11} \\mid R\\right)\\), \\(E\\left(T_0 \\mid R\\right), E\\left(T_1 \\mid R\\right), E(X \\mid R)\\)"
  },
  {
    "objectID": "spatial_regression_discontinuity.html#введение",
    "href": "spatial_regression_discontinuity.html#введение",
    "title": "9  Пространственная разрывная регрессия",
    "section": "9.1 Введение",
    "text": "9.1 Введение\nЗнакомиться с методом пространственной разрывной регрессии мы будем на примере статьи Алекса Ленера, который изучал эффекты от колонизации одного из штатов Индии португальцами.\nАнализируя индийский штат Гоа, статья использует исторический квазиестественный эксперимент, чтобы продемонстрировать стойкое влияние португальского (католического) колониализма в контексте Южной Азии. Ленер изучает три ключевых социально-экономических фактора:\n\nженскую грамотность,\nмужскую грамотность,\nсоотношение полов.\n\nОн установил, что:\n\nРазрывы в грамотности мужчин сходятся примерно в пределах одного поколения.\nРазрывы в женской грамотности также сходятся, но гораздо медленнее.\nПредпочтения сыновей дочерям оказались гораздо более серьезным – разрывы в соотношении полов вообще не изменились за последние десятилетия.\n\nВсё, что написано курсивом ниже не обязательно к прочтению, но делает контекст исследования более понятным.\nСтав первой европейской державой, обогнувшей южную оконечность Африки в 1497 году, португальцы основали столицу своей последующей морской империи в Индийском океане, так называемую Estado da ndia, в Гоа в 1510 году. Это происходило в течение 450 лет и, таким образом, делает этот штат самым длинным постоянно колонизируемым участком земли в молодой истории человечества.\nПервоначально удерживая только портовый город и его окрестности, около 1540 г. они решили занять большие участки земли в направлении север-юг, чтобы создать буферную зону. Эти области составляют Старые завоевания, и именно здесь развернулась уникальная португальская стратегия колонизации. В отличие от других узурпаторов в Индийском океане, таких как голландцы или британцы с их торговыми компаниями, португальцы взаимодействовали с коренными народами.\nСмешанные браки их солдат с местными женщинами поощрялись, чтобы создать лояльное местное население и расширить культурное влияние. Кроме того, были предприняты усилия по обращению населения в католицизм. Их всегда сопровождали монахи и священники, принадлежавшие к определенным религиозным орденам: францисканцы, доминиканцы и, самое главное, иезуиты. Они построили церкви, колледжи, организовали сеть церковно-приходских школ, ввели структурированное образование и даже завезли печатный станок.\nЧто еще более важно, лузитанцы значительно изменили положение женщин в обществе сразу после их появления в начале 16 века: сати (или сатти), полигамия и ранние детские браки были запрещены.\nКроме того, женщинам были предоставлены права собственности, и поэтому с этого момента они могли наследовать. Это было обусловлено вступлением в брак с христианином и, таким образом, служило дополнительным стимулом для обращения в другую веру. Дальнейший разрыв с местными культурными нормами был отмечен тем, что вдовам было разрешено вступать в повторный брак.\nСо временем в результате появилось заметное неравенство между двумя областями, в том числе и в том, что касается инфраструктуры. В то время, когда Индия изгнала португальских колонизаторов в 1961 году, только в нескольких процентах деревень было электричество, а во многих не было государственных школ. Однако правительство Индии вмешалось с крупномасштабными инфраструктурными инвестициями и сумело уравнять предоставление общественных благ по всему Гоа с поразительной скоростью."
  },
  {
    "objectID": "spatial_regression_discontinuity.html#работа-с-картами-и-генерация-данных",
    "href": "spatial_regression_discontinuity.html#работа-с-картами-и-генерация-данных",
    "title": "9  Пространственная разрывная регрессия",
    "section": "9.2 Работа с картами и генерация данных",
    "text": "9.2 Работа с картами и генерация данных\nДалее мы будем использовать географические границы штата Гоа из Lehner (2019). Данные, включенные в авторский пакет, содержат:\n\nстрока cut_off.sf, которая описывает пространственный разрыв (границу колонии)\nполигон (многоугольник), определяющий область тритмента\nполигон (многоугольник), определяющий всю изучаемую область\n\nПодключаем библиотеки:\n\nlibrary(sf)\n# library(devtools)\n# devtools::install_github(\"axlehner/SpatialRDD\")\nlibrary(SpatialRDD)\nlibrary(dplyr) \nlibrary(stargazer) \n\nПочти все пространственные объекты относятся к классу sf из пакета sf. Это означает, что они представляют собой data.frame со специальным столбцом, содержащим геометрию (координаты) для каждой строки.\nБольшим преимуществом является то, что независимо от того, предпочитаете ли вы base R, dplyr или любой другой способ обработки данных, объект sf можно обрабатывать так же, как стандартный data.frame.\n\ndata(cut_off.sf, polygon_full.sf, polygon_treated.sf)\n\nНарисуем границы:\n\nlibrary(tmap)\ntm_shape(polygon_full.sf) + tm_polygons() + \n  tm_shape(polygon_treated.sf) + tm_polygons(col = \"grey\") + \n  tm_shape(cut_off.sf) + tm_lines(col = \"red\")\n\n\n\n\nВыше мы видим простую карту, где полигон тритмента закрашен более темным цветом, а cutoff обозначена красным цветом.\nДавайте смоделируем несколько случайных точек внутри полигона, описывающего всю изучаемую область:\n\nset.seed(1088) \npoints_samp.sf &lt;- sf::st_sample(polygon_full.sf, 1000)\npoints_samp.sf &lt;- sf::st_sf(points_samp.sf) # делаем его объектом sf, потому что st_sample создал только столбец координат (sfc)\npoints_samp.sf$id &lt;- 1:nrow(points_samp.sf) # добавим уникальный ID каждому наблюдению\n\nИ снова всё нарисуем:\n\ntm_shape(points_samp.sf) + tm_dots() + \n  tm_shape(cut_off.sf) + tm_lines(col = \"red\")"
  },
  {
    "objectID": "spatial_regression_discontinuity.html#генерация-тритмента",
    "href": "spatial_regression_discontinuity.html#генерация-тритмента",
    "title": "9  Пространственная разрывная регрессия",
    "section": "9.3 Генерация тритмента",
    "text": "9.3 Генерация тритмента\nТеперь воспользуемся первой функцией пакета SpatialRDD – assign_treated().\nОна выполняет пространственное разграничение и возвращает вектор-столбец, который содержит 0 или 1, в зависимости от того, находится ли наблюдение внутри или снаружи области обработки.\nТаким образом, мы просто добавляем его как новый столбец к объекту точек. Для функции требуется имя объекта точек, имя полигона, определяющего обрабатываемую область, и идентификатор, который однозначно идентифицирует каждое наблюдение в объекте точек:\n\npoints_samp.sf$treated &lt;- assign_treated(points_samp.sf, polygon_treated.sf, id = \"id\")\n\nСнова рисуем:\n\ntm_shape(points_samp.sf) + tm_dots(\"treated\", palette = \"Set1\") + \n  tm_shape(cut_off.sf) + tm_lines(col = \"red\")\n\n\n\n\nДля того, чтобы что-то посчитать, нам нужна зависимая переменная. Назовем эту переменную образованием, готорая будет измерять уровень грамотности, который колеблется от 0 до 1 (от 0%, что означает, что все неграмотны, до 100%, что означает, что все в популяции умеют читать и писать).\nМы предполагаем, что юниты, называемые деревнями, в тритмент полигоне в среднем имеют более высокий уровень грамотности, потому что они подверглись колонизации.\n\n# first we define a variable for the number of \"treated\" and control which makes the code more readable in the future\n# сначала сохраним отдельно количество тритмент и контрольных деревень, чтобы дальше было удобнее писать код\nNTr &lt;- length(points_samp.sf$id[points_samp.sf$treated == 1])\nNCo &lt;- length(points_samp.sf$id[points_samp.sf$treated == 0])\n\nСоздаём зависимую переменную:\n\n# тритмент деревни получают на 10 процентных пунктов более высокий уровень грамотности\npoints_samp.sf$education[points_samp.sf$treated == 1] &lt;- 0.7\npoints_samp.sf$education[points_samp.sf$treated == 0] &lt;- 0.6\n\n# добавляем немного шума, иначе мы бы получили коэффициенты регрессии без стандартных ошибок\npoints_samp.sf$education[points_samp.sf$treated == 1] &lt;- rnorm(NTr, mean = 0, sd = .1) +\n  points_samp.sf$education[points_samp.sf$treated == 1]\npoints_samp.sf$education[points_samp.sf$treated == 0] &lt;- rnorm(NCo, mean = 0, sd = .1) +\n  points_samp.sf$education[points_samp.sf$treated == 0]\n\nТакже создадим плацебо результат без скачка в разрыве:\n\npoints_samp.sf$placebo &lt;- rnorm(nrow(points_samp.sf), mean = 1, sd = .25)\n\nПосмотрим распределение зависимой переменной:\n\nlibrary(ggplot2)\nggplot(points_samp.sf, aes(x = education)) + geom_histogram(binwidth = .01) + facet_grid(treated ~ .)\n\n\n\n\nИз приведенных выше гистограмм видно, что нам удалось создать различные средние группы. Это также подтверждается простой одномерной регрессией \\(y_i=\\alpha+\\beta \\mathbb{1}(\\text { treated })_i+\\varepsilon_i\\) :\n\nlist(lm(education ~ treated, data = points_samp.sf),\n     lm(placebo   ~ treated, data = points_samp.sf)) %&gt;% stargazer::stargazer(type = \"text\")\n\n\n===========================================================\n                                   Dependent variable:     \n                               ----------------------------\n                                  education      placebo   \n                                     (1)           (2)     \n-----------------------------------------------------------\ntreated1                          0.105***        0.035*   \n                                   (0.008)       (0.020)   \n                                                           \nConstant                          0.601***       0.994***  \n                                   (0.004)       (0.009)   \n                                                           \n-----------------------------------------------------------\nObservations                        1,000         1,000    \nR2                                  0.157         0.003    \nAdjusted R2                         0.156         0.002    \nResidual Std. Error (df = 998)      0.100         0.260    \nF Statistic (df = 1; 998)        185.992***       3.072*   \n===========================================================\nNote:                           *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nСреднее значение в контрольных деревнях составляет 0,6, а в тритмент деревнях образование в среднем на 0,1 больше (10 процентных пунктов)."
  },
  {
    "objectID": "spatial_regression_discontinuity.html#расстояние-до-отсечки",
    "href": "spatial_regression_discontinuity.html#расстояние-до-отсечки",
    "title": "9  Пространственная разрывная регрессия",
    "section": "9.4 Расстояние до отсечки",
    "text": "9.4 Расстояние до отсечки\nСледующим важным шагом, прежде чем мы начнем проводить надлежащий пространственный RDD-анализ, является определение того, насколько далеко каждая из этих точек находится от границы отсечки.\nЗдесь мы просто используем функцию st_distance() из sf, которая возвращает вектор с единицами измерения (которые мы должны преобразовать в действительные числа с помощью as.numeric()):\n\npoints_samp.sf$dist2cutoff &lt;- as.numeric(sf::st_distance(points_samp.sf, cut_off.sf))\n\nЭто позволяет нам теперь исследовать деревни только в пределах определенного диапазона, скажем, 3 километра вокруг нашей границы:\n\ntm_shape(points_samp.sf[points_samp.sf$dist2cutoff &lt; 3000, ]) + tm_dots(\"education\", palette = \"RdYlGn\", size = .1) + \n  tm_shape(cut_off.sf) + tm_lines()\n\n\n\n\nДалее мы можем оценить регрессию только в пределах полосы в 3 км (эта постановка уже начинает напоминать идею классического RDD):\n\nlm(education ~ treated, data = points_samp.sf[points_samp.sf$dist2cutoff &lt; 3000, ]) %&gt;% stargazer::stargazer(type = \"text\")\n\n\n===============================================\n                        Dependent variable:    \n                    ---------------------------\n                             education         \n-----------------------------------------------\ntreated1                     0.090***          \n                              (0.015)          \n                                               \nConstant                     0.612***          \n                              (0.011)          \n                                               \n-----------------------------------------------\nObservations                    159            \nR2                             0.186           \nAdjusted R2                    0.181           \nResidual Std. Error      0.095 (df = 157)      \nF Statistic           35.810*** (df = 1; 157)  \n===============================================\nNote:               *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "spatial_regression_discontinuity.html#проведение-пространственной-оценки-rdd",
    "href": "spatial_regression_discontinuity.html#проведение-пространственной-оценки-rdd",
    "title": "9  Пространственная разрывная регрессия",
    "section": "9.5 Проведение пространственной оценки RDD",
    "text": "9.5 Проведение пространственной оценки RDD\nТеперь мы шаг за шагом рассмотрим все потенциальные (параметрические и непараметрические) способы, с помощью которых можно получить точечные оценки для пространственных RDD.\n\n9.5.1 Наивное расстояние\nДля «наивной» оценки (KeeleTitiunik2015), означающей, что пространственное измерение практически не учитывается, мы сначала определяем переменную distrunning, которая делает расстояния в обработанных областях отрицательными, так что наше двумерное отсечение становится равным 0.\n\npoints_samp.sf$distrunning &lt;- points_samp.sf$dist2cutoff\n# сделаем running variable отрицательной для наблюдений слева от cutoff, но на карте это соответсвтует области справа (контрольные деревни)\npoints_samp.sf$distrunning[points_samp.sf$treated == 0] &lt;- -1 * points_samp.sf$distrunning[points_samp.sf$treated == 0]\n\nggplot(data = points_samp.sf, aes(x = distrunning, y = education)) + \n  geom_point() + \n  geom_vline(xintercept = 0, col = \"red\")\n\n\n\n\nТогда точечная оценка “классической” непараметрической локальной линейной регрессии, выполненной с помощью пакета rdrobust, выглядит так:\n\nlibrary(rdrobust)\nsummary(rdrobust(points_samp.sf$education, points_samp.sf$distrunning, c = 0))\n\nSharp RD estimates using local polynomial regression.\n\nNumber of Obs.                 1000\nBW type                       mserd\nKernel                   Triangular\nVCE method                       NN\n\nNumber of Obs.                  785          215\nEff. Number of Obs.             127          100\nOrder est. (p)                    1            1\nOrder bias  (q)                   2            2\nBW est. (h)                4248.546     4248.546\nBW bias (b)                6601.220     6601.220\nrho (h/b)                     0.644        0.644\nUnique Obs.                     785          215\n\n=============================================================================\n        Method     Coef. Std. Err.         z     P&gt;|z|      [ 95% C.I. ]       \n=============================================================================\n  Conventional     0.116     0.025     4.580     0.000     [0.066 , 0.166]     \n        Robust         -         -     4.089     0.000     [0.064 , 0.181]     \n=============================================================================\n\n\n\nПо выборке:\n\nNumber of Obs. количество наблюдений\nBW type определяет используемую процедуру выбора ширины окна.\nKernel это функция ядра, используемая для построения локально-полиномиальных оценок.\nVCE method тип процедуры, используемой для вычисления оценки матрицы дисперсии-ковариации (робастные ошибки).\n\nПо группам (тритмент и контроль):\n\nNumber of Obs.\nEff. Number of Obs.\nOrder est. (p) указывает порядок локального многочлена, используемого для построения точечной оценки; по умолчанию p = 1 (локальная линейная регрессия).\nOrder bias  (q) задает порядок локального полинома, используемого для построения коррекции смещения; по умолчанию q = 2 (локальная квадратичная регрессия).\nBW est. (h) задает окно, используемое для создания средства оценки точек RD. Если не указано иного, то h вычисляется сопутствующей командой rdbwselect.\nBW bias (b) задает ширину окна, используемую для создания средства оценки коррекции смещения. Если не указано иное, то b вычисляется сопутствующей командой rdbwselect.\nrho (h/b) по умолчанию rho = 1, если h указано, а b нет.\nUnique Obs. количество уникальных наблюдений.\n\nОценка:\n\nConventional обычные оценки RD с обычными стандартными ошибками.\nRobust оценки с поправкой на погрешность с робастными стандартными ошибками\n\n\nПосмотрим картинку эффектов в зависимости от ширины окна:\n\nrdplot(points_samp.sf$education, points_samp.sf$distrunning, c = 0, ci = 95, \n       kernel = \"triangular\", y.label = \"education\", x.label = \"distance to border\")\n\n\n\n\nДля оценки RDD в R в настоящее время существует три пакета: RDD, rddtools и rddapp (основанный на RDD); при этом последний является наиболее современным, он оценивает различные спецификации:\n\nlibrary(rddapp)\n\n\nsummary(rd_est(education ~ distrunning, data = points_samp.sf, t.design = \"g\"))\n\n\nCall:\nrd_est(formula = education ~ distrunning, data = points_samp.sf, \n    t.design = \"g\")\n\nITT used:\nFALSE\n\nType:\nsharp \n\nEstimates:\n            Bandwidth  Observations  Estimate  Std. Error  lower.CL  upper.CL\nLinear         NA      1000          0.08474   0.01321     0.05884   0.1106  \nQuadratic      NA      1000          0.09778   0.01888     0.06078   0.1348  \nCubic          NA      1000          0.11587   0.02409     0.06864   0.1631  \nOpt         15055       652          0.09259   0.01540     0.06240   0.1228  \nHalf-Opt     7527       415          0.10276   0.01957     0.06440   0.1411  \nDouble-Opt  30110       975          0.08809   0.01351     0.06161   0.1146  \n            z value  Pr(&gt;|z|)      \nLinear      6.413    1.425e-10  ***\nQuadratic   5.179    2.226e-07  ***\nCubic       4.809    1.517e-06  ***\nOpt         6.011    1.848e-09  ***\nHalf-Opt    5.250    1.519e-07  ***\nDouble-Opt  6.519    7.082e-11  ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nConfidence interval used:  0.95 \n\n\nНарисуем несколько разных спецификаций на одном графике. Здесь мы произвольно выбираем одну параметрическую и одну непараметрическую оценку, включая доверительные интервалы и выбранные вручную размеры окон:\n\nplot(rd_est(education ~ distrunning, data = points_samp.sf, t.design = \"g\"), fit_line = c(\"quadratic\", \"optimal\"))\n\n\n\n\n\n\n9.5.2 Параметрические характеристики\nЭтот метод, популяризированный Dell2010 в его job market paper, исследует только наблюдения в пределах определенного расстояния вокруг границы с использованием (полу-)параметрического подхода.\nПо существу, он отличается от предыдущих оценок только введением сегментов границы. Они используются для “within” оценки, позволяющей использовать различные точки пересечения для каждой из этих категорий сегментов, чтобы, среди прочего, облегчить проблему пропущенных переменных.\nВ качестве альтернативы этому подходу с фиксированными эффектами мы могли бы использовать набор фиктивных моделей для каждого сегмента регрессии. А затем просто бы усреднили по ним переменную интереса.\nКроме того, нас также может заинтересовать коэффициент каждого сегмента, чтобы сделать вывод о потенциальной неоднородности наряду с разрывом нашей регрессии.\nВычислительно требовательная функция border_segment() нуждается только в слое точек и координатах границы в качестве входных данных. Последний параметр функции позволяет нам определить, сколько сегментов мы хотим. Как и в случае с функцией assign_treated(), результатом является вектор факторов.\n\npoints_samp.sf$segment10 &lt;- border_segment(points_samp.sf, cut_off.sf, 10)\n\nStarting to create 10 border segments with an approximate length of 13 kilometres each.\n\npoints_samp.sf$segment15 &lt;- border_segment(points_samp.sf, cut_off.sf, 15)\n\nStarting to create 15 border segments with an approximate length of 9 kilometres each.\n\npoints_samp.sf$segment15 &lt;- border_segment(points_samp.sf, cut_off.sf, 5)\n\nStarting to create 5 border segments with an approximate length of 26 kilometres each.\n\n\n\ntm_shape(points_samp.sf) + tm_dots(\"segment10\", size = 0.1) +\n  tm_shape(cut_off.sf) + tm_lines()\n\n\n\ntm_shape(points_samp.sf) + tm_dots(\"segment15\", size = 0.1) +\n  tm_shape(cut_off.sf) + tm_lines()\n\n\n\n\nВажно всегда отображать сегменты (категории фиксированных эффектов) на карте. border_segment() уже дает исследователю представление о том, насколько осмысленным был выбор количества сегментов.\nВ приведенном выше примере у нас есть сегмент на каждые 13 километров, что кажется не слишком разумным. Однако мы могли видеть, что некоторые из сегментов содержат очень мало наблюдений, что нежелательно.\nТаким образом, в следующем примере мы выбираем меньше сегментов, что приводит к большему количеству наблюдений с каждой стороны границы для каждого сегмента и, следовательно, к более значимым точечным оценкам:\n\npoints_samp.sf$segment5 &lt;- border_segment(points_samp.sf, cut_off.sf, 5)\n\nStarting to create 5 border segments with an approximate length of 26 kilometres each.\n\n\n\ntm_shape(points_samp.sf) + tm_dots(\"segment5\", size = 0.1) + tm_shape(cut_off.sf) + tm_lines()\n\n\n\n\nПростые оценки МНК с использованием сегментов, которые мы только что получили в качестве фиксированных эффектов, показывают следующие различия:\n\nlibrary(lfe)\n\n\nlist(lfe::felm(education ~ treated | factor(segment15) | 0 | 0, data = points_samp.sf[points_samp.sf$dist2cutoff &lt; 3000, ]),\nlfe::felm(education ~ treated | factor(segment5) | 0 | 0, data = points_samp.sf[points_samp.sf$dist2cutoff &lt; 3000, ])\n) %&gt;% stargazer::stargazer(type = \"text\")\n\n\n===========================================================\n                                   Dependent variable:     \n                               ----------------------------\n                                        education          \n                                    (1)            (2)     \n-----------------------------------------------------------\ntreated1                          0.089***      0.089***   \n                                  (0.015)        (0.015)   \n                                                           \n-----------------------------------------------------------\nObservations                        159            159     \nR2                                 0.248          0.248    \nAdjusted R2                        0.224          0.224    \nResidual Std. Error (df = 153)     0.092          0.092    \n===========================================================\nNote:                           *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01\n\n\nДоверительные интервалы обеих точечных оценок перекрываются, однако видно, что выбор фиксированных эффектов может оказать существенное влияние.\nМы получаем точечную оценку, которая (что неудивительно, поскольку у нас есть процесс генерации данных, который однороден в пространстве) очень похожа на ту, которую мы получили из простой регрессии МНК с самого начала.\nПо сравнению с точечной оценкой «классического RD», которую мы получили из непараметрической локальной линейной регрессии из пакета rdrobust, точечная оценка из нашей регрессии с фиксированными эффектами немного более консервативна. Но на глаз мы можем определить, что средний эффект находится где-то около 0,1, а это означает, что уровень грамотности на 10 процентных пунктов выше в тритмент деревнях. Что соотвествует тому, что мы замоделировали в данных.\n\n\n9.5.3 Geographic Regression Discontinuity (GRD)\nНаконец, мы переходим к полноценному дизайну разрыва географической регрессии (GRD) (KeeleTitiunik2015). Функция spacerd() включает оценку RD с двумя running variable, а также позволяет выполнять оценку для каждой граничной точки (boundarypoint) («GRDDseries»).\nЭто позволяет нам визуализировать эффект лечения в нескольких точках отсечки и, таким образом, сделать вывод о потенциальной неоднородности эффекта. И, самое главное, оценить надежность самого GRD.\nПрежде всего, мы должны разрезать границу на равные сегменты. Для каждого из этих отрезков, а точнее граничных точек, мы в дальнейшем получим точечную оценку. Для функции discretise_border() просто требуется объект sf, который содержит границу и количество желаемых граничных точек:\n\nborderpoints.sf &lt;- discretise_border(cutoff = cut_off.sf, n = 50)\n\nStarting to create 50 borderpoints from the given set of borderpoints. Approximately every 3 kilometres we can run an estimation then.\n\nborderpoints.sf$id &lt;- 1:nrow(borderpoints.sf)\n\n\ntm_shape(points_samp.sf[points_samp.sf$dist2cutoff &lt; 3000, ]) + tm_dots(\"education\", palette = \"RdYlGn\", size = .1) +\n  tm_shape(cut_off.sf) + tm_lines() +\n  tm_shape(borderpoints.sf) + tm_symbols(shape = 4, size = .3)\n\n\n\n\nДля построения только таблицы результатов было бы предпочтительнее выбрать в качестве вывода только data.frame (spatial.object = F).\n\nresults &lt;- spatialrd(y = \"education\", data = points_samp.sf, cutoff.points = borderpoints.sf, treated = \"treated\", minobs = 10, spatial.object = F)\nknitr::kable(results)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPoint\nEstimate\nSE_Conv\nSE_Rob\np_Conv\np_Rob\nNtr\nNco\nbw_l\nbw_r\nCI_Conv_l\nCI_Conv_u\nCI_Rob_l\nCI_Rob_u\n\n\n\n\n1\n0.12\n0.05\n0.06\n0.02\n0.05\n53\n55\n14.2\n14.2\n0.02\n0.21\n0.00\n0.24\n\n\n2\n0.14\n0.07\n0.08\n0.04\n0.07\n71\n57\n15.2\n15.2\n0.00\n0.27\n-0.01\n0.30\n\n\n3\n0.11\n0.05\n0.06\n0.02\n0.06\n103\n84\n19.9\n19.9\n0.02\n0.21\n0.00\n0.24\n\n\n4\n0.08\n0.05\n0.06\n0.11\n0.22\n100\n65\n16.0\n16.0\n-0.02\n0.17\n-0.05\n0.20\n\n\n5\n0.08\n0.05\n0.06\n0.11\n0.22\n104\n73\n17.3\n17.3\n-0.02\n0.17\n-0.04\n0.19\n\n\n6\n0.07\n0.04\n0.05\n0.09\n0.22\n112\n84\n20.9\n20.9\n-0.01\n0.15\n-0.04\n0.16\n\n\n7\n0.06\n0.03\n0.04\n0.08\n0.20\n108\n62\n18.9\n18.9\n-0.01\n0.13\n-0.03\n0.13\n\n\n8\n0.07\n0.04\n0.05\n0.10\n0.18\n93\n46\n17.1\n17.1\n-0.01\n0.15\n-0.03\n0.16\n\n\n9\n0.11\n0.07\n0.08\n0.09\n0.11\n77\n33\n14.1\n14.1\n-0.02\n0.24\n-0.03\n0.27\n\n\n10\n0.13\n0.07\n0.08\n0.04\n0.05\n69\n32\n12.3\n12.3\n0.01\n0.26\n0.00\n0.30\n\n\n11\n0.18\n0.07\n0.08\n0.01\n0.02\n56\n32\n11.1\n11.1\n0.04\n0.32\n0.03\n0.35\n\n\n12\n0.25\n0.12\n0.13\n0.03\n0.03\n40\n22\n9.6\n9.6\n0.02\n0.48\n0.02\n0.53\n\n\n13\n0.32\n0.14\n0.15\n0.02\n0.02\n29\n17\n8.2\n8.2\n0.04\n0.60\n0.05\n0.65\n\n\n14\n0.20\n0.07\n0.08\n0.01\n0.01\n33\n32\n9.5\n9.5\n0.06\n0.35\n0.06\n0.40\n\n\n15\n0.15\n0.06\n0.07\n0.01\n0.01\n24\n30\n8.8\n8.8\n0.03\n0.27\n0.04\n0.32\n\n\n16\n0.16\n0.05\n0.06\n0.00\n0.00\n52\n86\n13.7\n13.7\n0.06\n0.25\n0.06\n0.28\n\n\n17\n0.18\n0.06\n0.07\n0.00\n0.00\n30\n45\n10.7\n10.7\n0.07\n0.29\n0.07\n0.33\n\n\n18\n0.15\n0.06\n0.07\n0.01\n0.02\n56\n98\n14.5\n14.5\n0.04\n0.26\n0.02\n0.29\n\n\n19\n0.11\n0.05\n0.06\n0.02\n0.09\n96\n102\n16.4\n16.4\n0.01\n0.20\n-0.01\n0.21\n\n\n20\n0.10\n0.06\n0.07\n0.08\n0.16\n85\n56\n13.9\n13.9\n-0.01\n0.21\n-0.04\n0.23\n\n\n21\n0.08\n0.05\n0.06\n0.11\n0.22\n80\n39\n13.2\n13.2\n-0.02\n0.19\n-0.05\n0.20\n\n\n22\n0.07\n0.06\n0.07\n0.21\n0.35\n73\n53\n13.3\n13.3\n-0.04\n0.19\n-0.07\n0.20\n\n\n23\n0.10\n0.05\n0.06\n0.04\n0.12\n96\n52\n14.1\n14.1\n0.00\n0.20\n-0.02\n0.21\n\n\n24\n0.10\n0.05\n0.07\n0.05\n0.14\n103\n60\n14.5\n14.5\n0.00\n0.21\n-0.03\n0.23\n\n\n25\n0.10\n0.06\n0.07\n0.10\n0.23\n83\n57\n13.6\n13.6\n-0.02\n0.22\n-0.06\n0.24\n\n\n26\n0.06\n0.07\n0.09\n0.43\n0.64\n55\n49\n11.7\n11.7\n-0.09\n0.20\n-0.13\n0.22\n\n\n27\n0.05\n0.08\n0.10\n0.56\n0.80\n37\n38\n9.6\n9.6\n-0.11\n0.21\n-0.17\n0.22\n\n\n30\n0.01\n0.09\n0.11\n0.88\n0.95\n32\n34\n9.2\n9.2\n-0.17\n0.19\n-0.22\n0.21\n\n\n31\n0.08\n0.06\n0.07\n0.20\n0.35\n65\n61\n12.8\n12.8\n-0.04\n0.19\n-0.08\n0.21\n\n\n32\n0.11\n0.06\n0.07\n0.07\n0.14\n47\n39\n10.6\n10.6\n-0.01\n0.22\n-0.03\n0.24\n\n\n33\n0.10\n0.04\n0.05\n0.01\n0.04\n102\n68\n14.9\n14.9\n0.02\n0.17\n0.00\n0.20\n\n\n34\n0.10\n0.04\n0.05\n0.01\n0.02\n109\n63\n14.8\n14.8\n0.03\n0.18\n0.02\n0.20\n\n\n35\n0.11\n0.04\n0.05\n0.01\n0.02\n53\n47\n11.3\n11.3\n0.02\n0.19\n0.02\n0.22\n\n\n36\n0.17\n0.03\n0.03\n0.00\n0.00\n24\n25\n8.6\n8.6\n0.11\n0.23\n0.12\n0.25\n\n\n37\n0.15\n0.05\n0.06\n0.00\n0.01\n38\n21\n8.6\n8.6\n0.05\n0.26\n0.05\n0.29\n\n\n38\n0.15\n0.06\n0.07\n0.01\n0.02\n108\n44\n13.4\n13.4\n0.04\n0.25\n0.02\n0.29\n\n\n39\n0.13\n0.05\n0.06\n0.01\n0.02\n167\n64\n16.5\n16.5\n0.03\n0.22\n0.03\n0.26\n\n\n40\n0.14\n0.05\n0.06\n0.01\n0.01\n137\n62\n15.1\n15.1\n0.04\n0.24\n0.04\n0.28\n\n\n41\n0.18\n0.06\n0.07\n0.00\n0.00\n61\n45\n11.1\n11.1\n0.06\n0.30\n0.07\n0.34\n\n\n42\n0.15\n0.06\n0.07\n0.01\n0.01\n57\n50\n10.9\n10.9\n0.03\n0.26\n0.04\n0.30\n\n\n43\n0.13\n0.05\n0.06\n0.01\n0.01\n152\n64\n15.5\n15.5\n0.04\n0.22\n0.04\n0.25\n\n\n44\n0.11\n0.06\n0.07\n0.04\n0.05\n99\n60\n13.3\n13.3\n0.01\n0.22\n0.00\n0.26\n\n\n45\n0.10\n0.05\n0.06\n0.04\n0.05\n111\n59\n13.8\n13.8\n0.01\n0.20\n0.00\n0.23\n\n\n46\n0.11\n0.06\n0.08\n0.09\n0.10\n112\n52\n13.4\n13.4\n-0.02\n0.23\n-0.02\n0.28\n\n\n47\n0.08\n0.05\n0.06\n0.12\n0.13\n130\n60\n15.5\n15.5\n-0.02\n0.18\n-0.03\n0.21\n\n\n48\n0.06\n0.04\n0.05\n0.12\n0.18\n233\n75\n23.0\n23.0\n-0.02\n0.15\n-0.03\n0.18\n\n\n49\n0.06\n0.04\n0.06\n0.17\n0.23\n162\n67\n19.6\n19.6\n-0.03\n0.15\n-0.04\n0.17\n\n\n50\n0.05\n0.04\n0.05\n0.24\n0.35\n112\n60\n17.6\n17.6\n-0.03\n0.12\n-0.05\n0.14\n\n\n\n\n\nСредний тритмент эффект определяется как среднее значение всех точечных оценок.\n\nmean(results$Estimate)\n\n[1] 0.116875\n\n\nПолучили 0.12, практически так, как и замоделировали.\nДля построения серии подобных оценок и визуализации в пространстве каждой точечной оценки нам необходим пространственный объект. Все это включено в функцию plotspatialrd().\n\nresults &lt;- spatialrd(y = \"education\", data = points_samp.sf, cutoff.points = borderpoints.sf, treated = \"treated\", minobs = 10)\nplotspatialrd(results, map = T)\n\n\n\n\nМожно вывести и более компактно:\n\nplotspatialrd(results, map = F)"
  },
  {
    "objectID": "spatial_regression_discontinuity.html#робастность",
    "href": "spatial_regression_discontinuity.html#робастность",
    "title": "9  Пространственная разрывная регрессия",
    "section": "9.6 Робастность",
    "text": "9.6 Робастность\nВ работах с разрывной регрессией исследователь обычно также должен показать, что результаты устойчивы к различным спецификациям и параметрам. Пакет SpatialRDD предлагает множество возможностей, которые экономят время и упрощают воспроизводимость. Этот набор инструментов для смещения и перемещения вокруг границ и последующего назначения тритмента (плацебо) на самом деле настолько эффективен, что его можно использовать во многих других условиях дизайна исследований за пределами географических RD.\n\n9.6.1 Плацебо граница\nМы применяем сдвиг на 3000 метров по координатам x и y границы.\n\nplacebocut_off.1 &lt;- shift_border(cut_off.sf, operation = \"shift\", shift = c(3000, 3000))\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\nplaceboborderpoints.1 &lt;- discretise_border(cutoff = placebocut_off.1, n = 50)\n\nStarting to create 50 borderpoints from the given set of borderpoints. Approximately every 3 kilometres we can run an estimation then.\n\ntm_shape(points_samp.sf) + tm_dots(\"treated\", palette = \"Set1\")  + tm_shape(placeboborderpoints.1) + tm_symbols(shape = 4, size = .3) + tm_shape(placebocut_off.1) + tm_lines()\n\n\n\n\nПосле сдвига границы нам теперь нужно повторно присвоить новый тритмент, чтобы выполнить регрессии.\nМы создаем новые полигоны с нуля с помощью функции cutoff2polygons(). В нашем случае нам не нужно огибать углы контрфактического многоугольника, потому что оба конца отсечки идут на запад. Просто убедитесь, что конечные точки выбраны таким образом, чтобы все наблюдения, которые должны быть в группе «тритмент плацебо», также фактически находились внутри этого результирующего многоугольника.\n\nplacebo.poly.1 &lt;- cutoff2polygon(data = points_samp.sf, cutoff = placebocut_off.1, orientation = c(\"west\", \"west\"), endpoints = c(.8, .2))\n\ntm_shape(placebo.poly.1) + tm_polygons(alpha = .3)\n\n\n\n\nНаконец, мы должны снова использовать функцию assign_treated():\n\npoints_samp.sf$treated1 &lt;- assign_treated(data = points_samp.sf, polygon = placebo.poly.1, id = \"id\")\nsum(points_samp.sf$treated == 0 & points_samp.sf$treated1 == 1) # количество деревень, которые изменили статус тритмента\n\n[1] 60\n\ntm_shape(points_samp.sf) + tm_dots(\"treated1\", palette = \"Set1\")  + tm_shape(placeboborderpoints.1) + tm_symbols(shape = 4, size = .3) + tm_shape(placebocut_off.1) + tm_lines()\n\n\n\n\nПосле повторного нанесения точек мы можем визуально сделать вывод, что правильно перераспределили группы в тритмент и контроль.\nДалее мы можем подсчитать количество деревень, которые меняют свой статус. Это помогает нам решить, было ли смещение границы достаточно большим (например, если переключится только несколько наблюдений, то мы ожидаем, что это практически не повлияет на наши точечные оценки, и поэтому такое упражнение на надежность можно назвать не очень значимым).\nВ данном случае поменялось 60 деревень. Учитывая начальное количество обработанных наблюдений, это кажется изменением достаточно большой величины и, следовательно, значимым упражнением на надежность.\n\n\n9.6.2 Надежность GRD\nНаконец, мы снова делаем то же самое упражнение, описанное выше, и запускаем непараметрическую спецификацию на многих граничных точках, чтобы аппроксимировать многократный эффект воздействия. Ряд колеблется около 0 и не имеет ни одной значимой оценки, поэтому можно сделать вывод, что методология работает.\n\nresults1 &lt;- spatialrd(y = \"education\", data = points_samp.sf, cutoff.points = placeboborderpoints.1, treated = \"treated1\", minobs = 10)\nplotspatialrd(results1, map = T)\n\n\n\n\n\n\n9.6.3 Устойчивость к спецификации полинома\nНаконец, мы также запускаем наше плацебо-упражнение с параметрической спецификацией.\nК сожалению, OLS с фиксированными эффектами не так чувствительна, когда дело доходит до обнаружения сдвига границы. Коэффициент по-прежнему находится на грани значимости. В этом случае мы должны были отодвинуть границу на 1-2 километра дальше, чтобы сделать ее незначительной.\n\npoints_samp.sf$segment.1.5 &lt;- border_segment(points_samp.sf, placebocut_off.1, 5) # assigning new segments based on now cutoff\n\nStarting to create 5 border segments with an approximate length of 26 kilometres each.\n\npoints_samp.sf$dist2cutoff1 &lt;- as.numeric(sf::st_distance(points_samp.sf, placebocut_off.1)) # recompute distance to new placebo cutoff\n\nlist(\n  lm(education ~ treated1, data = points_samp.sf[points_samp.sf$dist2cutoff1 &lt; 3000, ]),\n  lfe::felm(education ~ treated1 | factor(segment.1.5) | 0 | 0, data = points_samp.sf[points_samp.sf$dist2cutoff1 &lt; 3000, ])\n) %&gt;% stargazer::stargazer(type = \"text\")\n\n\n========================================================\n                            Dependent variable:         \n                    ------------------------------------\n                                 education              \n                            OLS               felm      \n                            (1)               (2)       \n--------------------------------------------------------\ntreated11                  0.021             0.018      \n                          (0.015)           (0.015)     \n                                                        \nConstant                 0.617***                       \n                          (0.010)                       \n                                                        \n--------------------------------------------------------\nObservations                177               177       \nR2                         0.011             0.032      \nAdjusted R2                0.005             0.004      \nResidual Std. Error  0.100 (df = 175)   0.100 (df = 171)\nF Statistic         1.944 (df = 1; 175)                 \n========================================================\nNote:                        *p&lt;0.1; **p&lt;0.05; ***p&lt;0.01"
  },
  {
    "objectID": "spatial_regression_discontinuity.html#смещение-границ-создание-полигонов-из-линий",
    "href": "spatial_regression_discontinuity.html#смещение-границ-создание-полигонов-из-линий",
    "title": "9  Пространственная разрывная регрессия",
    "section": "9.7 Смещение границ, создание полигонов из линий",
    "text": "9.7 Смещение границ, создание полигонов из линий\nОдной из самых утомительных задач, когда речь идет о географических RDD, является выполнение так называемых проверок плацебо. С ними нужно показать, что постулируемый эффект исчезает при смещении границы RD. Иными словами, тритмент должен быть незначительным при оценке RD на любой другой границе.\n\nlibrary(SpatialRDD)\ndata(cut_off.sf, polygon_full.sf, polygon_treated.sf)\nlibrary(tmap)\nset.seed(1088) # set a seed to make the results replicable\npoints_samp.sf &lt;- sf::st_sample(polygon_full.sf, 1000)\npoints_samp.sf &lt;- sf::st_sf(points_samp.sf) # make it an sf object bc st_sample only created the geometry list-column (sfc)\npoints_samp.sf$id &lt;- 1:nrow(points_samp.sf) # add a unique ID to each observation\n\n\n9.7.1 Повороты\n\ntm_rotate.sf10 &lt;- shift_border(border = cut_off.sf, operation = \"rotate\", angle = 10)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_rotate.sf25 &lt;- shift_border(border = cut_off.sf, operation = \"rotate\", angle = 25)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_rotate.sf45 &lt;- shift_border(border = cut_off.sf, operation = \"rotate\", angle = 45)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\n\n\ntm_shape(polygon_full.sf) + tm_polygons() + tm_shape(cut_off.sf) + tm_lines() + \n  tm_shape(tm_rotate.sf10) + tm_lines(col = \"red\") + \n  tm_shape(tm_rotate.sf25) + tm_lines(col = \"red\") + \n  tm_shape(tm_rotate.sf45) + tm_lines(col = \"red\")\n\n\n\n\n\n\n9.7.2 Масштабирование\n\ntm_scale.sf.4 &lt;- shift_border(border = cut_off.sf, operation = \"scale\", scale = .4)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_scale.sf.7 &lt;- shift_border(border = cut_off.sf, operation = \"scale\", scale = .7)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_scale.sf1.5 &lt;- shift_border(border = cut_off.sf, operation = \"scale\", scale = 1.5)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\n\n\ntm_shape(polygon_full.sf) + tm_polygons() + tm_shape(cut_off.sf) + tm_lines() + \n  tm_shape(tm_scale.sf.4) + tm_lines(col = \"blue\") + \n  tm_shape(tm_scale.sf.7) + tm_lines(col = \"red\") + \n  tm_shape(tm_scale.sf1.5) + tm_lines(col = \"red\")\n\n\n\n\n\n\n9.7.3 Сдвиг\n\ntm_shift.sf3 &lt;- shift_border(border = cut_off.sf, operation = \"shift\", shift = c(3000, 0))\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_shift.sf6 &lt;- shift_border(border = cut_off.sf, operation = \"shift\", shift = c(6000, 0))\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_shift.sf_4 &lt;- shift_border(border = cut_off.sf, operation = \"shift\", shift = c(-4000, 0))\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\n\n\ntm_shape(polygon_full.sf) + tm_polygons() + tm_shape(cut_off.sf) + tm_lines() + \n  tm_shape(tm_shift.sf3) + tm_lines(col = \"red\") + \n  tm_shape(tm_shift.sf6) + tm_lines(col = \"red\") + \n  tm_shape(tm_shift.sf_4) + tm_lines(col = \"blue\")  \n\n\n\n\n\ntm_shift.sf_42 &lt;- shift_border(border = cut_off.sf, operation = \"shift\", shift = c(-4000, -2000))\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_shift.sf_44 &lt;- shift_border(border = cut_off.sf, operation = \"shift\", shift = c(-4000, -4000))\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\n\n\ntm_shape(polygon_full.sf) + tm_polygons() + tm_shape(cut_off.sf) + tm_lines() + \n  tm_shape(tm_shift.sf_42) + tm_lines(col = \"red\") + \n  tm_shape(tm_shift.sf_44) + tm_lines(col = \"red\") + \n  tm_shape(tm_shift.sf_4) + tm_lines(col = \"blue\")  \n\n\n\n\n\n\n9.7.4 Всё вместе\nПравильная граница плацебо в идеале включает в себя как сдвиг, так и изменение масштаба:\n\ntm_placebo.sf1 &lt;- shift_border(border = cut_off.sf, operation = c(\"shift\", \"scale\"), shift = c(-5000, -3000), scale = .85)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_placebo.sf2 &lt;- shift_border(border = cut_off.sf, operation = c(\"shift\", \"scale\"), shift = c(4000, 2000), scale = 1.1)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\ntm_placebo.sf3 &lt;- shift_border(border = cut_off.sf, operation = c(\"shift\", \"scale\"), shift = c(6000, 3000), scale = 1.2)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\n\n\ntm_shape(polygon_full.sf) + tm_polygons() + tm_shape(cut_off.sf) + tm_lines() + \n  tm_shape(tm_placebo.sf1) + tm_lines(col = \"red\") +\n  tm_shape(tm_placebo.sf2) + tm_lines(col = \"red\") +\n  tm_shape(tm_placebo.sf3) + tm_lines(col = \"red\")\n\n\n\n\n\ntm_shift.sf &lt;- shift_border(border = cut_off.sf, operation = c(\"shift\", \"rotate\", \"scale\"), \n                              shift = c(-10000, -1000), angle = 0, scale = .9)\n\nPay attention to CRS! If you work in lon/lat then degrees have to be provided. Local UTM CRS is preferable!\n\n\n\ntm_shape(cut_off.sf) + tm_lines() + tm_shape(tm_shift.sf) + tm_lines(col = \"red\")\n\n\n\n\nИ соответствующие полигоны для назначения тритмента:\n\npolygon1 &lt;- cutoff2polygon(data = points_samp.sf, cutoff = tm_placebo.sf1, orientation = c(\"west\", \"west\"), endpoints = c(.8, .2), # corners = 0,\n                           #     crs = 32643\n                           )\npolygon2 &lt;- cutoff2polygon(data = points_samp.sf, cutoff = tm_placebo.sf2, orientation = c(\"west\", \"west\"), endpoints = c(.8, .2), # corners = 0,\n                           #     crs = 32643\n                           )\npolygon3 &lt;- cutoff2polygon(data = points_samp.sf, cutoff = tm_placebo.sf3, orientation = c(\"west\", \"west\"), endpoints = c(.8, .2), # corners = 0,\n                           #     crs = 32643\n                           )\n\n\ntm_shape(polygon_full.sf) + tm_polygons() + \n  tm_shape(polygon_treated.sf) + tm_polygons(col = \"grey\") + \n  tm_shape(cut_off.sf) + tm_lines(col = \"red\") +\n  tm_shape(polygon1) + tm_polygons(alpha = .3) +\n  tm_shape(polygon2) + tm_polygons(alpha = .3) +\n  tm_shape(polygon3) + tm_polygons(alpha = .3)"
  },
  {
    "objectID": "synthetic_control.html#напоминание-теории",
    "href": "synthetic_control.html#напоминание-теории",
    "title": "11  Синтетический контроль",
    "section": "11.1 Напоминание теории",
    "text": "11.1 Напоминание теории\nin progress…"
  },
  {
    "objectID": "synthetic_control.html#пример",
    "href": "synthetic_control.html#пример",
    "title": "11  Синтетический контроль",
    "section": "11.2 Пример",
    "text": "11.2 Пример\n\nlibrary('tidysynth')\n\n\ndata(\"smoking\")\nsmoking %&gt;% dplyr::glimpse()\n\nRows: 1,209\nColumns: 7\n$ state     &lt;chr&gt; \"Rhode Island\", \"Tennessee\", \"Indiana\", \"Nevada\", \"Louisiana…\n$ year      &lt;dbl&gt; 1970, 1970, 1970, 1970, 1970, 1970, 1970, 1970, 1970, 1970, …\n$ cigsale   &lt;dbl&gt; 123.9, 99.8, 134.6, 189.5, 115.9, 108.4, 265.7, 93.8, 100.3,…\n$ lnincome  &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ beer      &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ age15to24 &lt;dbl&gt; 0.1831579, 0.1780438, 0.1765159, 0.1615542, 0.1851852, 0.175…\n$ retprice  &lt;dbl&gt; 39.3, 39.9, 30.6, 38.9, 34.3, 38.4, 31.4, 37.3, 36.7, 28.8, …\n\n\n\nsmoking_out &lt;- smoking %&gt;%\n    # initial the synthetic control object\n    synthetic_control(outcome = cigsale, # outcome\n                      unit = state, # unit index in the panel data\n                      time = year, # time index in the panel data\n                      i_unit = \"California\", # unit where the intervention occurred\n                      i_time = 1988, # time period when the intervention occurred\n                      generate_placebos=T # generate placebo synthetic controls (for inference)\n    ) %&gt;%\n    \n    # Generate the aggregate predictors used to fit the weights\n    \n    # average log income, retail price of cigarettes, and proportion of the\n    # population between 15 and 24 years of age from 1980 - 1988\n    generate_predictor(time_window = 1980:1988,\n                       ln_income = mean(lnincome, na.rm = T),\n                       ret_price = mean(retprice, na.rm = T),\n                       youth = mean(age15to24, na.rm = T)) %&gt;%\n    \n    # average beer consumption in the donor pool from 1984 - 1988\n    generate_predictor(time_window = 1984:1988,\n                       beer_sales = mean(beer, na.rm = T)) %&gt;%\n    \n    # Lagged cigarette sales \n    generate_predictor(time_window = 1975,\n                       cigsale_1975 = cigsale) %&gt;%\n    generate_predictor(time_window = 1980,\n                       cigsale_1980 = cigsale) %&gt;%\n    generate_predictor(time_window = 1988,\n                       cigsale_1988 = cigsale) %&gt;%\n    \n    \n    # Generate the fitted weights for the synthetic control\n    generate_weights(optimization_window = 1970:1988, # time to use in the optimization task\n                     margin_ipop = .02,sigf_ipop = 7,bound_ipop = 6 # optimizer options\n    ) %&gt;%\n    \n    # Generate the synthetic control\n    generate_control()\n\n\nCalifornia_treated &lt;- smoking_out[1,]\nCalifornia_control &lt;- smoking_out[2,]\nCalifornia_treated_outcome &lt;- California_control$.outcome[[1]]\nCalifornia_control_outcome &lt;- California_treated$.outcome[[1]]\nCalifornia &lt;- merge(California_control_outcome, California_treated_outcome, by = 'time_unit')\n\n\n# Потенциальные исходы\nCalifornia &lt;- smoking_out[1,]\nCalifornia_outcomes &lt;- California$.synthetic_control[[1]]\n\n# График\nCalifornia_outcomes &lt;- data.frame(time = c(rep(California_outcomes$time_unit,2)),\n                                  outcome = c(California_outcomes$real_y, California_outcomes$synth_y), \n                                  label = c(rep('real', 31), rep('synth', 31)))\nCalifornia_outcomes$label &lt;- as.factor(California_outcomes$label)\nlibrary(ggplot2)\nggplot(California_outcomes, aes(x = time, y = outcome, color = label)) + \n  geom_point()\n\n\n\n\n\nsmoking_out\n\n# A tibble: 78 × 11\n   .id       .plac…¹ .type .outcome .predi…² .synth…³ .unit_…⁴ .predi…⁵ .origi…⁶\n   &lt;chr&gt;       &lt;dbl&gt; &lt;chr&gt; &lt;list&gt;   &lt;list&gt;   &lt;list&gt;   &lt;list&gt;   &lt;list&gt;   &lt;list&gt;  \n 1 Californ…       0 trea… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 2 Californ…       0 cont… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 3 Rhode Is…       1 trea… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 4 Rhode Is…       1 cont… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 5 Tennessee       1 trea… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 6 Tennessee       1 cont… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 7 Indiana         1 trea… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 8 Indiana         1 cont… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n 9 Nevada          1 trea… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n10 Nevada          1 cont… &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt; &lt;tibble&gt;\n# … with 68 more rows, 2 more variables: .meta &lt;list&gt;, .loss &lt;list&gt;, and\n#   abbreviated variable names ¹​.placebo, ²​.predictors, ³​.synthetic_control,\n#   ⁴​.unit_weights, ⁵​.predictor_weights, ⁶​.original_data\n\n\n\nsmoking_out %&gt;% grab_synthetic_control()\n\n# A tibble: 31 × 3\n   time_unit real_y synth_y\n       &lt;dbl&gt;  &lt;dbl&gt;   &lt;dbl&gt;\n 1      1970   123     116.\n 2      1971   121     118.\n 3      1972   124.    123.\n 4      1973   124.    124.\n 5      1974   127.    126.\n 6      1975   127.    127.\n 7      1976   128     127.\n 8      1977   126.    125.\n 9      1978   126.    125.\n10      1979   122.    122.\n# … with 21 more rows\n\n\nПосле создания синтетического контроля можно легко оценить соответствие, сравнив тенденции синтетического и наблюдаемого временных рядов. Идея состоит в том, что тенденции в период до вмешательства должны быть тесно связаны друг с другом.\n\nsmoking_out %&gt;% plot_trends()\n\n\n\n\nСравните распределения предикторов агрегированного уровня для наблюдаемой единицы вмешательства, синтетического контроля и среднего пула доноров.\n\nsmoking_out %&gt;% grab_balance_table()\n\n# A tibble: 7 × 4\n  variable     California synthetic_California donor_sample\n  &lt;chr&gt;             &lt;dbl&gt;                &lt;dbl&gt;        &lt;dbl&gt;\n1 ln_income        10.1                  9.84         9.83 \n2 ret_price        89.4                 89.4         87.3  \n3 youth             0.174                0.174        0.173\n4 beer_sales       24.3                 24.3         23.7  \n5 cigsale_1975    127.                 127.         137.   \n6 cigsale_1980    120.                 120.         138.   \n7 cigsale_1988     90.1                 90.8        114.   \n\n\nЧтобы зафиксировать причинную величину (то есть разницу между наблюдаемым и контрфактическим), можно построить различия, используя plot_differences ()\n\nsmoking_out %&gt;% plot_differences()\n\n\n\n\nКроме того, можно легко проверить взвешивание единиц и переменных в подгонке. Это позволяет увидеть, какие случаи были частично использованы для создания синтетического контроля.\n\nsmoking_out %&gt;% plot_weights()\n\n\n\n\n\nsmoking_out %&gt;% plot_placebos(prune = FALSE)\n\n\n\n\n\nsmoking_out %&gt;% plot_placebos() # выкидываем с плохой подгонкой\n\n\n\n\n\nsmoking_out %&gt;% plot_mspe_ratio()"
  },
  {
    "objectID": "staggered_adoption.html#напоминание-теории",
    "href": "staggered_adoption.html#напоминание-теории",
    "title": "11  Ступенчатая разность разностей",
    "section": "11.1 Напоминание теории",
    "text": "11.1 Напоминание теории\nhttps://bcallaway11.github.io/did/articles/index.html https://github.com/naoki-egami/DIDdesign#Staggered-Adoption-Design"
  },
  {
    "objectID": "staggered_adoption.html#пример",
    "href": "staggered_adoption.html#пример",
    "title": "11  Ступенчатая разность разностей",
    "section": "11.2 Пример",
    "text": "11.2 Пример\n\nlibrary(did)\ndata(mpdta)\nhead(mpdta)\n\n    year countyreal     lpop     lemp first.treat treat\n866 2003       8001 5.896761 8.461469        2007     1\n841 2004       8001 5.896761 8.336870        2007     1\n842 2005       8001 5.896761 8.340217        2007     1\n819 2006       8001 5.896761 8.378161        2007     1\n827 2007       8001 5.896761 8.487352        2007     1\n937 2003       8019 2.232377 4.997212        2007     1\n\n\n\n# estimate group-time average treatment effects without covariates\nmw.attgt &lt;- att_gt(yname = \"lemp\",\n                   gname = \"first.treat\",\n                   idname = \"countyreal\",\n                   tname = \"year\",\n                   xformla = ~1,\n                   data = mpdta,\n                   )\n\n# summarize the results\nsummary(mw.attgt)\n\n\nCall:\natt_gt(yname = \"lemp\", tname = \"year\", idname = \"countyreal\", \n    gname = \"first.treat\", xformla = ~1, data = mpdta)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\nGroup-Time Average Treatment Effects:\n Group Time ATT(g,t) Std. Error [95% Simult.  Conf. Band]  \n  2004 2004  -0.0105     0.0246       -0.0781      0.0570  \n  2004 2005  -0.0704     0.0308       -0.1548      0.0140  \n  2004 2006  -0.1373     0.0360       -0.2359     -0.0387 *\n  2004 2007  -0.1008     0.0326       -0.1900     -0.0116 *\n  2006 2004   0.0065     0.0238       -0.0588      0.0719  \n  2006 2005  -0.0028     0.0207       -0.0594      0.0539  \n  2006 2006  -0.0046     0.0176       -0.0528      0.0436  \n  2006 2007  -0.0412     0.0199       -0.0956      0.0132  \n  2007 2004   0.0305     0.0148       -0.0100      0.0710  \n  2007 2005  -0.0027     0.0161       -0.0469      0.0415  \n  2007 2006  -0.0311     0.0174       -0.0786      0.0165  \n  2007 2007  -0.0261     0.0175       -0.0740      0.0219  \n---\nSignif. codes: `*' confidence band does not cover 0\n\nP-value for pre-test of parallel trends assumption:  0.16812\nControl Group:  Never Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\n\n# plot the results\n# set ylim so that all plots have the same scale along y-axis\nggdid(mw.attgt, ylim = c(-.3,.3))\n\n\n\n\n\n# aggregate the group-time average treatment effects\nmw.dyn &lt;- aggte(mw.attgt, type = \"dynamic\")\nsummary(mw.dyn)\n\n\nCall:\naggte(MP = mw.attgt, type = \"dynamic\")\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on event-study/dynamic aggregation:  \n     ATT    Std. Error     [ 95%  Conf. Int.]  \n -0.0772        0.0213     -0.119     -0.0355 *\n\n\nDynamic Effects:\n Event time Estimate Std. Error [95% Simult.  Conf. Band]  \n         -3   0.0305     0.0147       -0.0075      0.0685  \n         -2  -0.0006     0.0137       -0.0360      0.0349  \n         -1  -0.0245     0.0142       -0.0612      0.0123  \n          0  -0.0199     0.0114       -0.0494      0.0095  \n          1  -0.0510     0.0169       -0.0947     -0.0072 *\n          2  -0.1373     0.0382       -0.2361     -0.0385 *\n          3  -0.1008     0.0377       -0.1982     -0.0034 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Never Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\n\nggdid(mw.dyn, ylim = c(-.3,.3))\n\n\n\n\n\nmw.dyn.balance &lt;- aggte(mw.attgt, type = \"dynamic\", balance_e=1)\nsummary(mw.dyn.balance)\n\n\nCall:\naggte(MP = mw.attgt, type = \"dynamic\", balance_e = 1)\n\nReference: Callaway, Brantly and Pedro H.C. Sant'Anna.  \"Difference-in-Differences with Multiple Time Periods.\" Journal of Econometrics, Vol. 225, No. 2, pp. 200-230, 2021. &lt;https://doi.org/10.1016/j.jeconom.2020.12.001&gt;, &lt;https://arxiv.org/abs/1803.09015&gt; \n\n\nOverall summary of ATT's based on event-study/dynamic aggregation:  \n     ATT    Std. Error     [ 95%  Conf. Int.]  \n -0.0288        0.0145    -0.0571      -4e-04 *\n\n\nDynamic Effects:\n Event time Estimate Std. Error [95% Simult.  Conf. Band]  \n         -2   0.0065     0.0235       -0.0499      0.0629  \n         -1  -0.0028     0.0197       -0.0500      0.0445  \n          0  -0.0066     0.0139       -0.0400      0.0269  \n          1  -0.0510     0.0182       -0.0947     -0.0072 *\n---\nSignif. codes: `*' confidence band does not cover 0\n\nControl Group:  Never Treated,  Anticipation Periods:  0\nEstimation Method:  Doubly Robust\n\n\n\nmw.attgt.X &lt;- att_gt(yname = \"lemp\",\n                   gname = \"first.treat\",\n                   idname = \"countyreal\",\n                   tname = \"year\",\n                   xformla = ~lpop,\n                   data = mpdta,\n                   )"
  },
  {
    "objectID": "event_study.html#пример-руками",
    "href": "event_study.html#пример-руками",
    "title": "12  Событийный анализ",
    "section": "12.1 Пример “руками”",
    "text": "12.1 Пример “руками”\n\nlibrary('dplyr')\nlibrary('lubridate')\nlibrary('causaldata')\n\n\n12.1.1 Подготовка данных\nИмпортируем данные и обозначаем дату иследуемого события:\n\ngoog &lt;- causaldata::google_stock\nevent &lt;- ymd('2015-08-10')\n\nПосмотрим как ведут себя котировки акций и рыночного индекса вокруг даты события:\n\ngoog_plot &lt;- data.frame(date = goog$Date, \n                        return = c(goog$Google_Return, goog$SP500_Return),\n                        object = c(rep('Google', nrow(goog)), \n                                   rep('SP500', nrow(goog))))\n\nlibrary('ggplot2')\n\nggplot(goog_plot, aes(date, return)) +\n  geom_line(aes(colour=object)) +\n  geom_vline(aes(xintercept=event), linetype = 'dashed')\n\n\n\n\n\n\n12.1.2 Выбор окна\n\n# Estimation window\nestimation_data &lt;- goog %&gt;% filter(Date &gt;= ymd('2015-05-01') & Date &lt;= ymd('2015-07-31'))\n\n# Event window\nevent_data &lt;- goog %&gt;% filter(Date &gt;= event - days(7) & Date &lt;= event + days(14))\n\n\n\n12.1.3 Аномальная доходность\n\n# CAPM\ncapm &lt;- lm(Google_Return ~ SP500_Return, data = estimation_data)\n\n# Abnormal return\nevent_data &lt;- event_data %&gt;%\n  mutate(AR_mean = Google_Return - mean(estimation_data$Google_Return),\n         AR_market = Google_Return - SP500_Return, \n         AR_risk = Google_Return - predict(capm, newdata = event_data))\n\n\nAR_plot &lt;- data.frame(date = event_data$Date, \n                      AR = c(event_data$AR_mean, event_data$AR_market, event_data$AR_risk),\n                      object = c(rep('means-adjusted rm', nrow(event_data)),\n                                 rep('market-adjusted rm', nrow(event_data)),\n                                 rep('risk-adjusted rm', nrow(event_data))))\n\nggplot(AR_plot, aes(date, AR))+\n  geom_line(aes(colour=object))+\n  geom_vline(aes(xintercept=event), linetype = 'dashed')\n\n\n\n\n\n\n12.1.4 Тестирование значимости события\n\n# Test\ngoog$AR_hat &lt;- predict(capm, newdata = goog)\nAR_mean &lt;- mean(goog$AR_hat)\ntest &lt;- goog %&gt;% mutate(shift = (AR_hat - AR_mean)^2)\nse &lt;- sqrt(sum(test$shift)/nrow(test))\nevent_data$t &lt;- event_data$AR_risk/se\n\nggplot(event_data, aes(x= Date, y = t)) +\n  geom_line() +\n  geom_vline(aes(xintercept = event), linetype = 'dashed') +\n  geom_hline(aes(yintercept = 1.96), linetype = 'dashed') +\n  geom_hline(aes(yintercept = -1.96),linetype = 'dashed')"
  },
  {
    "objectID": "event_study.html#пример-с-помощью-пакета-eventstudies",
    "href": "event_study.html#пример-с-помощью-пакета-eventstudies",
    "title": "12  Событийный анализ",
    "section": "12.2 Пример с помощью пакета eventstudies",
    "text": "12.2 Пример с помощью пакета eventstudies\n\n# library('devtools')\n# devtools::install_github(\"nipfpmf/eventstudies\", ref=\"master\")\nlibrary('eventstudies')\nlibrary('dplyr')\nlibrary('stringr')\nlibrary('dplyr')\n\n\n# Подгружаем датасет с новостями\nload(\"news_predupr.RData\")\n\n\n# Подгружаем котировки\nstocks_day &lt;- read.csv(\"~/Documents/master's_thesis/coding/data/stocks/stocks_day.csv\")\nstocks_day$time &lt;- as.POSIXlt(stocks_day$time, format=\"%Y-%m-%d\")\n\ndates &lt;- as.data.frame(seq(as.Date(\"2012-01-01\"), as.Date(\"2022-01-01\"), by = \"day\"))\ncolnames(dates)[1] &lt;- 'time'\n\nstocks_day &lt;- left_join(dates, stocks_day, by = c('time'))\n\nstocks_day &lt;- stocks_day[order(stocks_day$time),]\nstocks_day&lt;- stocks_day %&gt;% mutate(BANE.CLOSE = na.locf0(BANE.CLOSE), \n                                   SIBN.CLOSE = na.locf0(SIBN.CLOSE),\n                                   LKOH.CLOSE = na.locf0(LKOH.CLOSE),\n                                   ROSN.CLOSE = na.locf0(ROSN.CLOSE),\n                                   SNGS.CLOSE = na.locf0(SNGS.CLOSE),\n                                   TATN.CLOSE = na.locf0(TATN.CLOSE),\n                                   IMOEX.CLOSE = na.locf0(IMOEX.CLOSE),\n                                   MOEXOG.CLOSE = na.locf0(MOEXOG.CLOSE)) %&gt;% \n  mutate(bane = BANE.CLOSE/lag(BANE.CLOSE)-1,\n         sibn = SIBN.CLOSE/lag(SIBN.CLOSE)-1,\n         lkoh = LKOH.CLOSE/lag(LKOH.CLOSE)-1,\n         rosn = ROSN.CLOSE/lag(ROSN.CLOSE)-1,\n         sngs = SNGS.CLOSE/lag(SNGS.CLOSE)-1,\n         tatn = TATN.CLOSE/lag(TATN.CLOSE)-1,\n         imoex = IMOEX.CLOSE/lag(IMOEX.CLOSE)-1,\n         moexog = MOEXOG.CLOSE/lag(MOEXOG.CLOSE)-1)\n\nstocks_day &lt;- stocks_day[-c(1:3),-c(2:9)]\nstocks_day_zoo &lt;- read.zoo(stocks_day[,c(1:7)], format = \"%Y-%m-%d\")\nimoex &lt;- read.zoo(stocks_day[,c(1,8)], format = \"%Y-%m-%d\")\n\n\n# Графики\nes_day_predupr3 &lt;- eventstudy(firm.returns = stocks_day_zoo,\n                              event.list = news_predupr,\n                              event.window = 3,\n                              type = \"marketModel\",\n                              to.remap = TRUE,\n                              remap = \"cumsum\",\n                              inference = TRUE,\n                              inference.strategy = \"bootstrap\",\n                              model.args = list(market.returns=imoex)) \nes_day_predupr7 &lt;- eventstudy(firm.returns = stocks_day_zoo,\n                              event.list = news_predupr,\n                              event.window = 7,\n                              type = \"marketModel\",\n                              to.remap = TRUE,\n                              remap = \"cumsum\",\n                              inference = TRUE,\n                              inference.strategy = \"bootstrap\",\n                              model.args = list(market.returns=imoex)) \nes_day_predupr15 &lt;- eventstudy(firm.returns = stocks_day_zoo,\n                               event.list = news_predupr,\n                               event.window = 15,\n                               type = \"marketModel\",\n                               to.remap = TRUE,\n                               remap = \"cumsum\",\n                               inference = TRUE,\n                               inference.strategy = \"bootstrap\",\n                               model.args = list(market.returns=imoex)) \n\n\n# Плацебо тест\nset.seed(123)\npredupr &lt;- sample(seq(as.Date('2012/01/01'), as.Date('2019/01/01'), by=\"day\"), 9)\nplacebo_news_predupr &lt;- cbind(news_predupr[3], predupr)\ncolnames(placebo_news_predupr)[2] &lt;- 'when'\n\n\n# Плацебо графики\nplacebo_es_day_predupr3 &lt;- eventstudy(firm.returns = stocks_day_zoo,\n                                      event.list = placebo_news_predupr,\n                                      event.window = 3,\n                                      type = \"marketModel\",\n                                      to.remap = TRUE,\n                                      remap = \"cumsum\",\n                                      inference = TRUE,\n                                      inference.strategy = \"bootstrap\",\n                                      model.args = list(market.returns=imoex)) \nplacebo_es_day_predupr7 &lt;- eventstudy(firm.returns = stocks_day_zoo,\n                                      event.list = placebo_news_predupr,\n                                      event.window = 7,\n                                      type = \"marketModel\",\n                                      to.remap = TRUE,\n                                      remap = \"cumsum\",\n                                      inference = TRUE,\n                                      inference.strategy = \"bootstrap\",\n                                      model.args = list(market.returns=imoex)) \nplacebo_es_day_predupr15 &lt;- eventstudy(firm.returns = stocks_day_zoo,\n                                       event.list = placebo_news_predupr,\n                                       event.window = 15,\n                                       type = \"marketModel\",\n                                       to.remap = TRUE,\n                                       remap = \"cumsum\",\n                                       inference = TRUE,\n                                       inference.strategy = \"bootstrap\",\n                                       model.args = list(market.returns=imoex)) \n\n\n### Событийное окно (-3;+3) дня\npar(mfrow=c(1,2),oma = c(0, 0, 2, 0), mai=c(.8,.8,.2,.2), cex=.7)\nplot(es_day_predupr3) \nplot(placebo_es_day_predupr3) \nmtext(\"Оценка эффекта - слева, плацебо тест - справа\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n### Событийное окно (-7;+7) дней\npar(mfrow=c(1,2),oma = c(0, 0, 2, 0), mai=c(.8,.8,.2,.2), cex=.7)\nplot(es_day_predupr7) \nplot(placebo_es_day_predupr7) \nmtext(\"Оценка эффекта - слева, плацебо тест - справа\", outer = TRUE, cex = 1.5)\n\n\n\n\n\n### Событийное окно (-15;+15) дней\npar(mfrow=c(1,2),oma = c(0, 0, 2, 0), mai=c(.8,.8,.2,.2), cex=.7)\nplot(es_day_predupr15) \nplot(placebo_es_day_predupr15) \nmtext(\"Оценка эффекта - слева, плацебо тест - справа\", outer = TRUE, cex = 1.5)"
  },
  {
    "objectID": "event_study.html#causal-impact",
    "href": "event_study.html#causal-impact",
    "title": "12  Событийный анализ",
    "section": "12.3 Causal Impact",
    "text": "12.3 Causal Impact\n\noptions(warn = -1)\nlibrary(tseries)\nlibrary(ggplot2)\n#devtools::install_github(\"google/CausalImpact\")\nlibrary(CausalImpact)\n\n\nstart = \"2011-01-03\"\n  end = \"2017-03-20\"\nquote = \"AdjClose\"\nVolksWagen &lt;- get.hist.quote(instrument = \"VOW.DE\", start, end, quote, compression = \"w\")\nBMW &lt;- get.hist.quote(instrument = \"BMW.DE\", start, end, quote, compression = \"w\")\nAllianz &lt;- get.hist.quote(instrument = \"ALV.DE\", start, end, quote, compression = \"w\")\nseries &lt;- cbind(VolksWagen, BMW, Allianz)\n\n\ncolnames(series) &lt;- c(\"VolksWagen\", \"BMW\", \"Allianz\")\nautoplot(series, facet = NULL) + xlab(\"\") + ylab(\"Adjusted Close Price\")\n\n\n\n\n\npre.period &lt;- as.Date(c(start, \"2015-09-14\"))\npost.period &lt;- as.Date(c(\"2015-09-21\", end))\n\n\nimpact_vw &lt;- CausalImpact(series[, 1], pre.period, post.period, model.args = list(niter = 1000, nseasons = 52))\nplot(impact_vw)\n\n\n\n\n\nsummary(impact_vw)\n\nPosterior inference {CausalImpact}\n\n                         Average        Cumulative    \nActual                   100            7887          \nPrediction (s.d.)        129 (18)       10225 (1429)  \n95% CI                   [92, 164]      [7297, 12959] \n                                                      \nAbsolute effect (s.d.)   -30 (18)       -2338 (1429)  \n95% CI                   [-64, 7.5]     [-5072, 590.0]\n                                                      \nRelative effect (s.d.)   -21% (12%)     -21% (12%)    \n95% CI                   [-39%, 8.1%]   [-39%, 8.1%]  \n\nPosterior tail-area probability p:   0.04966\nPosterior prob. of a causal effect:  95.034%\n\nFor more details, type: summary(impact, \"report\")\n\n\n\nsummary(impact_vw, \"report\")\n\nAnalysis report {CausalImpact}\n\n\nDuring the post-intervention period, the response variable had an average value of approx. 99.84. In the absence of an intervention, we would have expected an average response of 129.44. The 95% interval of this counterfactual prediction is [92.37, 164.04]. Subtracting this prediction from the observed response yields an estimate of the causal effect the intervention had on the response variable. This effect is -29.59 with a 95% interval of [-64.20, 7.47]. For a discussion of the significance of this effect, see below.\n\nSumming up the individual data points during the post-intervention period (which can only sometimes be meaningfully interpreted), the response variable had an overall value of 7.89K. Had the intervention not taken place, we would have expected a sum of 10.23K. The 95% interval of this prediction is [7.30K, 12.96K].\n\nThe above results are given in terms of absolute numbers. In relative terms, the response variable showed a decrease of -21%. The 95% interval of this percentage is [-39%, +8%].\n\nThis means that, although it may look as though the intervention has exerted a negative effect on the response variable when considering the intervention period as a whole, this effect is not statistically significant, and so cannot be meaningfully interpreted. The apparent effect could be the result of random fluctuations that are unrelated to the intervention. This is often the case when the intervention period is very long and includes much of the time when the effect has already worn off. It can also be the case when the intervention period is too short to distinguish the signal from the noise. Finally, failing to find a significant effect can happen when there are not enough control variables or when these variables do not correlate well with the response variable during the learning period.\n\nThe probability of obtaining this effect by chance is very small (Bayesian one-sided tail-area probability p = 0.05). This means the causal effect can be considered statistically significant. \n\n\n\nimpact_vw_reg &lt;- CausalImpact(series, pre.period, post.period, model.args = list(niter = 1000, nseasons = 52))\nplot(impact_vw_reg)\n\n\n\n\n\nsummary(impact_vw_reg)\n\nPosterior inference {CausalImpact}\n\n                         Average        Cumulative    \nActual                   100            7887          \nPrediction (s.d.)        134 (4.2)      10586 (331.3) \n95% CI                   [125, 142]     [9910, 11227] \n                                                      \nAbsolute effect (s.d.)   -34 (4.2)      -2698 (331.3) \n95% CI                   [-42, -26]     [-3340, -2023]\n                                                      \nRelative effect (s.d.)   -25% (2.4%)    -25% (2.4%)   \n95% CI                   [-30%, -20%]   [-30%, -20%]  \n\nPosterior tail-area probability p:   0.00103\nPosterior prob. of a causal effect:  99.89701%\n\nFor more details, type: summary(impact, \"report\")"
  },
  {
    "objectID": "matching.html",
    "href": "matching.html",
    "title": "5  Мэтчинг",
    "section": "",
    "text": "library('MatchIt')\n\n\ndata('lalonde')\nhead(lalonde)\n\n     treat age educ   race married nodegree re74 re75       re78\nNSW1     1  37   11  black       1        1    0    0  9930.0460\nNSW2     1  22    9 hispan       0        1    0    0  3595.8940\nNSW3     1  30   12  black       0        0    0    0 24909.4500\nNSW4     1  27   11  black       0        1    0    0  7506.1460\nNSW5     1  33    8  black       0        1    0    0   289.7899\nNSW6     1  22    9  black       0        1    0    0  4056.4940\n\n\n\nБаланс ковариатов ДО мэтчинга\n\n\nt-тест – p-value\n\n\nlibrary('tableone')\n\n\ntable1 &lt;- CreateTableOne(vars=c('age', 'educ', 'race', 'married', 'nodegree', 're74', 're75'), \n                         strata = 'treat', data=lalonde, test=TRUE)\ntable1\n\n                      Stratified by treat\n                       0                 1                 p      test\n  n                        429               185                      \n  age (mean (SD))        28.03 (10.79)     25.82 (7.16)     0.011     \n  educ (mean (SD))       10.24 (2.86)      10.35 (2.01)     0.633     \n  race (%)                                                 &lt;0.001     \n     black                  87 (20.3)        156 (84.3)               \n     hispan                 61 (14.2)         11 ( 5.9)               \n     white                 281 (65.5)         18 ( 9.7)               \n  married (mean (SD))     0.51 (0.50)       0.19 (0.39)    &lt;0.001     \n  nodegree (mean (SD))    0.60 (0.49)       0.71 (0.46)     0.009     \n  re74 (mean (SD))     5619.24 (6788.75) 2095.57 (4886.62) &lt;0.001     \n  re75 (mean (SD))     2466.48 (3292.00) 1532.06 (3219.25)  0.001     \n\n\nЕсть баланс только по education"
  },
  {
    "objectID": "matching.html#теория",
    "href": "matching.html#теория",
    "title": "6  Мэтчинг",
    "section": "6.1 Теория",
    "text": "6.1 Теория\nРанее, когда мы обсуждали рандомизированные эксперименты, где воздействие является случайным (экзогенным), мы говорили, что контрольные переменные (covariates) можно не включать, поскольку их пропуск не вызывал смещения. Мы включали их только тогда, когда хотели снизить дисперисю оценки. Схема такой ситуации на рисунке ниже.\n\n\n\n\nflowchart LR\n  T(T) --&gt; Y(Y)\n  X(X) --&gt; Y(Y)\n\n\n\n\n\nТеперь мы столкнулись с ситуацией, отличной от эксперимента. Наш тритмент больше не является случайным, а контрольные переменные (confounders) мы будем использовать для того, чтобы избавиться от смещения.\n\n\n\n\nflowchart LR\n  T(T) --&gt; Y(Y)\n  X(X) --&gt;|1| Y(Y)\n  X(X) --&gt;|2| T(T)\n\n\n\n\n\nНа такой икс контролировать обязательно, поскольку в противном случае он создает смещение выборки. К тому же в данной ситуации нельзя просто сравнить средние, нужно как-то убрать лишние стрелочки (см. рисунок выше):\n\n\\(Y \\sim T + X\\) – чтобы убрать первую стрелку, нужно построить полную и правильно специфицированную модель Y. Часто это бывает очень сложно. Эквивалентной процедурой будет сначала оценить модель только на X, а потом посмотреть на эффект на остатках.Также это эквивалентно оценке \\(ATE = \\frac{1}{n_T}\\sum_{T=1}[Y-m(X)]-\\frac{1}{n_C}\\sum_{T=0}[Y-m(X)]\\), где \\(m(X) = \\mathbb{E}(Y|X)\\).\n\\(T \\sim X\\) – гораздо проще построить модель назначения воздействия. Иногда мы знаем точный гайдлайн, по которому формируется группа воздействия, например, разные должностные инструкции или дугие официальные критерии. А иногда мы можем просто догадаться. В любом случае это проще, чем построение общей модели зависимой переменной.\n\nПредсказанные значения вероятности \\(\\widehat{T}\\) называются propensity score (мера склонности). Они используются для расчета весов \\(w = \\frac{T}{e(X)} + \\frac{1-T}{1-e(X)}\\), которые входят в оценку эффекта. Используя эти веса строится оценка вида \\(\\widehat{ATE}=\\frac{1}{N_T} \\sum_{T=1} \\frac{1}{e(X)} Y-\\frac{1}{N_C} \\sum_{T=0} \\frac{1}{1-e(X)} Y\\). Аналогично можно оценить обычную регрессию, где в качестве зависимой переменной выступает \\(wY\\).\nПредпосылками к оценке являются:\n\n\\(T_i \\perp\\left(Y(1)_i, Y(0)_i\\right) \\mid X_i\\) – unconfoundedness (CIA, conditional independence assumption). Если взять людей с одинаковыми характеристиками, то факт, что они в такой-то группе, не зависит от потенциальных исходов. Фактически, если мы фиксируем икс, то получаем идеальный эксперимент. Мы говорили, что есть иксы, которые вызывают смещение, потому что “смешивают” внтури нашей выборки разные группы, так вот если мы этот икс фиксируем, “размешивая” наши данные обратно, то внутри каждой группы мы получаем идеальный эксперимент. Невыполнение этой предпосылки ведёт к смещению оценок.\n\\(e\\left(X_i\\right)=E\\left(T_i \\mid X_i\\right) \\in(0,1)\\) – overlap. Вероятность попадания в тритмент группу зависит от характеристик и ненулевая для всех значений X. Это важно для нас потому, что для propesity score, равному нулю мы не найдем контрольную группу, а наблюдения с propesity score, равным единице совершенно точно имели назначение тритмента, то есть это тоже какие-то странные наблюдения, эффект на которых явно отличается. Невыполнение этой предпосылки ведет к тому, что мы просто физически не сможем посчитать эффект, потому что второе слагаемое в разности средних просто не будет существовать."
  },
  {
    "objectID": "matching.html#пример",
    "href": "matching.html#пример",
    "title": "6  Мэтчинг",
    "section": "6.2 Пример",
    "text": "6.2 Пример\nБаза данных, впервые использованная в работе LaLonde (1986), представляет собой классический массив данных, используемый в качестве тестового во многих методологических работах, посвященных мэтчингу. Исследуется вопрос о воздействии программ повышения квалификации (переобучения безработных) на доход.\nЭто подвыборка данных из совокупности, подвергшейся воздействию в рамках программы National Supported Work Demonstration (NSW) и выборки для сопоставления из текущего обследования населения (Current Population Survey, CPS). Эти данные были использованы в исследованиях Lalonde (1986), Dehejia and Wahba (1999).\n\nlibrary('MatchIt')\n\n\ndata('lalonde')\nhead(lalonde)\n\n     treat age educ   race married nodegree re74 re75       re78\nNSW1     1  37   11  black       1        1    0    0  9930.0460\nNSW2     1  22    9 hispan       0        1    0    0  3595.8940\nNSW3     1  30   12  black       0        0    0    0 24909.4500\nNSW4     1  27   11  black       0        1    0    0  7506.1460\nNSW5     1  33    8  black       0        1    0    0   289.7899\nNSW6     1  22    9  black       0        1    0    0  4056.4940\n\n\nДанные состоят из 614 наблюдений (185 в тритменте, 429 в контроле):\n\ntreat – назначение тритмента (1 – участвовал в программе, 0 – не участвовал)\nage – возраст в годах\neduc – количество лет образования\nrace – этническая принадлежность человека (Black, Hispanic, or White)\nmarried – семейный статус (1 – в браке, 0 – холост).\nnodegree – индикатор того, имеет ли человек высшее образование (1 – нет высшего образования, 0 – есть высшее образование)\nre74 – доход в 1974 году в долларах США.\nre75 – доход в 1975 году в долларах США.\nre78 – доход в 1978 году в долларах США.\n\n\n6.2.1 Баланс ковариатов ДО мэтчинга\nОсновная проблема в случае, когда тритмент является эндогенным, это смещение выборки. С высокой долей вероятности наблюдения в двух группах будут неплохожими друг на друга, то есть предпосылка об экзогенности \\(T_i \\perp Y(1)_i, Y(0)_i, X_i\\) не будет выполнена.\nМы можем это проверить на данных, используя тот же инструмент, который мы использовали при проверки качества рандомизации – баланс ковариатов. Фактически это сравнение средних значений контрольных переменных в двух группах. Если воздействие было случайным, то средние в двух группах должны быть примерно равны.\nПроверим это для наших данных, используя разные пакеты.\n\n6.2.1.1 t-тест – p-value\n\\(H_0:\\) среднее значение параметра в группах одинаковое, группы не различаются.\nЕсли мы получили достаточно большое значение t-статистики такое, что \\(p-value &lt; \\alpha\\), то мы отклоняем нулевую гипотезу и заключаем, что группы статистически различаются по переменной интереса.\n\nlibrary('tableone')\n\n\ntable1 &lt;- CreateTableOne(vars=c('age', 'educ', 'race', 'married', 'nodegree', 're74', 're75'), \n                         strata = 'treat', data=lalonde, test=TRUE)\ntable1\n\n                      Stratified by treat\n                       0                 1                 p      test\n  n                        429               185                      \n  age (mean (SD))        28.03 (10.79)     25.82 (7.16)     0.011     \n  educ (mean (SD))       10.24 (2.86)      10.35 (2.01)     0.633     \n  race (%)                                                 &lt;0.001     \n     black                  87 (20.3)        156 (84.3)               \n     hispan                 61 (14.2)         11 ( 5.9)               \n     white                 281 (65.5)         18 ( 9.7)               \n  married (mean (SD))     0.51 (0.50)       0.19 (0.39)    &lt;0.001     \n  nodegree (mean (SD))    0.60 (0.49)       0.71 (0.46)     0.009     \n  re74 (mean (SD))     5619.24 (6788.75) 2095.57 (4886.62) &lt;0.001     \n  re75 (mean (SD))     2466.48 (3292.00) 1532.06 (3219.25)  0.001     \n\n\nВидим, что баланс ковариант есть только по переменной education.\n\n\n6.2.1.2 Хи-квадрат тест – сводит к одной статистике\n\nlibrary('RItools')\n\n\nxBalance(treat ~ age + educ + race + married + nodegree + re74 + re75, \n         data=lalonde, report = 'chisquare.test')\n\n---Overall Test---\n        chisquare df  p.value\nunstrat       238  8 6.17e-47\n\n\nЕсли статистика &gt;25, то нет баланса. У нас 238, поэтому баланса точно нет.\n\n\n6.2.1.3 t-тест – std diff\n\nmod1 &lt;- matchit(treat ~ age + educ + race + married + nodegree + re74 + re75,\n                data = lalonde, method = NULL, distance = 'glm')\nsummary(mod1)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, data = lalonde, method = NULL, distance = \"glm\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5774        0.1822          1.7941     0.9211    0.3774\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\nmarried           0.1892        0.5128         -0.8263          .    0.3236\nnodegree          0.7081        0.5967          0.2450          .    0.1114\nre74           2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2903     0.9563    0.1342\n           eCDF Max\ndistance     0.6444\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nmarried      0.3236\nnodegree     0.1114\nre74         0.4470\nre75         0.2876\n\nSample Sizes:\n          Control Treated\nAll           429     185\nMatched       429     185\nUnmatched       0       0\nDiscarded       0       0\n\n\n\n\n6.2.1.4 t-тест, выдача в формате true/false\n\nlibrary('cobalt')\n\n\nbal.tab(treat ~ age + educ + race + married + nodegree + re74 + re75, \n        data = lalonde, estimand = 'ATE', m.threshold = 0.05)\n\nBalance Measures\n               Type Diff.Un      M.Threshold.Un\nage         Contin. -0.2419 Not Balanced, &gt;0.05\neduc        Contin.  0.0448     Balanced, &lt;0.05\nrace_black   Binary  0.6404 Not Balanced, &gt;0.05\nrace_hispan  Binary -0.0827 Not Balanced, &gt;0.05\nrace_white   Binary -0.5577 Not Balanced, &gt;0.05\nmarried      Binary -0.3236 Not Balanced, &gt;0.05\nnodegree     Binary  0.1114 Not Balanced, &gt;0.05\nre74        Contin. -0.5958 Not Balanced, &gt;0.05\nre75        Contin. -0.2870 Not Balanced, &gt;0.05\n\nBalance tally for mean differences\n                    count\nBalanced, &lt;0.05         1\nNot Balanced, &gt;0.05     8\n\nVariable with the greatest mean difference\n   Variable Diff.Un      M.Threshold.Un\n race_black  0.6404 Not Balanced, &gt;0.05\n\nSample sizes\n    Control Treated\nAll     429     185\n\n\nБаланс есть только по образованию, а вот самый большой дисбаланс по расе – в тритмент группе преобладают темнокожие.\n\n\n6.2.1.5 dplyr – наше всё\n\nlibrary('dplyr')\n\n\nbalance1 &lt;- lalonde %&gt;% group_by(treat) %&gt;% summarise(avgeduc = mean(educ))\nbalance1\n\n# A tibble: 2 × 2\n  treat avgeduc\n  &lt;int&gt;   &lt;dbl&gt;\n1     0    10.2\n2     1    10.3\n\n\n\nbalance2 &lt;- lalonde %&gt;% group_by(treat) %&gt;% summarize_all(mean)\nbalance2\n\n# A tibble: 2 × 9\n  treat   age  educ  race married nodegree  re74  re75  re78\n  &lt;int&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;   &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;\n1     0  28.0  10.2    NA   0.513    0.597 5619. 2466. 6984.\n2     1  25.8  10.3    NA   0.189    0.708 2096. 1532. 6349.\n\n\n\n\n6.2.1.6 Гистограмы\n\nlalonde$ftreat &lt;- as.factor(lalonde$treat)\n\nВо-первых, посмотрим, как изменился доход после участия в программе переобучения:\n\nggplot(lalonde, aes(x=re74, fill=ftreat, color=ftreat)) +\n  geom_histogram(position=\"identity\", alpha=0.7)\n\n\n\n\n\nggplot(lalonde, aes(x=re78, fill=ftreat, color=ftreat)) +\n  geom_histogram(position=\"identity\", alpha=0.7)\n\n\n\n\nБаланс по возрасту отсутствует:\n\nggplot(lalonde, aes(x=age, fill=ftreat, color=ftreat)) +\n  geom_histogram(position=\"identity\", alpha=0.7)\n\n\n\n\nБаланс по образованию тоже отсутствует:\n\nggplot(lalonde, aes(x=educ, fill=ftreat, color=ftreat)) +\n  geom_histogram(position=\"identity\", alpha=0.7)\n\n\n\n\n\n\n6.2.1.7 Пакеты с красивыми описательными статистиками\n\n6.2.1.7.1 Пакет psych\n\nlibrary('psych')\n\n\npsych::describeBy(lalonde, lalonde$treat)\n\n\n Descriptive statistics by group \ngroup: 0\n         vars   n    mean      sd  median trimmed     mad min      max    range\ntreat       1 429    0.00    0.00    0.00    0.00    0.00   0     0.00     0.00\nage         2 429   28.03   10.79   25.00   26.72   10.38  16    55.00    39.00\neduc        3 429   10.24    2.86   11.00   10.39    1.48   0    18.00    18.00\nrace*       4 429    2.45    0.81    3.00    2.56    0.00   1     3.00     2.00\nmarried     5 429    0.51    0.50    1.00    0.52    0.00   0     1.00     1.00\nnodegree    6 429    0.60    0.49    1.00    0.62    0.00   0     1.00     1.00\nre74        7 429 5619.24 6788.75 2547.05 4453.19 3776.25   0 25862.32 25862.32\nre75        8 429 2466.48 3292.00 1086.73 1830.87 1611.18   0 18347.23 18347.23\nre78        9 429 6984.17 7294.16 4975.50 5968.08 7376.68   0 25564.67 25564.67\nftreat*    10 429    1.00    0.00    1.00    1.00    0.00   1     1.00     0.00\n          skew kurtosis     se\ntreat      NaN      NaN   0.00\nage       0.88    -0.34   0.52\neduc     -0.68     1.26   0.14\nrace*    -0.99    -0.75   0.04\nmarried  -0.05    -2.00   0.02\nnodegree -0.39    -1.85   0.02\nre74      1.22     0.57 327.76\nre75      1.77     3.34 158.94\nre78      0.94    -0.14 352.17\nftreat*    NaN      NaN   0.00\n------------------------------------------------------------ \ngroup: 1\n         vars   n    mean      sd  median trimmed     mad min      max    range\ntreat       1 185    1.00    0.00    1.00    1.00    0.00   1     1.00     0.00\nage         2 185   25.82    7.16   25.00   24.85    5.93  17    48.00    31.00\neduc        3 185   10.35    2.01   11.00   10.46    1.48   4    16.00    12.00\nrace*       4 185    1.25    0.62    1.00    1.07    0.00   1     3.00     2.00\nmarried     5 185    0.19    0.39    0.00    0.11    0.00   0     1.00     1.00\nnodegree    6 185    0.71    0.46    1.00    0.76    0.00   0     1.00     1.00\nre74        7 185 2095.57 4886.62    0.00  834.42    0.00   0 35040.07 35040.07\nre75        8 185 1532.06 3219.25    0.00  790.16    0.00   0 25142.24 25142.24\nre78        9 185 6349.14 7867.40 4232.31 4976.95 6274.82   0 60307.93 60307.93\nftreat*    10 185    2.00    0.00    2.00    2.00    0.00   2     2.00     0.00\n          skew kurtosis     se\ntreat      NaN      NaN   0.00\nage       1.11     0.81   0.53\neduc     -0.72     1.39   0.15\nrace*     2.20     3.21   0.05\nmarried   1.57     0.48   0.03\nnodegree -0.91    -1.18   0.03\nre74      3.36    14.20 359.27\nre75      3.75    19.03 236.68\nre78      2.70    12.28 578.42\nftreat*    NaN      NaN   0.00\n\n\n\n\n6.2.1.7.2 Пакет skimr\n\nlibrary('skimr')\n\n\nskim(lalonde)\n\n\nData summary\n\n\nName\nlalonde\n\n\nNumber of rows\n614\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n8\n\n\n________________________\n\n\n\nGroup variables\nNone\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nrace\n0\n1\nFALSE\n3\nwhi: 299, bla: 243, his: 72\n\n\nftreat\n0\n1\nFALSE\n2\n0: 429, 1: 185\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\ntreat\n0\n1\n0.30\n0.46\n0\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▃\n\n\nage\n0\n1\n27.36\n9.88\n16\n20.00\n25.00\n32.00\n55.00\n▇▅▂▂▁\n\n\neduc\n0\n1\n10.27\n2.63\n0\n9.00\n11.00\n12.00\n18.00\n▁▂▆▇▁\n\n\nmarried\n0\n1\n0.42\n0.49\n0\n0.00\n0.00\n1.00\n1.00\n▇▁▁▁▆\n\n\nnodegree\n0\n1\n0.63\n0.48\n0\n0.00\n1.00\n1.00\n1.00\n▅▁▁▁▇\n\n\nre74\n0\n1\n4557.55\n6477.96\n0\n0.00\n1042.33\n7888.50\n35040.07\n▇▂▁▁▁\n\n\nre75\n0\n1\n2184.94\n3295.68\n0\n0.00\n601.55\n3248.99\n25142.24\n▇▁▁▁▁\n\n\nre78\n0\n1\n6792.83\n7470.73\n0\n238.28\n4759.02\n10893.59\n60307.93\n▇▂▁▁▁\n\n\n\n\n\n\nlalonde %&gt;% group_by(treat) %&gt;% skim()\n\n\nData summary\n\n\nName\nPiped data\n\n\nNumber of rows\n614\n\n\nNumber of columns\n10\n\n\n_______________________\n\n\n\nColumn type frequency:\n\n\n\nfactor\n2\n\n\nnumeric\n7\n\n\n________________________\n\n\n\nGroup variables\ntreat\n\n\n\nVariable type: factor\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ntreat\nn_missing\ncomplete_rate\nordered\nn_unique\ntop_counts\n\n\n\n\nrace\n0\n0\n1\nFALSE\n3\nwhi: 281, bla: 87, his: 61\n\n\nrace\n1\n0\n1\nFALSE\n3\nbla: 156, whi: 18, his: 11\n\n\nftreat\n0\n0\n1\nFALSE\n1\n0: 429, 1: 0\n\n\nftreat\n1\n0\n1\nFALSE\n1\n1: 185, 0: 0\n\n\n\nVariable type: numeric\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nskim_variable\ntreat\nn_missing\ncomplete_rate\nmean\nsd\np0\np25\np50\np75\np100\nhist\n\n\n\n\nage\n0\n0\n1\n28.03\n10.79\n16\n19.00\n25.00\n35.00\n55.00\n▇▃▂▂▂\n\n\nage\n1\n0\n1\n25.82\n7.16\n17\n20.00\n25.00\n29.00\n48.00\n▇▇▂▁▁\n\n\neduc\n0\n0\n1\n10.24\n2.86\n0\n9.00\n11.00\n12.00\n18.00\n▁▂▆▇▁\n\n\neduc\n1\n0\n1\n10.35\n2.01\n4\n9.00\n11.00\n12.00\n16.00\n▁▂▇▃▁\n\n\nmarried\n0\n0\n1\n0.51\n0.50\n0\n0.00\n1.00\n1.00\n1.00\n▇▁▁▁▇\n\n\nmarried\n1\n0\n1\n0.19\n0.39\n0\n0.00\n0.00\n0.00\n1.00\n▇▁▁▁▂\n\n\nnodegree\n0\n0\n1\n0.60\n0.49\n0\n0.00\n1.00\n1.00\n1.00\n▆▁▁▁▇\n\n\nnodegree\n1\n0\n1\n0.71\n0.46\n0\n0.00\n1.00\n1.00\n1.00\n▃▁▁▁▇\n\n\nre74\n0\n0\n1\n5619.24\n6788.75\n0\n0.00\n2547.05\n9277.13\n25862.32\n▇▂▂▁▁\n\n\nre74\n1\n0\n1\n2095.57\n4886.62\n0\n0.00\n0.00\n1291.47\n35040.07\n▇▁▁▁▁\n\n\nre75\n0\n0\n1\n2466.48\n3292.00\n0\n0.00\n1086.73\n3881.42\n18347.23\n▇▂▁▁▁\n\n\nre75\n1\n0\n1\n1532.06\n3219.25\n0\n0.00\n0.00\n1817.28\n25142.24\n▇▁▁▁▁\n\n\nre78\n0\n0\n1\n6984.17\n7294.16\n0\n220.18\n4975.50\n11688.82\n25564.67\n▇▃▂▂▁\n\n\nre78\n1\n0\n1\n6349.14\n7867.40\n0\n485.23\n4232.31\n9643.00\n60307.93\n▇▁▁▁▁\n\n\n\n\n\n\n\n6.2.1.7.3 Пакет summarytools\n\nlibrary('summarytools')\n\n\ndfSummary(lalonde)\n\nData Frame Summary  \nlalonde  \nDimensions: 614 x 10  \nDuplicates: 5  \n\n-----------------------------------------------------------------------------------------------------------\nNo   Variable    Stats / Values                Freqs (% of Valid)    Graph             Valid      Missing  \n---- ----------- ----------------------------- --------------------- ----------------- ---------- ---------\n1    treat       Min  : 0                      0 : 429 (69.9%)       IIIIIIIIIIIII     614        0        \n     [integer]   Mean : 0.3                    1 : 185 (30.1%)       IIIIII            (100.0%)   (0.0%)   \n                 Max  : 1                                                                                  \n\n2    age         Mean (sd) : 27.4 (9.9)        40 distinct values    :                 614        0        \n     [integer]   min &lt; med &lt; max:                                    : :               (100.0%)   (0.0%)   \n                 16 &lt; 25 &lt; 55                                        : : .                                 \n                 IQR (CV) : 12 (0.4)                                 : : : . .                             \n                                                                     : : : : : : : .                       \n\n3    educ        Mean (sd) : 10.3 (2.6)        19 distinct values              :       614        0        \n     [integer]   min &lt; med &lt; max:                                              :       (100.0%)   (0.0%)   \n                 0 &lt; 11 &lt; 18                                                 : :                           \n                 IQR (CV) : 3 (0.3)                                        : : :                           \n                                                                       . . : : : : .                       \n\n4    race        1. black                      243 (39.6%)           IIIIIII           614        0        \n     [factor]    2. hispan                      72 (11.7%)           II                (100.0%)   (0.0%)   \n                 3. white                      299 (48.7%)           IIIIIIIII                             \n\n5    married     Min  : 0                      0 : 359 (58.5%)       IIIIIIIIIII       614        0        \n     [integer]   Mean : 0.4                    1 : 255 (41.5%)       IIIIIIII          (100.0%)   (0.0%)   \n                 Max  : 1                                                                                  \n\n6    nodegree    Min  : 0                      0 : 227 (37.0%)       IIIIIII           614        0        \n     [integer]   Mean : 0.6                    1 : 387 (63.0%)       IIIIIIIIIIII      (100.0%)   (0.0%)   \n                 Max  : 1                                                                                  \n\n7    re74        Mean (sd) : 4557.5 (6478)     358 distinct values   :                 614        0        \n     [numeric]   min &lt; med &lt; max:                                    :                 (100.0%)   (0.0%)   \n                 0 &lt; 1042.3 &lt; 35040.1                                :                                     \n                 IQR (CV) : 7888.5 (1.4)                             :                                     \n                                                                     : : . .                               \n\n8    re75        Mean (sd) : 2184.9 (3295.7)   356 distinct values   :                 614        0        \n     [numeric]   min &lt; med &lt; max:                                    :                 (100.0%)   (0.0%)   \n                 0 &lt; 601.5 &lt; 25142.2                                 :                                     \n                 IQR (CV) : 3249 (1.5)                               :                                     \n                                                                     : : .                                 \n\n9    re78        Mean (sd) : 6792.8 (7470.7)   457 distinct values   :                 614        0        \n     [numeric]   min &lt; med &lt; max:                                    :                 (100.0%)   (0.0%)   \n                 0 &lt; 4759 &lt; 60307.9                                  :                                     \n                 IQR (CV) : 10655.3 (1.1)                            : :                                   \n                                                                     : : : . .                             \n\n10   ftreat      1. 0                          429 (69.9%)           IIIIIIIIIIIII     614        0        \n     [factor]    2. 1                          185 (30.1%)           IIIIII            (100.0%)   (0.0%)   \n-----------------------------------------------------------------------------------------------------------\n\n\n\n\n\n\n6.2.2 Оценка меры склонности\nМы убедились, что баланса в контрольной группе и группе воздействия нет, как и пологается при энлогенном тритменте. Далее будем строить оценку воздействия с помощью мэтчинга.\n\n6.2.2.1 Вручную\nЧтобы построить прогнозное значение вероятности попадания каждого наблюдения в группу воздействия, оценим простейшую логит модель:\n\npropscore &lt;- glm(treat ~ age + educ + race + married + nodegree + re74 + re75, \n                 data = lalonde, family = binomial(link='logit'))\nsummary(propscore)\n\n\nCall:\nglm(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, family = binomial(link = \"logit\"), data = lalonde)\n\nDeviance Residuals: \n    Min       1Q   Median       3Q      Max  \n-1.7645  -0.4736  -0.2862   0.7508   2.7169  \n\nCoefficients:\n              Estimate Std. Error z value Pr(&gt;|z|)    \n(Intercept) -1.663e+00  9.709e-01  -1.713  0.08668 .  \nage          1.578e-02  1.358e-02   1.162  0.24521    \neduc         1.613e-01  6.513e-02   2.477  0.01325 *  \nracehispan  -2.082e+00  3.672e-01  -5.669 1.44e-08 ***\nracewhite   -3.065e+00  2.865e-01 -10.699  &lt; 2e-16 ***\nmarried     -8.321e-01  2.903e-01  -2.866  0.00415 ** \nnodegree     7.073e-01  3.377e-01   2.095  0.03620 *  \nre74        -7.178e-05  2.875e-05  -2.497  0.01253 *  \nre75         5.345e-05  4.635e-05   1.153  0.24884    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n(Dispersion parameter for binomial family taken to be 1)\n\n    Null deviance: 751.49  on 613  degrees of freedom\nResidual deviance: 487.84  on 605  degrees of freedom\nAIC: 505.84\n\nNumber of Fisher Scoring iterations: 5\n\n\nПосмотрим на первые 10 вероятностей:\n\npropscore$fitted.values[1:10]\n\n      NSW1       NSW2       NSW3       NSW4       NSW5       NSW6       NSW7 \n0.63876993 0.22463424 0.67824388 0.77632408 0.70163874 0.69906990 0.65368426 \n      NSW8       NSW9      NSW10 \n0.78972311 0.77983825 0.04292461 \n\n\nИ на их распределение:\n\nhist(propscore$fitted.values)\n\n\n\n\nПосчитаем веса по формуле \\(w = \\frac{T}{e(X)} + \\frac{1-T}{1-e(X)}\\):\n\nlalonde$ps_handmade &lt;- propscore$fitted.values # добавили в датасет меру склонности для каждого наблюдения\nlalonde &lt;- lalonde %&gt;% mutate(w_ate = treat/ps_handmade + (1-treat)/(1-ps_handmade)) # посчитаем веса\n\n\n\n6.2.2.2 Через пакет WeightIt\nАналогичные веса можно получить готовыми из пакета WeightIt.\n\nlibrary('WeightIt')\n\nОднако помимо самих весов пакет представляет в подарок еще и широкую аналитику по весам в вашей выборке:\n\npropscore1 &lt;- weightit(treat ~ age + educ + race + married + nodegree + re74 + re75,\n                       data = lalonde, estimand = 'ATE', method = 'ps')\nsummary(propscore1)\n\n                 Summary of weights\n\n- Weight ranges:\n\n           Min                                   Max\ntreated 1.1721 |---------------------------| 40.0773\ncontrol 1.0092 |-|                            4.7432\n\n- Units with the 5 most extreme weights by group:\n                                                \n              68     116      10     137     124\n treated 13.5451 15.9884 23.2967 23.3891 40.0773\n             597     573     381     411     303\n control  4.0301  4.0592  4.2397  4.5231  4.7432\n\n- Weight statistics:\n\n        Coef of Var   MAD Entropy # Zeros\ntreated       1.478 0.807   0.534       0\ncontrol       0.552 0.391   0.118       0\n\n- Effective Sample Sizes:\n\n           Control Treated\nUnweighted  429.    185.  \nWeighted    329.01   58.33\n\n\nТакже сохраним эти веса в свой набор данных:\n\nlalonde$w_ate_weightit &lt;- propscore1$weights\npropscore1$weights[1:10]\n\n [1]  1.565509  4.451681  1.474396  1.288122  1.425235  1.430472  1.529791\n [8]  1.266267  1.282317 23.296656\n\n\n\n\n\n6.2.3 Оценка ATE\nСамый простой способ оценить эффект – оценить обычную парную МНК регрессию, где в качестве зависимой переменной выступает \\(wY\\).\n\nmod_ATE &lt;- lm(re78 ~ treat, data = lalonde, weights = lalonde$w_ate) # а можно и взять веса из пакета пакет WeightIt\nsummary(mod_ATE)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = lalonde$w_ate)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n-42083  -6606  -2284   4979  77674 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   6422.8      397.4  16.161   &lt;2e-16 ***\ntreat          224.7      577.7   0.389    0.697    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 9864 on 612 degrees of freedom\nMultiple R-squared:  0.0002471, Adjusted R-squared:  -0.001386 \nF-statistic: 0.1513 on 1 and 612 DF,  p-value: 0.6975\n\n\n\n\n6.2.4 Оценка ATT\nДля оценки воздействия на воздействованных понадобятся иные веса.\n\n6.2.4.1 Веса вручную\n\nlalonde &lt;- lalonde %&gt;% mutate(w_att = treat + (1-treat)*ps_handmade/(1-ps_handmade)) # посчитаем веса\n\n\n\n6.2.4.2 Веса через пакет WeightIt\n\npropscore2 &lt;- weightit(treat ~ age + educ + race + married + nodegree + re74 + re75,\n                       data = lalonde, estimand = 'ATT', method = 'ps')\nsummary(propscore2)\n\n                 Summary of weights\n\n- Weight ranges:\n\n           Min                                  Max\ntreated 1.0000         ||                    1.0000\ncontrol 0.0092 |---------------------------| 3.7432\n\n- Units with the 5 most extreme weights by group:\n                                           \n              5      4      3      2      1\n treated      1      1      1      1      1\n            597    573    381    411    303\n control 3.0301 3.0592 3.2397 3.5231 3.7432\n\n- Weight statistics:\n\n        Coef of Var   MAD Entropy # Zeros\ntreated       0.000 0.000  -0.000       0\ncontrol       1.818 1.289   1.098       0\n\n- Effective Sample Sizes:\n\n           Control Treated\nUnweighted  429.       185\nWeighted     99.82     185\n\n\n\npropscore2$weights[1:10]\n\n [1] 1 1 1 1 1 1 1 1 1 1\n\n\n\n\n6.2.4.3 Сам эффект\n\nmod_ATT &lt;- lm(re78 ~ treat, data = lalonde, weights = lalonde$w_att) # а можно и взять веса из пакета пакет WeightIt\nsummary(mod_ATT)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = lalonde$w_att)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n -9182  -1938   -326   1792  53959 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5135.1      401.2  12.799   &lt;2e-16 ***\ntreat         1214.1      568.9   2.134   0.0332 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 5486 on 612 degrees of freedom\nMultiple R-squared:  0.007387,  Adjusted R-squared:  0.005765 \nF-statistic: 4.554 on 1 and 612 DF,  p-value: 0.03324\n\n\n\n\n\n6.2.5 Просто мэтчинг\n\nlibrary('MatchIt')\n\n\n6.2.5.1 Точный мэтчинг\nСначала подбираем мэтчи и считаем веса:\n\nmodel_0 &lt;- matchit(treat ~ age + educ + race + married + nodegree + re74 + re75, \n                   data = lalonde, method = \"exact\", estimand = 'ATE')\nsummary(model_0)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, data = lalonde, method = \"exact\", estimand = \"ATE\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage              25.8162       28.0303         -0.2419     0.4400    0.0813\neduc             10.3459       10.2354          0.0448     0.4959    0.0347\nraceblack         0.8432        0.2028          1.6708          .    0.6404\nracehispan        0.0595        0.1422         -0.2774          .    0.0827\nracewhite         0.0973        0.6550         -1.4080          .    0.5577\nmarried           0.1892        0.5128         -0.7208          .    0.3236\nnodegree          0.7081        0.5967          0.2355          .    0.1114\nre74           2095.5737     5619.2365         -0.5958     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2870     0.9563    0.1342\n           eCDF Max\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nmarried      0.3236\nnodegree     0.1114\nre74         0.4470\nre75         0.2876\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage                18.12         18.12               0     0.9927         0\neduc               10.32         10.32               0     0.9927         0\nraceblack           1.00          1.00               0          .         0\nracehispan          0.00          0.00               0          .         0\nracewhite           0.00          0.00               0          .         0\nmarried             0.00          0.00               0          .         0\nnodegree            0.80          0.80               0          .         0\nre74                0.00          0.00               0          .         0\nre75                0.00          0.00               0          .         0\n           eCDF Max Std. Pair Dist.\nage               0               0\neduc              0               0\nraceblack         0               0\nracehispan        0               0\nracewhite         0               0\nmarried           0               0\nnodegree          0               0\nre74              0               0\nre75              0               0\n\nSample Sizes:\n              Control Treated\nAll            429.    185.  \nMatched (ESS)   11.26   12.18\nMatched         12.     13.  \nUnmatched      417.    172.  \nDiscarded        0.      0.  \n\n\nВидим, что с помощью точного мэтчинга подобралось лишь 12 пар.\nЗатем проверяем баланс при данном типе мэтчинга. Белые точки соответсвуют балансу до мэтчинга, черные – после. Видим, что до мэтчинга баланс был выполнен лишь для образования, а после мэтчинга для всех переменных. Однако за этим мы расплатились малым количеством пар, а малое количество наблюдений при усреднении ведёт к высокой дисперсии, то есть из-за широкого доверительного интервала мы можем не заметить даже реально существующий эффект.\n\nplot(summary(model_0))\n\n\n\n\n\nplot(model_0, type = \"qq\", interactive = FALSE, wich.xs = c('age', 'married', 're75', 're74', 'educ'))\n\n\n\n\n\n\n\n\n\n\nСчитаем эффект и видим, что он незначим.\n\nmodel_0_t &lt;- lm(re78 ~ treat, data = lalonde, weights = model_0$weights) \nsummary(model_0_t)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = model_0$weights)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n -7598      0      0      0  12131 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)   \n(Intercept)     6331       1875   3.376   0.0026 **\ntreat          -1132       2600  -0.435   0.6675   \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6496 on 23 degrees of freedom\nMultiple R-squared:  0.008168,  Adjusted R-squared:  -0.03495 \nF-statistic: 0.1894 on 1 and 23 DF,  p-value: 0.6675\n\n\n\n\n6.2.5.2 Метод ближайшего соседа с расстоянием по мере склонности\nПо умолчанию, для мэтчинга по методу ближайшего соседа функция matchit() использует логистическую регрессию для оценки индивидуальных вероятностей попадания в группу воздействия. Чтобы изменить метрику, следует применить аргумент distance.\nСопоставление ближайших соседей также известно как жадное сопоставление. Оно включает просмотр тритмент наблюдений и выбор ближайшего наблюдения из контрольной группы для сопоставления. Подход является жадным в том смысле, что каждое сопоставление происходит безотносительно к тому, как будут или были сопоставлены другие пары, и поэтому не направлено на оптимизацию какого-либо критерия общего критерия, кроме минимизации расстояния на конкретном шаге. То есть на каждом отдельном шаге это будет оптимум, однако сумма попарных расстояний может не быть мимнимальной.\nСопоставление ближайших соседей также требудет указания метрики расстояния. По умолчаниюиспользуется разница в мере склонности. Еще одно популярное расстояние — расстояние Махаланобиса. Пакет при подборе пар по умолчанию начинает с наблюдений с наибольшей мерой склоннсти и дальше действует по убыванию. Это позволит первыми сопоставить те наблюдения, которым будет труднее всего найти пару. Однако возможны и другие упорядочивания (случайные, с возвращениями и т.д.)\n\nmodel_1 &lt;- matchit(treat ~ age + educ + race + married + nodegree + re74 + re75, \n                   data = lalonde, method = 'nearest', estimand = 'ATT')\nsummary(model_1)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, data = lalonde, method = \"nearest\", estimand = \"ATT\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5774        0.1822          1.7941     0.9211    0.3774\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\nmarried           0.1892        0.5128         -0.8263          .    0.3236\nnodegree          0.7081        0.5967          0.2450          .    0.1114\nre74           2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2903     0.9563    0.1342\n           eCDF Max\ndistance     0.6444\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nmarried      0.3236\nnodegree     0.1114\nre74         0.4470\nre75         0.2876\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5774        0.3629          0.9739     0.7566    0.1321\nage              25.8162       25.3027          0.0718     0.4568    0.0847\neduc             10.3459       10.6054         -0.1290     0.5721    0.0239\nraceblack         0.8432        0.4703          1.0259          .    0.3730\nracehispan        0.0595        0.2162         -0.6629          .    0.1568\nracewhite         0.0973        0.3135         -0.7296          .    0.2162\nmarried           0.1892        0.2108         -0.0552          .    0.0216\nnodegree          0.7081        0.6378          0.1546          .    0.0703\nre74           2095.5737     2342.1076         -0.0505     1.3289    0.0469\nre75           1532.0553     1614.7451         -0.0257     1.4956    0.0452\n           eCDF Max Std. Pair Dist.\ndistance     0.4216          0.9740\nage          0.2541          1.3938\neduc         0.0757          1.2474\nraceblack    0.3730          1.0259\nracehispan   0.1568          1.0743\nracewhite    0.2162          0.8390\nmarried      0.0216          0.8281\nnodegree     0.0703          1.0106\nre74         0.2757          0.7965\nre75         0.2054          0.7381\n\nSample Sizes:\n          Control Treated\nAll           429     185\nMatched       185     185\nUnmatched     244       0\nDiscarded       0       0\n\n\n\nplot(model_1, type = 'jitter', interactive = FALSE) # расположение наблюдений по propscore\n\n\n\n\n\nplot(summary(model_1))\n\n\n\n\n\nplot(model_1, type = \"qq\", interactive = FALSE, wich.xs = c('age', 'married', 're75', 're74', 'educ'))\n\n\n\n\n\n\n\n\n\n\n\nmodel_1_t &lt;- lm(re78 ~ treat, data = lalonde, weights = model_1$weights) \nsummary(model_1_t)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = model_1$weights)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n -6349  -3734      0      0  53959 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5454.8      516.4  10.563   &lt;2e-16 ***\ntreat          894.4      730.3   1.225    0.221    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7024 on 368 degrees of freedom\nMultiple R-squared:  0.004059,  Adjusted R-squared:  0.001353 \nF-statistic:   1.5 on 1 and 368 DF,  p-value: 0.2215\n\n\n\n\n6.2.5.3 Метод ближайшего соседа c расстоянием Махаланобиса\n\nmodel_2 &lt;- matchit(treat ~ age + educ + race + married + nodegree + re74 + re75, \n                   data = lalonde, method = 'nearest', distance = 'mahalanobis', estimand = 'ATT')\nsummary(model_2)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, data = lalonde, method = \"nearest\", distance = \"mahalanobis\", \n    estimand = \"ATT\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\nmarried           0.1892        0.5128         -0.8263          .    0.3236\nnodegree          0.7081        0.5967          0.2450          .    0.1114\nre74           2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2903     0.9563    0.1342\n           eCDF Max\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nmarried      0.3236\nnodegree     0.1114\nre74         0.4470\nre75         0.2876\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage              25.8162       24.9189          0.1254     0.5333    0.0692\neduc             10.3459       10.4378         -0.0457     0.8306    0.0111\nraceblack         0.8432        0.4649          1.0407          .    0.3784\nracehispan        0.0595        0.0595          0.0000          .    0.0000\nracewhite         0.0973        0.4757         -1.2767          .    0.3784\nmarried           0.1892        0.2486         -0.1518          .    0.0595\nnodegree          0.7081        0.6595          0.1070          .    0.0486\nre74           2095.5737     3308.2167         -0.2482     0.8710    0.1016\nre75           1532.0553     1960.6355         -0.1331     1.0081    0.0662\n           eCDF Max Std. Pair Dist.\nage          0.2324          0.6210\neduc         0.0486          0.2930\nraceblack    0.3784          1.0407\nracehispan   0.0000          0.0000\nracewhite    0.3784          1.2767\nmarried      0.0595          0.1794\nnodegree     0.0486          0.1070\nre74         0.3405          0.4552\nre75         0.2216          0.4123\n\nSample Sizes:\n          Control Treated\nAll           429     185\nMatched       185     185\nUnmatched     244       0\nDiscarded       0       0\n\n\n\nplot(summary(model_2))\n\n\n\n\nМы также можем построить стандартизированные средние различия на графике Лава\n\n#eCDF plot\nplot(model_2, type = \"ecdf\")\n\n\n\n\n\n\n\n\n\n\nПо оси X отображаются значения ковариат, а по оси Y отображается доля выборки, равная или меньшая этого значения ковариаты. Идеально перекрывающиеся линии указывают на хороший баланс. Черная линия соответствует группе воздействия, а серая линия — контрольной группе.\n\n#eCDF plot\nplot(model_2, type = \"density\")\n\n\n\n\n\n\n\n\n\n\n\nplot(model_2, type = \"qq\", interactive = FALSE, wich.xs = c('age', 'married', 're75', 're74', 'educ'))\n\n\n\n\n\n\n\n\n\n\n\nmodel_2_t &lt;- lm(re78 ~ treat, data = lalonde, weights = model_2$weights) \nsummary(model_2_t)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = model_2$weights)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n -6349  -3591      0      0  53959 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5832.5      528.0  11.047   &lt;2e-16 ***\ntreat          516.6      746.7   0.692    0.489    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 7181 on 368 degrees of freedom\nMultiple R-squared:  0.001299,  Adjusted R-squared:  -0.001415 \nF-statistic: 0.4787 on 1 and 368 DF,  p-value: 0.4894\n\n\n\n\n6.2.5.4 Комбинация метода “ближайшего соседа” и точного мэтчинга\n\nmodel_3 &lt;- matchit(treat ~ age + educ + race + married + nodegree + re74 + re75, \n                  data = lalonde, method = \"nearest\", distance = 'mahalanobis',\n                  exact = c (\"educ\",\"race\", \"married\",\"nodegree\"), estimand = 'ATT')\n\nWarning: Fewer control units than treated units in some `exact` strata; not all\ntreated units will get a match.\n\nsummary(model_3)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, data = lalonde, method = \"nearest\", distance = \"mahalanobis\", \n    estimand = \"ATT\", exact = c(\"educ\", \"race\", \"married\", \"nodegree\"))\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\nmarried           0.1892        0.5128         -0.8263          .    0.3236\nnodegree          0.7081        0.5967          0.2450          .    0.1114\nre74           2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2903     0.9563    0.1342\n           eCDF Max\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nmarried      0.3236\nnodegree     0.1114\nre74         0.4470\nre75         0.2876\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\nage              25.9020       25.2157          0.0959     0.5407    0.0696\neduc             10.2843       10.2843          0.0000     1.0000    0.0000\nraceblack         0.7157        0.7157          0.0000          .    0.0000\nracehispan        0.1078        0.1078          0.0000          .    0.0000\nracewhite         0.1765        0.1765          0.0000          .    0.0000\nmarried           0.2157        0.2157          0.0000          .    0.0000\nnodegree          0.6667        0.6667          0.0000          .    0.0000\nre74           1090.1290     2618.1375         -0.3127     0.5914    0.1337\nre75           1017.1332     1497.0957         -0.1491     1.0732    0.0993\n           eCDF Max Std. Pair Dist.\nage          0.2549          0.7701\neduc         0.0000          0.0000\nraceblack    0.0000          0.0000\nracehispan   0.0000          0.0000\nracewhite    0.0000          0.0000\nmarried      0.0000          0.0000\nnodegree     0.0000          0.0000\nre74         0.4608          0.4536\nre75         0.3235          0.4384\n\nSample Sizes:\n          Control Treated\nAll           429     185\nMatched       102     102\nUnmatched     327      83\nDiscarded       0       0\n\n\n\nplot(summary(model_3))\n\n\n\n\n\nplot(model_3, type = \"qq\", interactive = FALSE, wich.xs = c('age', 'married', 're75', 're74', 'educ'))\n\n\n\n\n\n\n\n\n\n\n\nmodel_3_t &lt;- lm(re78 ~ treat, data = lalonde, weights = model_3$weights) \nsummary(model_3_t)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = model_3$weights)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n -5976      0      0      0  20842 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5618.1      617.6   9.097   &lt;2e-16 ***\ntreat          357.5      873.4   0.409    0.683    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6237 on 202 degrees of freedom\nMultiple R-squared:  0.0008287, Adjusted R-squared:  -0.004118 \nF-statistic: 0.1675 on 1 and 202 DF,  p-value: 0.6828\n\n\n\n\n6.2.5.5 Метод минимизации суммы попарных расстояний\nОптимальный подбор пар очень похож на сопоставление ближайших соседей, поскольку пытается соединить каждое наблюдение из тритмента с одним или несколькми наблюденями из контрольной группы. Однако в отличие от сопоставления методом ближайших соседей он является «оптимальным», а не жадным; он оптимален в том смысле, что пытается выбрать совпадения, которые в совокупности оптимизируют общую сумму абсолютных попарных расстояний.\n\nlibrary('optmatch')\n\n\nmodel_4 &lt;- matchit(treat ~ age + educ + race + married + nodegree + re74 + re75, \n                   data = lalonde, method = 'optimal', estimand = 'ATT')\nsummary(model_4)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, data = lalonde, method = \"optimal\", estimand = \"ATT\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5774        0.1822          1.7941     0.9211    0.3774\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\nmarried           0.1892        0.5128         -0.8263          .    0.3236\nnodegree          0.7081        0.5967          0.2450          .    0.1114\nre74           2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2903     0.9563    0.1342\n           eCDF Max\ndistance     0.6444\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nmarried      0.3236\nnodegree     0.1114\nre74         0.4470\nre75         0.2876\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5774        0.3629          0.9739     0.7566    0.1321\nage              25.8162       25.3027          0.0718     0.4568    0.0847\neduc             10.3459       10.6054         -0.1290     0.5721    0.0239\nraceblack         0.8432        0.4703          1.0259          .    0.3730\nracehispan        0.0595        0.2162         -0.6629          .    0.1568\nracewhite         0.0973        0.3135         -0.7296          .    0.2162\nmarried           0.1892        0.2108         -0.0552          .    0.0216\nnodegree          0.7081        0.6378          0.1546          .    0.0703\nre74           2095.5737     2342.1076         -0.0505     1.3289    0.0469\nre75           1532.0553     1614.7451         -0.0257     1.4956    0.0452\n           eCDF Max Std. Pair Dist.\ndistance     0.4216          0.9740\nage          0.2541          1.3138\neduc         0.0757          1.1668\nraceblack    0.3730          1.0259\nracehispan   0.1568          1.0743\nracewhite    0.2162          0.9484\nmarried      0.0216          0.8005\nnodegree     0.0703          0.9155\nre74         0.2757          0.7361\nre75         0.2054          0.7057\n\nSample Sizes:\n          Control Treated\nAll           429     185\nMatched       185     185\nUnmatched     244       0\nDiscarded       0       0\n\n\n\nplot(model_4, type = 'jitter', interactive = FALSE) \n\n\n\n\n\nplot(summary(model_4))\n\n\n\n\n\nplot(model_4, type = \"qq\", interactive = FALSE, \n     wich.xs = c('age', 'married', 're75', 're74', 'educ'))\n\n\n\n\n\n\n\n\n\n\n\nmodel_4_t &lt;- lm(re78 ~ treat, data = lalonde, weights = model_4$weights) \nsummary(model_3_t)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = model_3$weights)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n -5976      0      0      0  20842 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   5618.1      617.6   9.097   &lt;2e-16 ***\ntreat          357.5      873.4   0.409    0.683    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6237 on 202 degrees of freedom\nMultiple R-squared:  0.0008287, Adjusted R-squared:  -0.004118 \nF-statistic: 0.1675 on 1 and 202 DF,  p-value: 0.6828\n\n\n\n\n6.2.5.6 Полный мэтчинг, мэтчатся все наблюдения и никто не выкидывается\n\nmodel_5 &lt;- matchit(treat ~ age + educ + race + married + nodegree + re74 + re75, \n                   data = lalonde, method = 'full', link = 'probit')\nsummary(model_5)\n\n\nCall:\nmatchit(formula = treat ~ age + educ + race + married + nodegree + \n    re74 + re75, data = lalonde, method = \"full\", link = \"probit\")\n\nSummary of Balance for All Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5773        0.1817          1.8276     0.8777    0.3774\nage              25.8162       28.0303         -0.3094     0.4400    0.0813\neduc             10.3459       10.2354          0.0550     0.4959    0.0347\nraceblack         0.8432        0.2028          1.7615          .    0.6404\nracehispan        0.0595        0.1422         -0.3498          .    0.0827\nracewhite         0.0973        0.6550         -1.8819          .    0.5577\nmarried           0.1892        0.5128         -0.8263          .    0.3236\nnodegree          0.7081        0.5967          0.2450          .    0.1114\nre74           2095.5737     5619.2365         -0.7211     0.5181    0.2248\nre75           1532.0553     2466.4844         -0.2903     0.9563    0.1342\n           eCDF Max\ndistance     0.6413\nage          0.1577\neduc         0.1114\nraceblack    0.6404\nracehispan   0.0827\nracewhite    0.5577\nmarried      0.3236\nnodegree     0.1114\nre74         0.4470\nre75         0.2876\n\nSummary of Balance for Matched Data:\n           Means Treated Means Control Std. Mean Diff. Var. Ratio eCDF Mean\ndistance          0.5773        0.5766          0.0036     0.9946    0.0042\nage              25.8162       25.6335          0.0255     0.4674    0.0819\neduc             10.3459       10.4590         -0.0562     0.6138    0.0221\nraceblack         0.8432        0.8389          0.0119          .    0.0043\nracehispan        0.0595        0.0469          0.0532          .    0.0126\nracewhite         0.0973        0.1142         -0.0571          .    0.0169\nmarried           0.1892        0.1555          0.0860          .    0.0337\nnodegree          0.7081        0.6711          0.0814          .    0.0370\nre74           2095.5737     2108.4175         -0.0026     1.3485    0.0330\nre75           1532.0553     1557.1654         -0.0078     1.5659    0.0509\n           eCDF Max Std. Pair Dist.\ndistance     0.0541          0.0197\nage          0.2764          1.2686\neduc         0.0595          1.1950\nraceblack    0.0043          0.0162\nracehispan   0.0126          0.5068\nracewhite    0.0169          0.3978\nmarried      0.0337          0.4866\nnodegree     0.0370          0.9550\nre74         0.2067          0.8421\nre75         0.2059          0.8367\n\nSample Sizes:\n              Control Treated\nAll            429.       185\nMatched (ESS)   51.66     185\nMatched        429.       185\nUnmatched        0.         0\nDiscarded        0.         0\n\n\n\nplot(model_5, type = 'jitter', interactive = FALSE) \n\n\n\n\n\nplot(summary(model_5))\n\n\n\n\n\nplot(model_5, type = \"qq\", interactive = FALSE, wich.xs = c('age', 'married', 're75', 're74', 'educ'))\n\n\n\n\n\n\n\n\n\n\n\nmodel_5_t &lt;- lm(re78 ~ treat, data = lalonde, weights = model_5$weights) \nsummary(model_5_t)\n\n\nCall:\nlm(formula = re78 ~ treat, data = lalonde, weights = model_5$weights)\n\nWeighted Residuals:\n   Min     1Q Median     3Q    Max \n-19309  -2313   -190   2320  53959 \n\nCoefficients:\n            Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)   4517.0      309.7  14.587  &lt; 2e-16 ***\ntreat         1832.1      564.1   3.248  0.00123 ** \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 6414 on 612 degrees of freedom\nMultiple R-squared:  0.01694,   Adjusted R-squared:  0.01534 \nF-statistic: 10.55 on 1 and 612 DF,  p-value: 0.001227\n\n\n\n\n\n6.2.6 Сравнение мэтчингов\nИз пакета cobalt:\n\nbal.tab(treat ~ age + educ + race + married + re74 + re75,\ndata = MatchIt::lalonde,\n# links to mathing results\nweights = data.frame(exact = get.w(model_0),\n                     nearest = get.w(model_1),\n                     mahalanobis = get.w(model_2)),\n# matching method (\"matching\" or \"weighting\")\nmethod = rep(\"matching\", 3),\n# standardized mean diffs. for binary vars.\nbinary = \"std\",\ndisp.v.ratio = TRUE,\ndisp.ks = TRUE)\n\nBalance Measures\n               Type Diff.exact V.Ratio.exact KS.exact Diff.nearest\nage         Contin.          0        0.9927        0       0.0718\neduc        Contin.          0        0.9927        0      -0.1290\nrace_black   Binary          0             .        0       1.0259\nrace_hispan  Binary          0             .        0      -0.6629\nrace_white   Binary          0             .        0      -0.7296\nmarried      Binary          0             .        0      -0.0552\nre74        Contin.          0             .        0      -0.0505\nre75        Contin.          0             .        0      -0.0257\n            V.Ratio.nearest KS.nearest Diff.mahalanobis V.Ratio.mahalanobis\nage                  0.4568     0.2541           0.1254              0.5333\neduc                 0.5721     0.0757          -0.0457              0.8306\nrace_black                .     0.3730           1.0407                   .\nrace_hispan               .     0.1568           0.0000                   .\nrace_white                .     0.2162          -1.2767                   .\nmarried                   .     0.0216          -0.1518                   .\nre74                 1.3289     0.2757          -0.2482              0.8710\nre75                 1.4956     0.2054          -0.1331              1.0081\n            KS.mahalanobis\nage                 0.2324\neduc                0.0486\nrace_black          0.3784\nrace_hispan         0.0000\nrace_white          0.3784\nmarried             0.0595\nre74                0.3405\nre75                0.2216\n\nEffective sample sizes\n            Control Treated\nAll          429.    185.  \nexact         11.26   12.18\nnearest      185.    185.  \nmahalanobis  185.    185.  \n\n\n\nbal.plot(treat ~ age + educ + race + married + re74 + re75,\ndata = MatchIt::lalonde,\n# links to mathing results\nweights = data.frame(exact = get.w(model_0),\n                     nearest = get.w(model_1),\n                     mahalanobis = get.w(model_2)),\n# matching method (\"matching\" or \"weighting\")\nmethod = rep(\"matching\", 3),\nvar.name = \"age\",\nwhich = \"both\")\n\n\n\n\n\nbal.plot(treat ~ age + educ + race + married + re74 + re75,\ndata = MatchIt::lalonde,\n# links to mathing results\nweights = data.frame(exact = get.w(model_0),\n                     nearest = get.w(model_1),\n                     mahalanobis = get.w(model_2)),\n# matching method (\"matching\" or \"weighting\")\nmethod = rep(\"matching\", 3),\nvar.name = \"married\",\nwhich = \"both\")\n\n\n\n\n\nlove.plot(treat ~ age + educ + race + married + re74 + re75,\ndata = MatchIt::lalonde,\nweights = data.frame(exact = get.w(model_0),\n                     nearest = get.w(model_1),\n                     mahalanobis = get.w(model_2)),\nmethod = c(\"matching\", \"matching\", \"matching\"),\n# link method-specific dots\nline = TRUE,\nbinary = \"std\",\n# set thresholds for mean diffs.\nthreshold = 0.1,\nshapes = c(\"circle\", \"square\",\n\"triangle\", \"diamond\")) +\nscale_colour_hue()"
  }
]